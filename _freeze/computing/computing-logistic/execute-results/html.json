{
  "hash": "0b167a0b2f34bf8618ab3e68fb7c6921",
  "result": {
    "engine": "knitr",
    "markdown": "---\n  title: \"Logistic regression\"\n---\n\n\nThe logistic regression model uses a set of predictors ($x_1$, $x_2$, ..., $x_p$) to model the probability that a binary response $y$ is equal to one:\n\n$$\n\\text{Prob}(y=1)=\\frac{1}{1+e^{-(\\beta_0+\\beta_1x_1+...+\\beta_px_p)}}.\n$$\n\nThis primer leads you down the path of least resistance to fitting this model, plotting the best-fitting S-curve in the single-predictor case, plotting the decision boundary in the bivariate case, and generating predictions.\n\n## Setup\n\nThe commands for working with logistic regressions are in the `tidymodels` package, so load that:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse) \nlibrary(tidymodels) \n```\n:::\n\n\nNext, we need something to model, so let us load in a data set. We will consider this data set from Hewlett-Packard on spam emails:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhp_spam <- read_csv(\"hp-spam.csv\")\n\nhp_spam <- hp_spam |>\n  mutate(type = as.factor(type))\n```\n:::\n\n\n::: callout-note\nBe prepared to [adjust the file path](https://sta101-f24.github.io/computing/computing-file-paths.html) to match how you have organized your files and folders.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhp_spam |>\n  select(type, george, capitalTotal, you, charDollar)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4,601 × 5\n   type  george capitalTotal   you charDollar\n   <fct>  <dbl>        <dbl> <dbl>      <dbl>\n 1 1          0          278  1.93      0    \n 2 1          0         1028  3.47      0.18 \n 3 1          0         2259  1.36      0.184\n 4 1          0          191  3.18      0    \n 5 1          0          191  3.18      0    \n 6 1          0           54  0         0    \n 7 1          0          112  3.85      0.054\n 8 1          0           49  0         0    \n 9 1          0         1257  1.23      0.203\n10 1          0          749  1.67      0.081\n# ℹ 4,591 more rows\n```\n\n\n:::\n:::\n\n\nEach observation (row) represents an email that was sent to a person named George, and the variables (columns) include:\n\n-   `type`: is the email spam or not?\n-   `george`: percentage of words in email that are \"George\";\n-   `you`: percentage of words in email that are \"you\";\n-   `capitalTotal`: number of capitalized letters in email;\n-   `charDollar`: percentage of characters that are a dollar sign.\n\nIntuition suggests that a less personalized email (does not mention George by name) with lots of capital letters (I'M NOT SCREAMING) and dollar signs is more likely to be spam. Can we capture this in a model?\n\n## Run a \"simple\" logistic regression and plot the best-fitting S-curve\n\nTake the same code we've seen before, change `linear_reg` to `logistic_reg`, and bada bing:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntype_you_fit <- logistic_reg() |>\n  fit(type ~ you, data = hp_spam)\n  \ntidy(type_you_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic   p.value\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)   -1.01     0.0456     -22.2 4.72e-109\n2 you            0.341    0.0193      17.6 1.68e- 69\n```\n\n\n:::\n:::\n\n\nThese estimates determine the shape of the best fitting S-curve for these data. Chapter Nine in our textbook provides further discussion of how we might interpret the estimates probabilistically, but we will not concern ourselves with this at the present. For us, estimating these will simply be a means to an end of determining a model that we can use as a black box for prediction.\n\nThis code plots the S-curve. Apart from the weird and ugly `y = as.numeric(type) - 1)` part at the beginning, the only difference with plotting a straight best fit line is we changed the method (and some other things) inside `geom_smooth`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(hp_spam, aes(x = you, y = as.numeric(type) - 1)) + \n  geom_point() + \n  geom_smooth(\n    method = \"glm\", \n    se = FALSE, \n    method.args = list(family = binomial)\n  ) + \n  labs(\n    x = \"Percent of words equal to `you`\",\n    y = \"Probability the email is spam\"\n  )\n```\n\n::: {.cell-output-display}\n![](computing-logistic_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nThe logistic regression model is a special case of a *generalized linear model* (*glm*), so `method = \"glm\"` is us telling `R` that we want to do...that. But there are many generalized linear models out there, and so `method.args = list(family = binomial)` is us telling it we want the logistic one.\n\n## Run a \"multiple\" logistic regression and plot the decision boundary\n\nJust like there is nothing special about a single predictor in linear regression, there is nothing special about a single predictor in logistic regression. To add more predictors to the model, we just add them to the formula (`y ~ x`) inside `fit`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntype_you_capital_fit <- logistic_reg() |>\n  fit(type ~ you + capitalTotal, data = hp_spam)\n  \ntidy(type_you_capital_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term         estimate std.error statistic   p.value\n  <chr>           <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)  -1.50     0.0554       -27.1 2.97e-162\n2 you           0.361    0.0198        18.3 1.84e- 74\n3 capitalTotal  0.00173  0.000104      16.6 5.66e- 62\n```\n\n\n:::\n:::\n\n\nAfter doing some itchy algebra that you don't necessarily have to concern yourself with[^1], we plot a scatter plot of our two predictors, color the points according to the type of the email, and then add a straight line (`geom_abline`) to visualize the decision boundary when we threshold $\\text{Prob}(y=1)$ at 1/2:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# extract the estimates from their tidy clutches\nb0 <- tidy(type_you_capital_fit)$estimate[1]\nb1 <- tidy(type_you_capital_fit)$estimate[2]\nb2 <- tidy(type_you_capital_fit)$estimate[3]\n\n# set the threshold for classification\np_thresh <- 0.5\n\n# compute intercept and slope of decision boundary\nbd_incpt <- (log(p_thresh / (1 - p_thresh)) - b0) / b2\nbd_slp <- -b1 / b2\n\n# plot that thing\nhp_spam |>\n  mutate(type = if_else(type == 1, \"Spam\", \"Not Spam\")) |>\n  ggplot(aes(x = you, y = capitalTotal, color = type)) +\n  geom_point(alpha = 0.1) +\n  coord_cartesian(xlim = c(0, 6), ylim = c(0, 6000)) + \n  geom_abline(slope = bd_slp, intercept = bd_incpt) + \n  labs(\n    x = \"Percent of words equal to `you`\",\n    y = \"Number of capitalized letters\",\n    title = \"Is this email spam?\"\n  )\n```\n\n::: {.cell-output-display}\n![](computing-logistic_files/figure-html/plot-decision-boundary-1.png){width=672}\n:::\n:::\n\n\nIf an email has features that place it above the line, we predict that it is a spam email. If an email has features that place it below the line, we predict that it is not. As you can see, this boundary is not perfect -- there are red points above and blue points below. But nevertheless, it captures our intuitions pretty well; an email with a high fraction of \"you\" and many capital letters is more likely spam. If you keep studying statistics and machine learning, you will learn plenty of fancy methods for drawing funky, nonlinear decision boundaries that account for all sorts of contingencies.\n\nSomething to play around with: adjust the threshold `p_thresh` and see how it changes the decision boundary.\n\n[^1]: This is not hard to derive. Set $(1+e^{-(\\beta_0+\\beta_1x_1+\\beta_2x_2)})^{-1}$ equal to your chosen threshold $p^\\star$, and then solve for $x_2$ as a function of $x_1$. You'll get a line.\n\n## Make a prediction when a new email arrives\n\nThe scatterplot with the colored points and the linear decision boundary is cute, but if we have more than two predictors, this stuff becomes difficult or impossible to visualize. Fortunately, we do not have to eyeball a picture in order to use this machinery to make decisions.\n\nIf we get a new email where the frequency of you is 5% and there are 2,500 capital letters, what is the probability that this email is spam?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew_email <- tibble(\n  you = 5,\n  capitalTotal = 2500\n)\n\npredict(type_you_capital_fit, new_data = new_email, type = \"prob\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  .pred_0 .pred_1\n    <dbl>   <dbl>\n1 0.00963   0.990\n```\n\n\n:::\n:::\n\n\nAccording to our model, the probability of this email being spam is 99%, which is above any normal threshold we might choose. Send it to the trash!\n",
    "supporting": [
      "computing-logistic_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}