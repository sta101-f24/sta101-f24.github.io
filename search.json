[
  {
    "objectID": "course-grading.html",
    "href": "course-grading.html",
    "title": "Assignments and grading",
    "section": "",
    "text": "The final course grade will be calculated as follows:\nThe final letter grade will be determined based on the following thresholds, which will not change:",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "course-grading.html#labs",
    "href": "course-grading.html#labs",
    "title": "Assignments and grading",
    "section": "Labs",
    "text": "Labs\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios. Labs will focus on both computation and conceptualization. Lab assignments will be completed using Quarto and submitted as as a PDF for grading in Gradescope.\n\n\n\n\n\n\nNote\n\n\n\nYour lowest lab score will be dropped.",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "course-grading.html#exams",
    "href": "course-grading.html#exams",
    "title": "Assignments and grading",
    "section": "Exams",
    "text": "Exams\nThere will be two exams. Each exam will be comprised of two components:\n\nIn class: 75 minute in-class exam. This exam is closed book, however you are allowed to use one sheet of notes (“cheat sheet”) to the midterm and the final. This sheet must be no larger than 8.5 inches x 11 inches, and must be prepared by you. You may use both sides of the sheet. (70% of the grade)\nTake home: Following the in class exam, you’ll have 48 hours to complete the take home portion of your exam. The take home portion will follow from the in class exam and focus on the analysis of a dataset introduced in the take home exam. (30% of the grade)\n\nThrough these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. Each exam will include small analyses and computational tasks related to the content in application exercises and labs. More details about the content and structure of the exams will be discussed during the semester.\nSee the course schedule for dates and times of the exams. Exam dates cannot be changed and no make-up exams will be given. If you can’t take the exams on these dates, you should drop this class.",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "course-grading.html#final-project",
    "href": "course-grading.html#final-project",
    "title": "Assignments and grading",
    "section": "Final project",
    "text": "Final project\nThe course ends with a final project where you will explore a question and data set of your own. More details about the projects will be provided during the semester. The project will be completed in teams, and your final submission will consist of a written report and a five minute video presentation of your work. All team members are expected to contribute equally to the completion of each project and you will be asked to evaluate your team members. Failure to adequately contribute to an assignment will result in a penalty to your mark relative to the team’s overall mark.\nSee the course schedule for dates and times of project deadlines. Project deadlines cannot be changed.",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "computing/computing-logistic.html",
    "href": "computing/computing-logistic.html",
    "title": "Logistic regression",
    "section": "",
    "text": "The logistic regression model uses a set of predictors (\\(x_1\\), \\(x_2\\), …, \\(x_p\\)) to model the probability that a binary response \\(y\\) is equal to one:\n\\[\n\\text{Prob}(y=1)=\\frac{1}{1+e^{-(\\beta_0+\\beta_1x_1+...+\\beta_px_p)}}.\n\\]\nThis primer leads you down the path of least resistance to fitting this model, plotting the best-fitting S-curve in the single-predictor case, plotting the decision boundary in the bivariate case, and generating predictions.",
    "crumbs": [
      "Computing primers",
      "Logistic regression"
    ]
  },
  {
    "objectID": "computing/computing-logistic.html#setup",
    "href": "computing/computing-logistic.html#setup",
    "title": "Logistic regression",
    "section": "Setup",
    "text": "Setup\nThe commands for working with logistic regressions are in the tidymodels package, so load that:\n\nlibrary(tidyverse) \nlibrary(tidymodels) \n\nNext, we need something to model, so let us load in a data set. We will consider this data set from Hewlett-Packard on spam emails:\n\nhp_spam &lt;- read_csv(\"hp-spam.csv\")\n\nhp_spam &lt;- hp_spam |&gt;\n  mutate(type = as.factor(type))\n\n\n\n\n\n\n\nNote\n\n\n\nBe prepared to adjust the file path to match how you have organized your files and folders.\n\n\n\nhp_spam |&gt;\n  select(type, george, capitalTotal, you, charDollar)\n\n# A tibble: 4,601 × 5\n   type  george capitalTotal   you charDollar\n   &lt;fct&gt;  &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1 1          0          278  1.93      0    \n 2 1          0         1028  3.47      0.18 \n 3 1          0         2259  1.36      0.184\n 4 1          0          191  3.18      0    \n 5 1          0          191  3.18      0    \n 6 1          0           54  0         0    \n 7 1          0          112  3.85      0.054\n 8 1          0           49  0         0    \n 9 1          0         1257  1.23      0.203\n10 1          0          749  1.67      0.081\n# ℹ 4,591 more rows\n\n\nEach observation (row) represents an email that was sent to a person named George, and the variables (columns) include:\n\ntype: is the email spam or not?\ngeorge: percentage of words in email that are “George”;\nyou: percentage of words in email that are “you”;\ncapitalTotal: number of capitalized letters in email;\ncharDollar: percentage of characters that are a dollar sign.\n\nIntuition suggests that a less personalized email (does not mention George by name) with lots of capital letters (I’M NOT SCREAMING) and dollar signs is more likely to be spam. Can we capture this in a model?",
    "crumbs": [
      "Computing primers",
      "Logistic regression"
    ]
  },
  {
    "objectID": "computing/computing-logistic.html#run-a-simple-logistic-regression-and-plot-the-best-fitting-s-curve",
    "href": "computing/computing-logistic.html#run-a-simple-logistic-regression-and-plot-the-best-fitting-s-curve",
    "title": "Logistic regression",
    "section": "Run a “simple” logistic regression and plot the best-fitting S-curve",
    "text": "Run a “simple” logistic regression and plot the best-fitting S-curve\nTake the same code we’ve seen before, change linear_reg to logistic_reg, and bada bing:\n\ntype_you_fit &lt;- logistic_reg() |&gt;\n  fit(type ~ you, data = hp_spam)\n  \ntidy(type_you_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)   -1.01     0.0456     -22.2 4.72e-109\n2 you            0.341    0.0193      17.6 1.68e- 69\n\n\nThese estimates determine the shape of the best fitting S-curve for these data. Chapter Nine in our textbook provides further discussion of how we might interpret the estimates probabilistically, but we will not concern ourselves with this at the present. For us, estimating these will simply be a means to an end of determining a model that we can use as a black box for prediction.\nThis code plots the S-curve. Apart from the weird and ugly y = as.numeric(type) - 1) part at the beginning, the only difference with plotting a straight best fit line is we changed the method (and some other things) inside geom_smooth:\n\nggplot(hp_spam, aes(x = you, y = as.numeric(type) - 1)) + \n  geom_point() + \n  geom_smooth(\n    method = \"glm\", \n    se = FALSE, \n    method.args = list(family = binomial)\n  ) + \n  labs(\n    x = \"Percent of words equal to `you`\",\n    y = \"Probability the email is spam\"\n  )\n\n\n\n\n\n\n\n\nThe logistic regression model is a special case of a generalized linear model (glm), so method = \"glm\" is us telling R that we want to do…that. But there are many generalized linear models out there, and so method.args = list(family = binomial) is us telling it we want the logistic one.",
    "crumbs": [
      "Computing primers",
      "Logistic regression"
    ]
  },
  {
    "objectID": "computing/computing-logistic.html#run-a-multiple-logistic-regression-and-plot-the-decision-boundary",
    "href": "computing/computing-logistic.html#run-a-multiple-logistic-regression-and-plot-the-decision-boundary",
    "title": "Logistic regression",
    "section": "Run a “multiple” logistic regression and plot the decision boundary",
    "text": "Run a “multiple” logistic regression and plot the decision boundary\nJust like there is nothing special about a single predictor in linear regression, there is nothing special about a single predictor in logistic regression. To add more predictors to the model, we just add them to the formula (y ~ x) inside fit:\n\ntype_you_capital_fit &lt;- logistic_reg() |&gt;\n  fit(type ~ you + capitalTotal, data = hp_spam)\n  \ntidy(type_you_capital_fit)\n\n# A tibble: 3 × 5\n  term         estimate std.error statistic   p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)  -1.50     0.0554       -27.1 2.97e-162\n2 you           0.361    0.0198        18.3 1.84e- 74\n3 capitalTotal  0.00173  0.000104      16.6 5.66e- 62\n\n\nAfter doing some itchy algebra that you don’t necessarily have to concern yourself with1, we plot a scatter plot of our two predictors, color the points according to the type of the email, and then add a straight line (geom_abline) to visualize the decision boundary when we threshold \\(\\text{Prob}(y=1)\\) at 1/2:\n\n# extract the estimates from their tidy clutches\nb0 &lt;- tidy(type_you_capital_fit)$estimate[1]\nb1 &lt;- tidy(type_you_capital_fit)$estimate[2]\nb2 &lt;- tidy(type_you_capital_fit)$estimate[3]\n\n# set the threshold for classification\np_thresh &lt;- 0.5\n\n# compute intercept and slope of decision boundary\nbd_incpt &lt;- (log(p_thresh / (1 - p_thresh)) - b0) / b2\nbd_slp &lt;- -b1 / b2\n\n# plot that thing\nhp_spam |&gt;\n  mutate(type = if_else(type == 1, \"Spam\", \"Not Spam\")) |&gt;\n  ggplot(aes(x = you, y = capitalTotal, color = type)) +\n  geom_point(alpha = 0.1) +\n  coord_cartesian(xlim = c(0, 6), ylim = c(0, 6000)) + \n  geom_abline(slope = bd_slp, intercept = bd_incpt) + \n  labs(\n    x = \"Percent of words equal to `you`\",\n    y = \"Number of capitalized letters\",\n    title = \"Is this email spam?\"\n  )\n\n\n\n\n\n\n\n\nIf an email has features that place it above the line, we predict that it is a spam email. If an email have features that place it below the line, we predict that it is not. As you can see, this boundary is not perfect – there are red points above and blue points below. But nevertheless, it captures our intuitions pretty well; an email with a high fraction of “you” and many capital letters is more likely spam. If you keep studying statistics and machine learning, you will learn plenty of fancy methods for drawing funky, nonlinear decision boundaries that account for all sorts of contingencies.\nSomething to play around with: adjust the threshold p_thresh and see how it changes the decision boundary.",
    "crumbs": [
      "Computing primers",
      "Logistic regression"
    ]
  },
  {
    "objectID": "computing/computing-logistic.html#make-a-prediction-when-a-new-email-arrives",
    "href": "computing/computing-logistic.html#make-a-prediction-when-a-new-email-arrives",
    "title": "Logistic regression",
    "section": "Make a prediction when a new email arrives",
    "text": "Make a prediction when a new email arrives\nThe scatterplot with the colored points and the linear decision boundary is cute, but if we have more than two predictors, this stuff becomes difficult or impossible to visualize. Fortunately, we do not have to eyeball a picture in order to use this machinery to make decisions.\nIf we get a new email where the frequency of you is 5% and there are 2,500 capital letters, what is the probability that this email is spam?\n\nnew_email &lt;- tibble(\n  you = 5,\n  capitalTotal = 2500\n)\n\npredict(type_you_capital_fit, new_data = new_email, type = \"prob\")\n\n# A tibble: 1 × 2\n  .pred_0 .pred_1\n    &lt;dbl&gt;   &lt;dbl&gt;\n1 0.00963   0.990\n\n\nAccording to our model, the probability is pretty much 100%, which is above any normal threshold we might choose. Send it to the trash!",
    "crumbs": [
      "Computing primers",
      "Logistic regression"
    ]
  },
  {
    "objectID": "computing/computing-logistic.html#footnotes",
    "href": "computing/computing-logistic.html#footnotes",
    "title": "Logistic regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is not hard to derive. Set \\((1+e^{-(\\beta_0+\\beta_1x_1+\\beta_2x_2)})^{-1}\\) equal to your chosen threshold \\(p^\\star\\), and then solve for \\(x_2\\) as a function of \\(x_1\\). You’ll get a line.↩︎",
    "crumbs": [
      "Computing primers",
      "Logistic regression"
    ]
  },
  {
    "objectID": "computing/computing-cheatsheets.html",
    "href": "computing/computing-cheatsheets.html",
    "title": "R cheatsheets",
    "section": "",
    "text": "The following cheatsheets come from https://posit.co/resources/cheatsheets. We haven’t covered every function and functionality listed on them, but you might still find them useful as references.",
    "crumbs": [
      "Computing primers",
      "Cheatsheets"
    ]
  },
  {
    "objectID": "computing/computing-access.html",
    "href": "computing/computing-access.html",
    "title": "Access RStudio",
    "section": "",
    "text": "In this class, you will always and everywhere access RStudio through the Duke Container Manager. This ensures that all of us are using the same version of all the software. If this were not the case, unexpected and difficult to diagnose/resolve coding incompatibilities could arise when you seek help from the teaching team or collaborate with your project partners. Nobody needs that, so please stick to the containers. Here is how you get in:\n\nGo here: https://cmgr.oit.duke.edu/containers. You may have to log in with your NetID at some point;\n(The first time you do this, you look for STA101 under “Reservations available” on the righthand side, and click “reserve STA101”. After you do that once, STA101 will appear under “My reservations” on the lefthand side forever more)\nClick STA101 under “My reservations”;\nLogin;\nStart. It may take a while, but then RStudio should launch in your browser.",
    "crumbs": [
      "Computing primers",
      "Accessing RStudio"
    ]
  },
  {
    "objectID": "computing/computing-file-paths.html",
    "href": "computing/computing-file-paths.html",
    "title": "File paths and reading in data",
    "section": "",
    "text": "Hopefully you have followed the advice here and organized your RStudio files into folders like this:\n\nAnd so, for example, when you go inside your Lecture 2 folder, it looks like this:\n\nThis is great for organization, but it causes a small problem. A command like this may not work:\n\nlibrary(tidyverse)\n\nflint &lt;- read_csv(\"flint.csv\")\n\nWhy not? Because the file flint.csv is inside one of your handy dandy folders, but you have not told read_csv which folder, and so it cannot find it. To fix this, change the code to this:\n\nflint &lt;- read_csv(\"~/lecture-2/flint.csv\")\n\nThe string \"~/lecture-2/flint.csv\" is called a file path and it tells the function read_csv the path of folders it has to search down in order to find the file flint.csv. If you have chosen to give your folders slightly different names like Lecture 2 or Lecture-2 or lecture 2 or john-sucks, that’s fine. Just make sure you make the appropriate change when you run the command. So flint &lt;- read_csv(\"~/Lecture 2/flint.csv\") or flint &lt;- read_csv(\"~/john-sucks/flint.csv\") , etc.",
    "crumbs": [
      "Computing primers",
      "Adjusting file paths"
    ]
  },
  {
    "objectID": "computing/computing-regression.html",
    "href": "computing/computing-regression.html",
    "title": "Simple linear regression",
    "section": "",
    "text": "The simple linear regression model relates a predictor \\(x\\) to a response \\(y\\) via a linear function with error:\n\\[\ny=\\beta_0+\\beta_1x+\\varepsilon.\n\\]\nThis primer leads you down the path of least resistance to fitting this model, creating a scatterplot with the best fit line added to it, and producing a table with the coefficient estimates (\\(\\hat{\\beta}_0,\\,\\hat{\\beta}_1\\)).",
    "crumbs": [
      "Computing primers",
      "Simple linear regression"
    ]
  },
  {
    "objectID": "computing/computing-regression.html#setup",
    "href": "computing/computing-regression.html#setup",
    "title": "Simple linear regression",
    "section": "Setup",
    "text": "Setup\nThe commands for working with linear regressions are in the tidymodels package, so load that:\n\nlibrary(tidyverse) \nlibrary(tidymodels) \n\nNext, we need something to model, so let us load in a data set. We will consider this data set on the stock price of Microsoft and Apple (introduced during Lecture 6 on 9/12/2024):\n\nstocks &lt;- read_csv(\"stocks.csv\")\n\n\n\n\n\n\n\nNote\n\n\n\nRecalling the information here, be prepared to adjust the file path to match how you have organized your files and folders.\n\n\nTo keep things simple, we’ll work with a subset of the data, stock prices in January 2020.\n\nstocks_jan2020 &lt;- stocks |&gt;\n  filter(month(date) == 1 & year(date) == 2020)",
    "crumbs": [
      "Computing primers",
      "Simple linear regression"
    ]
  },
  {
    "objectID": "computing/computing-regression.html#plotting-the-least-squares-regression-line-line-of-best-fit",
    "href": "computing/computing-regression.html#plotting-the-least-squares-regression-line-line-of-best-fit",
    "title": "Simple linear regression",
    "section": "Plotting the least squares regression line (“line of best fit”)",
    "text": "Plotting the least squares regression line (“line of best fit”)\nThis chunk of code creates a scatter plot of the Microsoft and Apple opening stock prices on the various trading days of January 2020, and it adds the line of best fit:\n\nggplot(stocks_jan2020, aes(x = MSFT.Open, y = AAPL.Open)) +\n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(\n    title = \"Daily stock price data\",\n    subtitle = \"January 2020\",\n    x = \"Microsoft opening price\",\n    y = \"Apple opening price\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nSo, all we have to do is add a new geom_WHAT layer to a scatterplot to add the line. This is what geom_smooth is doing. If you set se = TRUE, you get the band indicating the margin of error. Try it out!",
    "crumbs": [
      "Computing primers",
      "Simple linear regression"
    ]
  },
  {
    "objectID": "computing/computing-regression.html#what-are-the-coefficient-estimates",
    "href": "computing/computing-regression.html#what-are-the-coefficient-estimates",
    "title": "Simple linear regression",
    "section": "What are the coefficient estimates?",
    "text": "What are the coefficient estimates?\nThis code will give you a table with the estimates:\n\nstock_fit &lt;- linear_reg() |&gt;\n  fit(AAPL.Open ~ MSFT.Open, data = stocks_jan2020)\n\ntidy(stock_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic      p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept)    3.31     8.87       0.373 0.713       \n2 MSFT.Open      0.454    0.0541     8.40  0.0000000808\n\n\nThere is a lot going on in that table, and we will explore some of it later, but focus on the first column for now. This column gives the estimates \\(\\hat{\\beta}_0,\\,\\hat{\\beta}_1\\). The first row has the estimate \\(\\hat{\\beta}_0\\) of the intercept, and the second row has the estimate \\(\\hat{\\beta}_1\\) of the slope. So the fitted model here is: \\[\n\\begin{align*}\n\\widehat{\\text{AAPL}}&=\\hat{\\beta}_0+\\hat{\\beta}_1{\\text{MSFT}}\\\\\n&\\approx3.31+0.45\\cdot{\\text{MSFT}}.\n\\end{align*}\n\\] So\n\n3.31 is the price you would predict for Apple stock if you knew Microsoft stock was opening at $0;\n0.45 is the price increase in Apple stock that you would predict if Microsoft stock became more expensive by $1 (remember, slope = rise/run, so \\(\\Delta\\text{AAPL}/\\Delta\\text{MSFT}\\) in this case).\n\nThe syntax in the fit commands is like fit(y ~ x). So the variable to the left of the ~ will be treated as the response variable (\\(y\\)), and the variable to the right will be treated as the predictor (\\(x\\)).",
    "crumbs": [
      "Computing primers",
      "Simple linear regression"
    ]
  },
  {
    "objectID": "project/project-2.html",
    "href": "project/project-2.html",
    "title": "Project 2",
    "section": "",
    "text": "Team assignments are posted at https://canvas.duke.edu/courses/4625/files?preview=549493.\nThe deliverable for this project (what you will turn in) is a written report and a pre-recorded presentation. See below for more details."
  },
  {
    "objectID": "project/project-2.html#criteria-for-datasets",
    "href": "project/project-2.html#criteria-for-datasets",
    "title": "Project 2",
    "section": "Criteria for datasets",
    "text": "Criteria for datasets\nThe data sets should meet the following criteria:\n\nAt least 100 observations\nAt least 5 columns\nAt least 4 of the columns must be useful and unique explanatory variables.\n\nIdentifier variables such as “name”, “social security number”, etc. are not useful explanatory variables.\nIf you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique explanatory variables.\n\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\n\n\n\n\n\n\nTip\n\n\n\nPlease ask a member of the teaching team if you’re unsure whether your data set meets the criteria.\n\n\nIf you set your hearts on a dataset that has fewer observations or variables than what’s suggested here, that might still be ok; use these numbers as guidance for a successful proposal, not as minimum requirements."
  },
  {
    "objectID": "project/project-2.html#resources",
    "href": "project/project-2.html#resources",
    "title": "Project 2",
    "section": "Resources for datasets",
    "text": "Resources for datasets\nYou can find data wherever you like, but here are some recommendations to get you started. You shouldn’t feel constrained to datasets that are already in a tidy format, you can start with data that needs cleaning and tidying, scrape data off the web, or collect your own data.\n\nAwesome public datasets\nBikeshare data portal\nCDC\nData.gov\nData is Plural\nDurham Open Data Portal\nEdinburgh Open Data\nElection Studies\nEuropean Statistics\nCORGIS: The Collection of Really Great, Interesting, Situated Datasets\nGeneral Social Survey\nGoogle Dataset Search\nHarvard Dataverse\nInternational Monetary Fund\nIPUMS survey data from around the world\nLos Angeles Open Data\nNational Crime Victimization Survey\nNHS Scotland Open Data\nNYC OpenData\nOpen access to Scotland’s official statistics\nPew Research\nPRISM Data Archive Project\nStatistics Canada\nThe National Bureau of Economic Research\nTidyTuesday\nUCI Machine Learning Repository\nUK Government Data\nUNICEF Data\nUnited Nations Data\nUnited Nations Statistics Division\nUS Census Data\nUS Government Data\nWorld Bank Data\nYouth Risk Behavior Surveillance System (YRBSS)"
  },
  {
    "objectID": "project/project-2.html#proposal-conversation-grading",
    "href": "project/project-2.html#proposal-conversation-grading",
    "title": "Project 2",
    "section": "Proposal conversation grading",
    "text": "Proposal conversation grading\nEach component will be graded as follows:\n\nMeets expectations (full credit): All team members are present and contribute to the conversation. The team has a dataset and research question identified. There is a plan for completing the project as envisioned.\nClose to expectations (half credit): Not all team members are present and contribute to the conversation (without any excused absences). The team does not have a dataset and/or research question identified. The plan for completing the project as envisioned is not well designed.\nDoes not meet expectations (no credit): Not all team members are present and contribute to the conversation (without any excused absences). The team does not have a dataset or research question identified. There is no plan for completing the project as envisioned.\n\nEven if you earn full credit, it may not mean that your proposal is perfect."
  },
  {
    "objectID": "project/project-2.html#components",
    "href": "project/project-2.html#components",
    "title": "Project 2",
    "section": "Components",
    "text": "Components\nYou should include, at a minimum, the following sections in your report.\n\nIntroduction (7 pts)\nThe introduction provides motivation and context for your research.\nTo begin, introduce the data set in a few short sentences. Next, create a code book (aka a “data dictionary”) of the variables in the data set. Although a code book is provided above, you should include one in your report as well so that your report is self-contained. Specifically, only include in your report a code book of the variables that you use.\nComplete the introduction by providing a concise, clear statement of your research question and hypotheses. Be sure to motivate why the research question is interesting/useful.\nExample research question and hypotheses (if we were predicting penguin weights instead of baby weights):\nCan we predict body mass with bill depth? We hypothesize that penguins with deeper bills will also have more mass.\n\n\nMethodology (15 pts)\nHere you should introduce any statistical methods you use and describe why you choose the methods you do to answer your question. You might also include any preliminary summary statistics or figures you use to explore the data.\n\n\nResults (15 pts)\nPlace figure(s) here to illustrate the main results from your analysis. 1 beautiful figure is worth more than several poorly formatted figures. You must have at least 1 figure.\nProvide only the main results from your analysis. The goal is not to do an exhaustive data analysis (calculate every possible statistic and create every possible model for all variables). Rather, you should demonstrate that you are proficient at asking meaningful questions and answering them using data, that you are skilled in writing about and interpreting results, and that you can accomplish these tasks using R. More is not better.\n\n\nDiscussion (6 pts)\nThis section is a conclusion and discussion. You should\n\nSummarize your main finding in a sentence or two.\nDiscuss your finding and why it is useful (put in the context of your motivation from the introduction).\nCritique your own analyses and include a brief paragraph on what you would do differently if you were able to start the project over.\n\n\n\nAppendix (2 pts)\nList a brief (1 or 2 sentence) summary of the relative contributions of each team member, e.g., “Aang built the models, Katara implemented them in R, and Sokka wrote the introduction and discussion.”\n\n\n\n\n\n\nImportant\n\n\n\nAll team members should be comfortable describing all aspects of the project and understanding all code.\n\n\n\n\nFormatting (5 pts)\nYour project should be professionally formatted. For example, this means labeling graphs and figures, turning off code chunks, using proper citations and cross-references, and following typical style guidelines."
  },
  {
    "objectID": "project/project-2.html#submission",
    "href": "project/project-2.html#submission",
    "title": "Project 2",
    "section": "Submission",
    "text": "Submission\n\nSelect one team member to upload the team’s PDF submission to Gradescope.\nBe sure to select every team member’s name in Gradescope.\nAssociate all pages with “Full report”."
  },
  {
    "objectID": "project/project-2.html#slides",
    "href": "project/project-2.html#slides",
    "title": "Project 2",
    "section": "Slides",
    "text": "Slides\nFor your presentation, you must create presentation slides that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and provide some conclusions. These slides should serve as a brief visual accompaniment to your write-up and will be graded for content and quality.\nHere is a suggested outline as you think through the slides; you do not have to use this exact format for the slide deck.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3 - 4: Highlights from exploratory data analysis\nSlide 4 - 5: Highlights from inference and/or modeling\nSlide 6: Conclusions + critique/shortcomings\n\nYou can create your slides with any software you like (Keynote, PowerPoint, Google Slides, etc.). We recommend choosing an option that’s easy to collaborate with, e.g., Google Slides.\n\n\n\n\n\n\nNote\n\n\n\nYou can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!"
  },
  {
    "objectID": "project/project-2.html#recording",
    "href": "project/project-2.html#recording",
    "title": "Project 2",
    "section": "Recording",
    "text": "Recording\nPresentations will be submitted as a pre-recorded video by the due date.\nFor recording, you may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\nOnce your video is ready, upload the video to Warpwire or another video platform (e.g., YouTube), then add a link to your video at https://docs.google.com/spreadsheets/d/1mGLkIqhtUEylFR4Ovlpuysv4xWCz6L4FdWqFGmjUKPw/edit?usp=sharing.\nTo upload your video to Warpwire:\n\nClick the Warpwire tab in the course Canvas site.\nClick the “+” and select “Upload files”.\nLocate the video on your computer and click to upload.\nOnce you’ve uploaded the video to Warpwire, click to share the video and copy the video’s URL. You will need this when you post the video in the Project 2 spreadsheet."
  },
  {
    "objectID": "project/project-2.html#grading-summary",
    "href": "project/project-2.html#grading-summary",
    "title": "Project 2",
    "section": "Grading summary",
    "text": "Grading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort."
  },
  {
    "objectID": "project/project-2.html#late-work-policy",
    "href": "project/project-2.html#late-work-policy",
    "title": "Project 2",
    "section": "Late work policy",
    "text": "Late work policy\nBe sure to turn in your work early to avoid any technological mishaps.\n\n\n\n\n\n\nWarning\n\n\n\nThere is no late work accepted on this project."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 101 Data Analysis and Statistical Inference",
    "section": "",
    "text": "Below is a prospective outline for the course, but things may change with advanced notice:\n\n\n\n\n\n\n\n\nWEEK\nDATE\nTOPIC\nPREPARE\nMATERIALS\nDUE\n\n\n\n\n1\nTue, Aug 27\nWelcome!\n\n\n\n\n\n\n\n\n\n\nThu, Aug 29\nGetting started\n📖 ims: Ch 1  💻 tutorial: 01-data-01\nlecture-2  (filled-in)\nGetting to know you @ 3PM\n\n\n\n\nFri, Aug 30\nLab 1: Hello R!\n\n\nlab-1\n\n\n\n\n2\nTue, Sep 3\nNumerical data and study design\n📖 ims: Ch 2  💻 tutorial: 01-data-02  💻 tutorial: 01-data-03\nslides lecture-3  (filled-in)\n\n\n\n\n\n\nThu, Sep 5\nCategorical data\n📖 ims: Ch 4  💻 tutorial: 02-explore-01\nlecture-4  (filled-in)\n\n\n\n\n\n\nFri, Sep 6\nLab 2: data\n📖 ims: Ch 3  💻 tutorial: 01-data-04\nlab-2\nLab 1 @ 8AM\n\n\n3\nTue, Sep 10\nCheckpoint: exploratory data analysis\n📖 ims: Ch 5  💻 tutorial: 02-explore-02\nslides\n\n\n\n\n\n\nThu, Sep 12\nSimple linear regression\n📖 ims: Ch 7  💻 tutorial: 03-model-01  💻 tutorial: 03-model-02\nslides  Play around!  Play around some more!  Primer\n\n\n\n\n\n\nFri, Sep 13\nLab 3: exploratory data analysis\n📖 ims: Ch 6  💻 tutorial: 02-explore-03\nlab-3\nLab 2 @ 8AM\n\n\n4\nTue, Sep 17\nMultiple linear regression\n📖 ims: Ch 8.1 - 8.2\nslides  Primer\n\n\n\n\n\n\nThu, Sep 19\n\\(R^2\\)\n📖 ims: Ch 8.3 - 8.4\nslides  Primer\n\n\n\n\n\n\nFri, Sep 20\nLab 4: regression\n\n\nlab-4\nLab 3 @ 8AM\n\n\n5\nTue, Sep 24\nModel selection\n📖 ims: Ch 8.4 - 8.5\n\n\n\n\n\n\n\n\nThu, Sep 26\nModel selection\n📖 ims: Ch 7  📖 ims: Ch 8\nslides\n\n\n\n\n\n\nFri, Sep 27\nLab: exam review\n\n\n\n\nLab 4 @ 8AM\n\n\n6\nTue, Oct 1\nIn-class Exam 1\nPractice exams (Canvas)  Make your cheet sheet!\n\n\n\n\n\n\n\n\nThu, Oct 3\nNo lecture\n\n\n\n\nTake-home Exam 1 @ 5PM\n\n\n\n\nFri, Oct 4\nNo lab\n\n\n\n\n\n\n\n\n7\nTue, Oct 8\nLogistic Regression 1\n📖 ims: Ch 9\nslides\n\n\n\n\n\n\nThu, Oct 10\nLogistic Regression 2 and Ethics\n📖 ims: Ch 9\nslides  Primer\n\n\n\n\n\n\nFri, Oct 11\nNo lab\n\n\n\n\n\n\n\n\n8\nTue, Oct 15\nNo lecture\n\n\n\n\n\n\n\n\n\n\nThu, Oct 17\nHypothesis testing\nTo be posted\nTo be posted\n\n\n\n\n\n\nFri, Oct 18\nLab 5: hypothesis testing\nTo be posted\nTo be posted\n\n\n\n\n9\nTue, Oct 22\nConfidence intervals\nTo be posted\nTo be posted\n\n\n\n\n\n\nThu, Oct 24\nDecision errors\nTo be posted\nTo be posted\n\n\n\n\n\n\nFri, Oct 25\nLab 6: foundations\nTo be posted\nTo be posted\nLab 5 @ 8AM\n\n\n10\nTue, Oct 29\nInference with mathematical models\nTo be posted\nTo be posted\n\n\n\n\n\n\nThu, Oct 31\nInference for one proportion\nTo be posted\nTo be posted\n\n\n\n\n\n\nFri, Nov 1\nLab 7: inference for proportions\nTo be posted\nTo be posted\nLab 6 @ 8AM\n\n\n11\nTue, Nov 5\nComparing two proportions\nTo be posted\nTo be posted\n\n\n\n\n\n\nThu, Nov 7\nInference for two-way tables\nTo be posted\nTo be posted\n\n\n\n\n\n\nFri, Nov 8\nLab: exam review\n\n\nTo be posted\nLab 7 @ 8AM\n\n\n12\nTue, Nov 12\nIn-class Exam 2\n\n\nTo be posted\n\n\n\n\n\n\nThu, Nov 14\nNo lecture\n\n\nTo be posted\nTake-home Exam 2 @ 5PM\n\n\n\n\nFri, Nov 15\nNo lab\n\n\nTo be posted\n\n\n\n\n13\nTue, Nov 19\nProportions overview\nTo be posted\nTo be posted\n\n\n\n\n\n\nThu, Nov 21\nInference for one mean\nTo be posted\nTo be posted\n\n\n\n\n\n\nFri, Nov 22\nLab: project proposal\n\n\n\n\nProject proposal @ 5PM\n\n\n14\nTue, Nov 26\nInference for two means\nTo be posted\nTo be posted\n\n\n\n\n\n\nThu, Nov 28\nNo lecture\n\n\n\n\n\n\n\n\n\n\nFri, Nov 29\nNo lab\n\n\n\n\n\n\n\n\n15\nTue, Dec 3\nANOVA\nTo be posted\nTo be posted\n\n\n\n\n\n\nThu, Dec 5\n\n\nTo be posted\nTo be posted\n\n\n\n\n\n\nFri, Dec 6\nNo lab\n\n\n\n\nPeer review @ 5PM\n\n\n16\nSun, Dec 15\nNo meeting\n\n\n\n\nFinal project @ 2PM",
    "crumbs": [
      "Syllabus",
      "Schedule"
    ]
  },
  {
    "objectID": "course-resources.html",
    "href": "course-resources.html",
    "title": "University resources",
    "section": "",
    "text": "If you are having difficulty with the costs associated with this course (obtaining a laptop, mostly), here are some resources:\n\nKarsh Office of Undergraduate Support: Regardless of your aid package, Karsh offers loans and resources for connecting students with campus programs that might help alleviate course costs.\nDukeLIFE: The Course Material Assistance program offers assistance for eligible students, including through the LIFE Loaner Laptop Program. Students who are eligible for DukeLIFE benefits are notified before the start of the semester; program resources are limited.\nDuke Link: They have a small supply of laptops that can be rented out for five days at a time.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "course-resources.html#course-costs",
    "href": "course-resources.html#course-costs",
    "title": "University resources",
    "section": "",
    "text": "If you are having difficulty with the costs associated with this course (obtaining a laptop, mostly), here are some resources:\n\nKarsh Office of Undergraduate Support: Regardless of your aid package, Karsh offers loans and resources for connecting students with campus programs that might help alleviate course costs.\nDukeLIFE: The Course Material Assistance program offers assistance for eligible students, including through the LIFE Loaner Laptop Program. Students who are eligible for DukeLIFE benefits are notified before the start of the semester; program resources are limited.\nDuke Link: They have a small supply of laptops that can be rented out for five days at a time.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "course-resources.html#tech-support",
    "href": "course-resources.html#tech-support",
    "title": "University resources",
    "section": "Tech support",
    "text": "Tech support\nContact the Duke OIT Service Desk at oit.duke.edu/help.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "course-resources.html#academic-support",
    "href": "course-resources.html#academic-support",
    "title": "University resources",
    "section": "Academic support",
    "text": "Academic support\nThere are times you may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "course-resources.html#accessibility",
    "href": "course-resources.html#accessibility",
    "title": "University resources",
    "section": "Accessibility",
    "text": "Accessibility\nIf any portion of the course is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students can engage with their courses and related assignments. Students should contact the SDAO to request or update accommodations under these circumstances.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "course-resources.html#mental-health-and-well-being",
    "href": "course-resources.html#mental-health-and-well-being",
    "title": "University resources",
    "section": "Mental health and well-being",
    "text": "Mental health and well-being\nDuke is committed to holistic student well-being, including mental, emotional, and physical health. The university offers resources to help students manage daily stress, encourage intentional self-care, and access just-in-time support. If you find you need support, your mental and/or emotional health concerns are impacting your day-to-day activities and your academic performance, or you need someone to talk to, the resources below are available to you:\n\nDukeReach: DukeReach provides comprehensive outreach services to support students in managing all aspects of well-being, including referrals and follow-up services for students who are experiencing significant challenges related to mental health, physical health, social adjustment, and/or a variety of other stressors. You can reach the DukeReach team at dukereach@duke.edu.\nCounseling and Psychological Services (CAPS): CAPS services include individual and group counseling services, psychiatric services, and workshops. CAPS also provides referrals to off-campus resources for specialized care. You can reach CAPS at (919) 660-1000.\nTimelyCare1: TimelyCare is an online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling.\nBC Fellows for Healthy Relationship: The BC Fellows meet with students individually and in groups, supporting the development of healthy relationships and building meaningful community in all areas of a student’s life.\nDukeLine: Students who want to connect anonymously with a Peer Coach can text 984-230-4888 from 5 to 11 p.m. daily. DukeLine offers in-the-moment anonymous, non-emergency text support from a peer.\nDuWell: DuWell provides Moments of Mindfulness (stress management and resilience building) and meditation programming (Koru workshop) to assist students in developing a daily emotional well-being practice. All are welcome, and no experience is necessary. You can reach DuWell at (919) 681-8421.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "course-resources.html#footnotes",
    "href": "course-resources.html#footnotes",
    "title": "University resources",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFormerly known as Blue Devils Care.↩︎",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "ae/ae-07-books.html",
    "href": "ae/ae-07-books.html",
    "title": "Weights of books",
    "section": "",
    "text": "Today we’ll explore the question “How do volume and weights books relate?” and “How, if at all, does that change when we take whether the book is hardback or paperback into consideration?”"
  },
  {
    "objectID": "ae/ae-07-books.html#plot-the-best-fit-line",
    "href": "ae/ae-07-books.html#plot-the-best-fit-line",
    "title": "Weights of books",
    "section": "Plot the best fit line",
    "text": "Plot the best fit line\nVisualize the relationship between volume (on the x-axis) and weight (on the y-axis). Overlay the line of best fit. Describe the relationship between these variables.\n\nggplot(allbacks, aes(x = volume, y = weight)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(\n    x = \"Volume (cubic centimeters)\",\n    y = \"Weight (grams)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nAdd response here."
  },
  {
    "objectID": "ae/ae-07-books.html#get-the-estimated-regression-coefficients",
    "href": "ae/ae-07-books.html#get-the-estimated-regression-coefficients",
    "title": "Weights of books",
    "section": "Get the estimated regression coefficients",
    "text": "Get the estimated regression coefficients\nFit a model predicting weight from volume for these books and save it as weight_fit. Display a tidy output of the model.\n\nweight_fit &lt;- linear_reg() |&gt;\n  fit(weight ~ volume, data = allbacks)\n\ntidy(weight_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic    p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 (Intercept)  108.      88.4         1.22 0.245     \n2 volume         0.709    0.0975      7.27 0.00000626"
  },
  {
    "objectID": "ae/ae-07-books.html#plot-the-best-fit-lines",
    "href": "ae/ae-07-books.html#plot-the-best-fit-lines",
    "title": "Weights of books",
    "section": "Plot the best fit line(s)",
    "text": "Plot the best fit line(s)\nVisualize the relationship between volume (on the x-axis) and weight (on the y-axis), taking into consideration the cover type of the book. Use different colors and shapes for hardback and paperback books. Also use different colors for lines of best fit for the two types of books. In addition, add the overall line of best fit (from Exercise 1) as a gray dashed line so that you can see the difference between the lines when considering and not considering cover type.\n\nggplot(allbacks, aes(x = volume, y = weight)) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"gray\", linetype = \"dashed\") +\n  geom_point() +\n  labs(\n    x = \"Volume (cubic centimeters)\",\n    y = \"Weight (grams)\",\n    shape = \"Cover\", color = \"Cover\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "ae/ae-07-books.html#get-the-estimated-regression-coefficients-1",
    "href": "ae/ae-07-books.html#get-the-estimated-regression-coefficients-1",
    "title": "Weights of books",
    "section": "Get the estimated regression coefficients",
    "text": "Get the estimated regression coefficients\nFit a model predicting weight from volume for these books and save it as weight_cover_fit. Display a tidy output of the model.\n\nweight_cover_fit &lt;- linear_reg() |&gt;\n  fit(weight ~ volume, data = allbacks)\n\ntidy(weight_cover_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic    p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 (Intercept)  108.      88.4         1.22 0.245     \n2 volume         0.709    0.0975      7.27 0.00000626"
  },
  {
    "objectID": "ae/ae-07-books.html#prediction",
    "href": "ae/ae-07-books.html#prediction",
    "title": "Weights of books",
    "section": "Prediction",
    "text": "Prediction\nUsing the model you chose, predict the weight of a hardcover book that is 1000 cubic centimeters (that is, roughly 25 centimeters in length, 20 centimeters in width, and 2 centimeters in height/thickness).\n\nnew_book &lt;- tibble(\n  cover = \"hb\",\n  volume = 1000\n)\n\npredict(weight_cover_fit, new_data = new_book)\n\n# A tibble: 1 × 1\n  .pred\n  &lt;dbl&gt;\n1  816."
  },
  {
    "objectID": "ae/ae-02-flint.html",
    "href": "ae/ae-02-flint.html",
    "title": "Exploring Flint Michigan’s water data",
    "section": "",
    "text": "By the end of this application exercise you will\n\nmeet the computational toolkit for the course\ndefine and compute various statistics\nbegin to gain familiarity with making data visualizations with ggplot()\n\nWe will do this using water lead content data from Flint, MI. The following paragraph will be useful in evaluating the lead amount values we’ll see in the dataset.\n\nWhile there is no completely safe amount of lead consumption, the limit allowed by the Lead and Copper Rule (LCR) of 1991 is 15 parts per billion (ppb). If this is exceeded in more than 10% of homes tested (or if the 90th percentile value of the total sample is above 15 ppb), action is required. And to make sure problems are caught, sampling for lead in water is supposed to target the “worst-case” homes – those in areas served by lead pipes.\n\nIf you’re interested in this sort of thing, Cullud Wattah by Erika Dickerson-Despenza is a very good play about the human toll of this fiasco."
  },
  {
    "objectID": "ae/ae-02-flint.html#rstudio",
    "href": "ae/ae-02-flint.html#rstudio",
    "title": "Exploring Flint Michigan’s water data",
    "section": "RStudio",
    "text": "RStudio\n\nFiles, plots, viewer, environment, etc. panes\nConsole\nEditor"
  },
  {
    "objectID": "ae/ae-02-flint.html#r",
    "href": "ae/ae-02-flint.html#r",
    "title": "Exploring Flint Michigan’s water data",
    "section": "R",
    "text": "R\n\nWriting code in the console\nBasic math with R\nCreating variables in R, the assignment operator (&lt;-), and the Environment pane\nR functions and packages and the Packages pane\nGetting help with R and the Help pane"
  },
  {
    "objectID": "ae/ae-02-flint.html#quarto",
    "href": "ae/ae-02-flint.html#quarto",
    "title": "Exploring Flint Michigan’s water data",
    "section": "Quarto",
    "text": "Quarto\n\nYAML: Metadata\nNarrative: Edited with the visual editor (or the source editor)\nCode: In code chunks\n\nChunk options (following #|)\nComments (following #)\nCode\n\nRunning individual code chunks vs. rendering a document"
  },
  {
    "objectID": "ae/ae-02-flint.html#load-packages",
    "href": "ae/ae-02-flint.html#load-packages",
    "title": "Exploring Flint Michigan’s water data",
    "section": "Load packages",
    "text": "Load packages\nWe’ll use the tidyverse package for analysis, which offers functionality for data import, wrangling, visualization, and more.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nLoading this package prints out a message. What does this message mean? How can we suppress the message from the output?"
  },
  {
    "objectID": "ae/ae-02-flint.html#load-data",
    "href": "ae/ae-02-flint.html#load-data",
    "title": "Exploring Flint Michigan’s water data",
    "section": "Load data",
    "text": "Load data\nThe read_csv() function can be used for reading CSV (comma separated values) files. The file we’re reading is called flint with the suffix (.csv) which indicates its file type. The file is in the data folder.\nBefore reading in the file, go to the data folder in the Files pane to confirm that it is, indeed, there. Then, read the file by running the code chunk below by clicking on the green triangle icon on the code chunk.\n\nflint &lt;- read_csv(\"data/flint.csv\")\n\nRows: 813 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): draw\ndbl (4): id, zip, ward, lead\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nOne of two things may have happened:\n\nThe file was read successfully and you now see a dataset called flint in your Environment pane.\nThe file was not read successfully and you see an error Error in read_csv(\"data/flint.csv\") : could not find function \"read_csv\".\n\nIf (1) happened, great!\nIf (2) happened, let’s troubleshoot first before continuing."
  },
  {
    "objectID": "ae/ae-02-flint.html#data-dictionary",
    "href": "ae/ae-02-flint.html#data-dictionary",
    "title": "Exploring Flint Michigan’s water data",
    "section": "Data dictionary",
    "text": "Data dictionary\nThe following variables are in the flint data frame:\n\nid: sample ID number (identifies the home)\nzip: ZIP code in Flint of the sample’s location\nward: ward in Flint of the sample’s location\ndraw: which time point the water was sampled from\nlead: lead content in parts per billion (ppb)"
  },
  {
    "objectID": "ae/ae-02-flint.html#populations-and-samples",
    "href": "ae/ae-02-flint.html#populations-and-samples",
    "title": "Exploring Flint Michigan’s water data",
    "section": "Populations and samples",
    "text": "Populations and samples\nWe want to learn about the population using a sample.\nIn the case we want to learn about the lead content in all of Flint, MI homes but only have available water readings from a sample of homes (our data set).\nExercise 1: Look at the data, how many observations are there? How many variables?\n\n# add code here"
  },
  {
    "objectID": "ae/ae-02-flint.html#frequencies",
    "href": "ae/ae-02-flint.html#frequencies",
    "title": "Exploring Flint Michigan’s water data",
    "section": "Frequencies",
    "text": "Frequencies\nLet’s count() to find the number of different time points water was sampled with the count() function.\n\nThe first argument is flint: the data frame\nThe second argument is draw: the variable\n\n\ncount(flint, draw)\n\n# A tibble: 3 × 2\n  draw       n\n  &lt;chr&gt;  &lt;int&gt;\n1 first    271\n2 second   271\n3 third    271\n\n\nWe can achieve the same result with the following “piped” operation as well.\n\nThe first line is flint: the data frame\nThen the pipe operator, read as “and then”, which places what comes before it as the first argument of what comes after it\nThe second line is count(draw)\n\n\nflint |&gt;\n  count(draw)\n\n# A tibble: 3 × 2\n  draw       n\n  &lt;chr&gt;  &lt;int&gt;\n1 first    271\n2 second   271\n3 third    271\n\n\nWe can use a similar approach to fund out how many unique homes are in the data set:\n\nflint |&gt;\n  count(id)\n\n# A tibble: 269 × 2\n      id     n\n   &lt;dbl&gt; &lt;int&gt;\n 1     1     3\n 2     2     3\n 3     4     3\n 4     5     3\n 5     6     3\n 6     7     3\n 7     8     3\n 8     9     3\n 9    12     3\n10    13     3\n# ℹ 259 more rows\n\n\nExercise 2: How many samples were taken from each zip code?\n\n# add code here\n\nExercise 3: Which ZIP code had the most samples drawn? Hint: See the help for count.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-02-flint.html#measures-of-central-tendency",
    "href": "ae/ae-02-flint.html#measures-of-central-tendency",
    "title": "Exploring Flint Michigan’s water data",
    "section": "Measures of central tendency",
    "text": "Measures of central tendency\n\nmean\nmedian\nmode"
  },
  {
    "objectID": "ae/ae-02-flint.html#measures-of-spread",
    "href": "ae/ae-02-flint.html#measures-of-spread",
    "title": "Exploring Flint Michigan’s water data",
    "section": "Measures of spread",
    "text": "Measures of spread\n\nvariance\nstandard deviation\nrange\nquartiles\ninter-quartile range (IQR)"
  },
  {
    "objectID": "ae/ae-02-flint.html#order-statistics",
    "href": "ae/ae-02-flint.html#order-statistics",
    "title": "Exploring Flint Michigan’s water data",
    "section": "Order statistics",
    "text": "Order statistics\n\nquantiles\nminimum (0 percentile)\nmedian (50th percentile)\nmaximum (100 percentile)\n\n… and any other arbitrary function of the data you can come up with!\nExercise 4: Compute each of these statistics for lead ppb.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-02-flint.html#histograms",
    "href": "ae/ae-02-flint.html#histograms",
    "title": "Exploring Flint Michigan’s water data",
    "section": "Histograms",
    "text": "Histograms\nLet’s take a look at the distribution of lead content in homes in Flint, MI.\n\nggplot(flint, aes(x = lead)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWe can make this plot look nicer/more useful by adjusting the number of bins and zooming into the x-axis.\n\nggplot(flint, aes(x = lead)) +\n  geom_histogram(bins = 50) +\n  coord_cartesian(xlim = c(0, 100))\n\n\n\n\n\n\n\n\nLet’s visualize some of our summary statistics on the plot.\nExercise 5: Add a new layer, geom_vline(xintercept = __, color = \"red\"), to the histogram below, filling in the blank with the mean.\n\nggplot(flint, aes(x = lead)) + \n  geom_histogram(bins = 50) + \n  coord_cartesian(xlim = c(0, 100))\n\n\n\n\n\n\n\n\nExercise 6: Add one more layer which overlays the median, in a different color.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-02-flint.html#box-plots",
    "href": "ae/ae-02-flint.html#box-plots",
    "title": "Exploring Flint Michigan’s water data",
    "section": "Box plots",
    "text": "Box plots\nNext, let’s narrow our focus to the zip codes 48503, 48504, 48505, 48506, and 48507 and observations with lead values less than 1,000 ppb.\n\nflint_focus &lt;- flint |&gt;\n  filter(zip %in% 48503:48507 & lead &lt; 1000)\n\nExercise 7: Below are side-by-side box plots for the three flushing times in each of the five zip codes we considered. Add x and y labels; add a title by inserting title = \"title_name\" inside the labs() function.\n\nggplot(data = flint_focus, aes(y = factor(zip), x = lead)) +\n  geom_boxplot(aes(fill = factor(draw))) +\n  labs(x = \"___\", y = \"___\", fill = \"Flushing time\") +\n  scale_fill_discrete(\n    breaks = c(\"first\", \"second\", \"third\"),\n    labels = c(\"0 (sec)\", \"45 (sec)\", \"120 (sec)\")\n  )\n\n\n\n\n\n\n\n\nExercise 8: Add labels for x, y, a title, and subtitle to the code below to update the corresponding plot.\n\nggplot(data = flint_focus, aes(y = factor(zip), x = lead)) +\n  geom_boxplot(aes(fill = factor(draw))) + \n  labs(\n    x = \"___\", y = \"___\", fill = \"Flushing time\",\n    title = \"___\",\n    subtitle = \"___\"\n    ) +\n  scale_fill_discrete(\n    breaks = c(\"first\", \"second\", \"third\"),\n    labels = c(\"0 (sec)\", \"45 (sec)\", \"120 (sec)\")\n  ) +\n  coord_cartesian(xlim = c(0, 50)) +\n  theme_bw()\n\n\n\n\n\n\n\n\nExercise 9: What is the difference between the two plots? What are the advantages and disadvantages to each plot?\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-03-delta-sa.html",
    "href": "ae/ae-03-delta-sa.html",
    "title": "COVID vaccine and deaths from Delta variant",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers for the application exercise. They’re not necessarily complete or 100% accurate, they’re roughly what we develop in class while going through the exercises.\nThe main question we’ll explore today is “How do deaths from COVID cases compare between vaccinated and unvaccinated?”\nWhat do you think?"
  },
  {
    "objectID": "ae/ae-03-delta-sa.html#exercise-1",
    "href": "ae/ae-03-delta-sa.html#exercise-1",
    "title": "COVID vaccine and deaths from Delta variant",
    "section": "Exercise 1",
    "text": "Exercise 1\nHow many rows and columns are in this dataset? Answer in a full sentence using inline code. What does each row represent and what does each column represent? For each variable, identify its type.\n\nThere are 268166 rows and 3 columns in the dataset. Each row represents a person with COVID, and the columns represent whether the person was vaccinated or not, their age, and whether they died or survived."
  },
  {
    "objectID": "ae/ae-03-delta-sa.html#exercise-2",
    "href": "ae/ae-03-delta-sa.html#exercise-2",
    "title": "COVID vaccine and deaths from Delta variant",
    "section": "Exercise 2",
    "text": "Exercise 2\nDo these data come from an observational study or experiment? Why?\n\nObservational study, people in the study chose to get vaccinated or not, they weren’t randomized into groups."
  },
  {
    "objectID": "ae/ae-03-delta-sa.html#exercise-3",
    "href": "ae/ae-03-delta-sa.html#exercise-3",
    "title": "COVID vaccine and deaths from Delta variant",
    "section": "Exercise 3",
    "text": "Exercise 3\nCreate a visualization of health outcome by vaccine status that allows you to compare the proportion of deaths across those who are and are not vaccinated. What can you say about death rates in these two groups based on this visualization?\n\nWhile this is very difficult to see, the proportion of patients who died is slightly higher for the vaccinated group compared to the unvaccinated group.\n\n\nggplot(delta, aes(x = vaccine, fill = outcome)) +\n  geom_bar(position = \"fill\")"
  },
  {
    "objectID": "ae/ae-03-delta-sa.html#exercise-4",
    "href": "ae/ae-03-delta-sa.html#exercise-4",
    "title": "COVID vaccine and deaths from Delta variant",
    "section": "Exercise 4",
    "text": "Exercise 4\nCalculate the proportion of deaths in among those who are vaccinated. Then, calculate the proportion among those who are not vaccinated.\n\nProportion of deaths among the vaccinated is 0.00407 and the proportion of deaths among the unvaccinated is 0.00166.\n\n\ndelta |&gt;\n  count(vaccine, outcome) |&gt;\n  group_by(vaccine) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 4 × 4\n# Groups:   vaccine [2]\n  vaccine      outcome       n    prop\n  &lt;chr&gt;        &lt;chr&gt;     &lt;int&gt;   &lt;dbl&gt;\n1 Unvaccinated died        250 0.00166\n2 Unvaccinated survived 150802 0.998  \n3 Vaccinated   died        477 0.00407\n4 Vaccinated   survived 116637 0.996"
  },
  {
    "objectID": "ae/ae-03-delta-sa.html#exercise-5",
    "href": "ae/ae-03-delta-sa.html#exercise-5",
    "title": "COVID vaccine and deaths from Delta variant",
    "section": "Exercise 5",
    "text": "Exercise 5\nCreate the visualization and calculate proportions from the two previous exercises, this time controlling for age. How do the proportions compare?\n\nAmong both the younger patients (&lt;50) and the older patients (50+), proportions of deaths is smaller for the vaccinated.\n\n\nggplot(delta, aes(x = vaccine, fill = outcome)) +\n  geom_bar(position = \"fill\") +\n  facet_wrap(~age)\n\n\n\n\n\n\n\ndelta |&gt;\n  count(age, vaccine, outcome) |&gt;\n  group_by(age, vaccine) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 8 × 5\n# Groups:   age, vaccine [4]\n  age   vaccine      outcome       n     prop\n  &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;     &lt;int&gt;    &lt;dbl&gt;\n1 50+   Unvaccinated died        205 0.0596  \n2 50+   Unvaccinated survived   3235 0.940   \n3 50+   Vaccinated   died        459 0.0168  \n4 50+   Vaccinated   survived  26848 0.983   \n5 &lt;50   Unvaccinated died         45 0.000305\n6 &lt;50   Unvaccinated survived 147567 1.00    \n7 &lt;50   Vaccinated   died         18 0.000200\n8 &lt;50   Vaccinated   survived  89789 1.00"
  },
  {
    "objectID": "ae/ae-03-delta-sa.html#exercise-6",
    "href": "ae/ae-03-delta-sa.html#exercise-6",
    "title": "COVID vaccine and deaths from Delta variant",
    "section": "Exercise 6",
    "text": "Exercise 6\nBased on your findings so far, fill in the blanks with more, less, or equally: Is there anything surprising about these statements? Speculate on what, if anything, the discrepancy might be due to.\n\nIn 2021, among those in the UK who were COVID Delta cases, the vaccinated were more likely to die than the unvaccinated.\nFor those under 50, those who were unvaccinated were more likely to die than those who were vaccinated.\nFor those 50 and up, those who were unvaccinated were more likely to die than those who were vaccinated.\n\n\nThe relationshio between outcome and vaccine status changes depending on the age of the person."
  },
  {
    "objectID": "ae/ae-03-delta-sa.html#exercise-7",
    "href": "ae/ae-03-delta-sa.html#exercise-7",
    "title": "COVID vaccine and deaths from Delta variant",
    "section": "Exercise 7",
    "text": "Exercise 7\nLet’s rephrase the previous question which asked you to speculate on why deaths among vaccinated cases overall is higher while deaths among unvaccinated cases are higher when we split the data into two groups (below 50 and 50 and up). What might be the confounding variable in the relationship between vaccination and deaths?\n\nAge."
  },
  {
    "objectID": "ae/ae-03-delta-sa.html#exercise-8",
    "href": "ae/ae-03-delta-sa.html#exercise-8",
    "title": "COVID vaccine and deaths from Delta variant",
    "section": "Exercise 8",
    "text": "Exercise 8\nVisualize and describe the distribution of seniors (50 and up) based on (a.k.a. conditional on) vaccination status. Hint: Your description will benefit from calculating proportions of seniors in each of the vaccination groups and working those values into your narrative.\n\nThe proportion of seniors (50+) is higher for the vaccinated group (0.233) compared to the unvaccinated group (0.0228).\n\n\nggplot(delta, aes(x = vaccine, fill = age)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\ndelta |&gt;\n  count(vaccine, age) |&gt;\n  group_by(vaccine) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 4 × 4\n# Groups:   vaccine [2]\n  vaccine      age        n   prop\n  &lt;chr&gt;        &lt;chr&gt;  &lt;int&gt;  &lt;dbl&gt;\n1 Unvaccinated 50+     3440 0.0228\n2 Unvaccinated &lt;50   147612 0.977 \n3 Vaccinated   50+    27307 0.233 \n4 Vaccinated   &lt;50    89807 0.767"
  },
  {
    "objectID": "ae/ae-01-unvotes.html",
    "href": "ae/ae-01-unvotes.html",
    "title": "UN Votes",
    "section": "",
    "text": "How do various countries vote in the United Nations General Assembly, how have their voting patterns evolved throughout time, and how similarly or differently do they view certain issues? Answering these questions (at a high level) is the focus of this analysis.\n\n\nWe will use the tidyverse, lubridate, and scales packages for data wrangling and visualization, and the DT package for interactive display of tabular output, and the unvotes package for the data.\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(DT)\nlibrary(unvotes)\nlibrary(ggthemes)\n\n\n\n\nThe data we’re using originally come from the unvotes package. In the chunk below we modify the data by joining the various data frames provided in the package to help you get started with the analysis.\n\nunvotes &lt;- un_votes |&gt;\n  inner_join(un_roll_calls, by = \"rcid\") |&gt;\n  inner_join(un_roll_call_issues, by = \"rcid\", relationship = \"many-to-many\")"
  },
  {
    "objectID": "ae/ae-01-unvotes.html#introduction",
    "href": "ae/ae-01-unvotes.html#introduction",
    "title": "UN Votes",
    "section": "",
    "text": "How do various countries vote in the United Nations General Assembly, how have their voting patterns evolved throughout time, and how similarly or differently do they view certain issues? Answering these questions (at a high level) is the focus of this analysis.\n\n\nWe will use the tidyverse, lubridate, and scales packages for data wrangling and visualization, and the DT package for interactive display of tabular output, and the unvotes package for the data.\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(DT)\nlibrary(unvotes)\nlibrary(ggthemes)\n\n\n\n\nThe data we’re using originally come from the unvotes package. In the chunk below we modify the data by joining the various data frames provided in the package to help you get started with the analysis.\n\nunvotes &lt;- un_votes |&gt;\n  inner_join(un_roll_calls, by = \"rcid\") |&gt;\n  inner_join(un_roll_call_issues, by = \"rcid\", relationship = \"many-to-many\")"
  },
  {
    "objectID": "ae/ae-01-unvotes.html#un-voting-patterns",
    "href": "ae/ae-01-unvotes.html#un-voting-patterns",
    "title": "UN Votes",
    "section": "UN voting patterns",
    "text": "UN voting patterns\nLet’s create a data visualization that displays how the voting record of the UK & NI changed over time on a variety of issues, and compares it to two other countries: US and Turkey.\nWe can easily change which countries are being plotted by changing which countries the code above filters for. Note that the country name should be spelled and capitalized exactly the same way as it appears in the data. See the Appendix for a list of the countries in the data.\n\nunvotes |&gt;\n  filter(country %in% c(\"United Kingdom\", \"United States\", \"Turkey\")) |&gt;\n  mutate(year = year(date)) |&gt;\n  group_by(country, year, issue) |&gt;\n  summarize(percent_yes = mean(vote == \"yes\")) |&gt;\n  ggplot(mapping = aes(x = year, y = percent_yes, color = country)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  facet_wrap(~issue) +\n  scale_y_continuous(labels = percent) +\n  scale_color_colorblind() +\n  labs(\n    title = \"Percentage of 'Yes' votes in the UN General Assembly\",\n    subtitle = \"1946 to 2019\",\n    y = \"% Yes\",\n    x = \"Year\",\n    color = \"Country\"\n  )"
  },
  {
    "objectID": "ae/ae-01-unvotes.html#references",
    "href": "ae/ae-01-unvotes.html#references",
    "title": "UN Votes",
    "section": "References",
    "text": "References\n\nRobinson D (2021). unvotes: United Nations General Assembly Voting Data. R package version 0.3.0, https://github.com/dgrtwo/unvotes.\nErik Voeten “Data and Analyses of Voting in the UN General Assembly” Routledge Handbook of International Organization, edited by Bob Reinalda (published May 27, 2013).\nMuch of the analysis has been modeled on the examples presented in the unvotes package vignette."
  },
  {
    "objectID": "ae/ae-01-unvotes.html#appendix",
    "href": "ae/ae-01-unvotes.html#appendix",
    "title": "UN Votes",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of countries in the dataset:"
  },
  {
    "objectID": "course-materials.html",
    "href": "course-materials.html",
    "title": "Course materials",
    "section": "",
    "text": "All books are freely available online:\n\n[ims]: Mine Çetinkaya-Rundel and Jo Hardin. Introduction to Modern Statistics. 2nd edition. OpenIntro, 2024.\n[r4ds]: Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund. R for Data Science. 2nd edition. O’Reilly, 2022.",
    "crumbs": [
      "Syllabus",
      "Course materials"
    ]
  },
  {
    "objectID": "course-materials.html#textbooks",
    "href": "course-materials.html#textbooks",
    "title": "Course materials",
    "section": "",
    "text": "All books are freely available online:\n\n[ims]: Mine Çetinkaya-Rundel and Jo Hardin. Introduction to Modern Statistics. 2nd edition. OpenIntro, 2024.\n[r4ds]: Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund. R for Data Science. 2nd edition. O’Reilly, 2022.",
    "crumbs": [
      "Syllabus",
      "Course materials"
    ]
  },
  {
    "objectID": "course-materials.html#technology",
    "href": "course-materials.html#technology",
    "title": "Course materials",
    "section": "Technology",
    "text": "Technology\nYou will need to bring a laptop to all lectures and labs. Options for obtaining a laptop through the university are described here. Armed with your trusty laptop, you must be able to access the following:\n\nThis course page that you are on right now;\nR/RStudio as provided by the Duke Container Manager;\nCanvas, through which you can access…\n\nGradescope;\nEd Discussion;\n\nZoom (e.g. for remote office hours).\n\nIf access to technology becomes a concern for you during the semester, contact the instructor immediately to discuss options.",
    "crumbs": [
      "Syllabus",
      "Course materials"
    ]
  },
  {
    "objectID": "labs/lab-1.html",
    "href": "labs/lab-1.html",
    "title": "Lab 1: Hello R!",
    "section": "",
    "text": "The goal of this lab is to acquaint you with R and RStudio1.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#quarto",
    "href": "labs/lab-1.html#quarto",
    "title": "Lab 1: Hello R!",
    "section": "Quarto",
    "text": "Quarto\nlab-1.qmd is an example of a Quarto Markdown file. Quarto allows you to seamlessly combine written text and code to produce clean and professional looking reports. You will use this system to create all of your assignment submissions in this course. When you open your .qmd file, you see a block of text at the top in between dashed lines. This is called the YAML2, and it contains the settings for your document, like the title, author name, date, and what sort of document you want to create. In our case, it will always be a PDF.\nChange the author name to your name and update the date with today’s date. Click the Render button to render the document. What do you notice?\n\n\n\n\n\n\nNote\n\n\n\nTo avoid issues that can occur while rendering, it is a good idea to render early and often. At least after every exercise.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#packages",
    "href": "labs/lab-1.html#packages",
    "title": "Lab 1: Hello R!",
    "section": "Packages",
    "text": "Packages\nIn this lab we will work with three packages: the tidyverse package which is a collection of packages for doing data analysis in a “tidy” way, the datasauRus package which contains the data set for the first part of your lab.\n\nlibrary(tidyverse) \nlibrary(datasauRus)",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-1",
    "href": "labs/lab-1.html#exercise-1",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nBased on the help file, how many rows and how many columns does the datasaurus_dozen file have? What are the variables included in the data frame? Add your responses to your lab report under “Exercise 1”.\n\nLet’s take a look at the names of the data sets inside of datasaurus_dozen. To do this, we can make a frequency table of the “data set” variable. Run the code chunk below. Note: when you run the code chunk below, a table “prints” to the screen. In general, we say “print to screen” to mean that the output of your code should show up on your screen (when asked to ‘print to screen’ in an assignment, you should make sure the output displays in your rendered document).\n\ndatasaurus_dozen |&gt;\n  count(dataset)\n\n# A tibble: 13 × 2\n   dataset        n\n   &lt;chr&gt;      &lt;int&gt;\n 1 away         142\n 2 bullseye     142\n 3 circle       142\n 4 dino         142\n 5 dots         142\n 6 h_lines      142\n 7 high_lines   142\n 8 slant_down   142\n 9 slant_up     142\n10 star         142\n11 v_lines      142\n12 wide_lines   142\n13 x_shape      142\n\n\nThe original Datasaurus (dino) data was created by Alberto Cairo. The other Dozen were generated using simulated annealing and the process is described in the paper Same Stats, Different Graphs: Generating data sets with Varied Appearance and Identical Statistics through Simulated Annealing by Justin Matejka and George Fitzmaurice. In the paper, the authors simulate a variety of data sets that have the same summary statistics as the original Datasaurus but have very different data.\n\n\n\n\n\n\nNote\n\n\n\nYou can view the whole data frame by running the code view(datasaurus_dozen) in the console. This will open the data frame in a new tab. Try it out!",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-2",
    "href": "labs/lab-1.html#exercise-2",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nPlot y vs. x for the dino data set. Then, calculate the correlation coefficient between x and y for this data set. Make sure that this value is printed in your document.\n\nBelow is the code you will need to complete this exercise. Basically, the answer is already given, but you need to include relevant bits in your .qmd document and successfully render it and view the results.\nStart with the datasaurus_dozen and pipe it into the filter function to filter for observations where dataset == \"dino\". Store the resulting filtered data frame as a new data frame called dino_data.\n\ndino_data &lt;- datasaurus_dozen |&gt;\n  filter(dataset == \"dino\")\n\nThere is a lot going on here, so let’s slow down and unpack it a bit.\nFirst, the pipe operator: |&gt;, takes what comes before it and sends it as the first argument to what comes after it. So here, we’re saying filter the datasaurus_dozen data frame for observations where dataset == \"dino\".\nSecond, the assignment operator: &lt;-, assigns the name dino_data to the filtered data frame.\n\n\n\n\n\n\nNote\n\n\n\nNote in R you may use either &lt;- or = for an assignment operator. We’ll use &lt;- in this class as it’s the more commonly used assignment operator, but when you look for R help online, you might see = being used as well.\n\n\nNext, we need to visualize these data. We will use the ggplot function for this. Its first argument is the data you’re visualizing. Next we define the aesthetic mappings. In other words, the columns of the data that get mapped to certain aesthetic features of the plot, e.g. the x axis will represent the variable called x and the y axis will represent the variable called y. Then, we add another layer to this plot where we define which geometric shapes we want to use to represent each observation in the data. In this case we want these to be points, hence geom_point.\n\nggplot(dino_data, aes(x = x, y = y)) +\n  geom_point()\n\n\n\n\n\n\n\nFor the second part of this exercise, we need to calculate a summary statistic: the correlation coefficient. The correlation coefficient (r) measures the strength and direction of the linear association between two variables. You will see that some of the pairs of variables we plot do not have a linear relationship between them. This is exactly why we want to visualize first: visualize to assess the form of the relationship, and calculate r only if relevant.\nIn this case, calculating a correlation coefficient really doesn’t make sense since the relationship between x and y is definitely not linear, but is instead more ‘dinosaur-esque’.\nFor illustrative purposes only, let’s calculate the correlation coefficient between x and y.\n\ndino_data |&gt;\n  summarize(r = cor(x, y))\n\n# A tibble: 1 × 1\n        r\n    &lt;dbl&gt;\n1 -0.0645",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-3",
    "href": "labs/lab-1.html#exercise-3",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nPlot y vs. x for the star dataset. You can (and should) reuse code we introduced above, just replace the dataset name with the desired dataset. Then, calculate the correlation coefficient between x and y for this dataset. How does this value compare to the r of dino?\n\nTo begin, edit the name of the code chunks from ex-3-1 and ex-3-2 to something more meaningful, e.g: plot-star and r-star respectively.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-4",
    "href": "labs/lab-1.html#exercise-4",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nFinally, let’s plot all datasets at once. In order to do this we will make use of faceting, given by the code below:\n\nggplot(datasaurus_dozen, aes(x = x, y = y, color = dataset)) +\n  geom_point() +\n  facet_wrap(~ dataset, ncol = 3)\n\nAnd we can use the group_by function to generate all the summary correlation coefficients. We’ll see these functions again and again.\n\ndatasaurus_dozen |&gt;\n  group_by(dataset) |&gt;\n  summarize(r = cor(x, y))",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-5",
    "href": "labs/lab-1.html#exercise-5",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nDescribe what |&gt; does. Hint: run the following two code chunks. What do you notice?\n\ndino_data |&gt;\n  summarize(\n    mu_x = mean(x),\n    mu_y = mean(y)\n  )\n\n\nsummarize(dino_data, mu_x = mean(x), mu_y = mean(y))",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-6",
    "href": "labs/lab-1.html#exercise-6",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nIn the above code chunk, identify each of the following as an argument or a function:\n\nsummarize\ndino_data\nmean\nx\ny\nmu_x = mean(x)",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-7",
    "href": "labs/lab-1.html#exercise-7",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nCombine the code from exercises 4 and 5 to compute the mean(x) and mean(y) for each data set. Print your result to the screen. What do you notice? What does this say about the importance of visualizing your data as opposed to only looking at summary statistics?",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-8",
    "href": "labs/lab-1.html#exercise-8",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nIMS - Chapter 1 exercises, #4: Cheaters, study components.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-9",
    "href": "labs/lab-1.html#exercise-9",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nIMS - Chapter 1 exercises, #14: UN Votes.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-10",
    "href": "labs/lab-1.html#exercise-10",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 10",
    "text": "Exercise 10\n\nIMS - Chapter 1 exercises, #16: Shows on Netflix.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#lastly",
    "href": "labs/lab-1.html#lastly",
    "title": "Lab 1: Hello R!",
    "section": "Lastly…",
    "text": "Lastly…\nRecommend some music for us to listen to while we grade this.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#submitting",
    "href": "labs/lab-1.html#submitting",
    "title": "Lab 1: Hello R!",
    "section": "Submitting",
    "text": "Submitting\n\n\n\n\n\n\nImportant\n\n\n\nBefore you proceed, first, make sure that you have updated the document YAML with your name! Then, render your document one last time, for good measure.\n\n\nTo submit your assignment to Gradescope:\n\nGo to your Files pane and check the box next to the PDF output of your document (lab-1.pdf).\nThen, in the Files pane, go to More &gt; Export. This will download the PDF file to your computer. Save it somewhere you can easily locate, e.g., your Downloads folder or your Desktop.\nGo to the course Canvas page and click on Gradescope and then click on the assignment. You’ll be prompted to submit it.\nMark the pages associated with each exercise. All of the papers of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you fail to mark the pages associated with an exercise, that exercise won’t be graded. This means, if you fail to mark the pages for all exercises, you will receive a 0 on the assignment. The TAs can’t mark your pages for you, and for them to be able to grade, you must mark them.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#grading",
    "href": "labs/lab-1.html#grading",
    "title": "Lab 1: Hello R!",
    "section": "Grading",
    "text": "Grading\n\n\nExercise\nPoints\n\n\n\nExercise 1\n5\n\n\nExercise 2\n4\n\n\nExercise 3\n6\n\n\nExercise 4\n5\n\n\nExercise 5\n2\n\n\nExercise 6\n6\n\n\nExercise 7\n7\n\n\nExercise 8\n5\n\n\nExercise 9\n5\n\n\nExercise 10\n5\n\n\nTotal\n50",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#acknowledgements",
    "href": "labs/lab-1.html#acknowledgements",
    "title": "Lab 1: Hello R!",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis assignment was adapted from a lab in Data Science in a Box.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#footnotes",
    "href": "labs/lab-1.html#footnotes",
    "title": "Lab 1: Hello R!",
    "section": "Footnotes",
    "text": "Footnotes\n\nR is a programming language, just like Python, Java, C++, and other things you may have heard of. RStudio is a platform for writing R code in an easy and organized way. It is an example of an integrated development environment (IDE).↩︎\nThat stands for “Yet Another Markup Language.” Now please promptly forget that.↩︎",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-2.html",
    "href": "labs/lab-2.html",
    "title": "Lab 2",
    "section": "",
    "text": "The goal of this lab is to effectively visualize numerical and categorical data.\nFor all visualizations you create, be sure to include informative titles for the plot, axes, and legend!",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#exercise-1",
    "href": "labs/lab-2.html#exercise-1",
    "title": "Lab 2",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nCreate a bar plot of the results of games for NC Courage. Additionally, calculate the numbers of wins, losses, and ties. Write a one sentence narrative for your findings.\n\nHint: result is a categorical variable, so use a bar plot for the visualization and the count() function for calculating the frequencies of levels of this variable. This primer may help you get started with the plot.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#exercise-2",
    "href": "labs/lab-2.html#exercise-2",
    "title": "Lab 2",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nCreate a new variable indicating whether the game was played at home or away for NC Courage. This variable should be called home_courage and take the value “home” if NC Courage is the home team and “away” if NC Courage is the away team. (Instructions for how to do this are given below.)\nThen, calculate the number of home and away games, and write a one sentence narrative for your findings.\n\nUse the example code below to get started.\n\ncourage &lt;- courage |&gt;\n  mutate(home_courage = if_else(home_team == \"NC\", \"home\", \"away\"))\n\nThere are two things of note here:\n\nThe use of the assignment operator (&lt;-) to assign the resulting data frame to courage, thus overwriting the courage dataset to contain this new column. We do this because we will use this new variable, home_courage, in a subsequent exercise.\n\nThe use of a new function, if_else() to determine whether the game is played at home or away.\n\n\nhome_team == \"NC\" finds all rows where the home team is NC Courage.\nIf the home team is NC Courage, then we set the value of home_courage to `“home”.\nOtherwise (else) Courage must be the away team and we set the value of home_courage to \"away\".",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#exercise-3",
    "href": "labs/lab-2.html#exercise-3",
    "title": "Lab 2",
    "section": "Exercise 3",
    "text": "Exercise 3\n\n\nThis code creates a visualization that displays the relationship between home_courage and result:\n\n\nggplot(courage, aes(x = home_courage, fill = result)) +\n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\nExplain what each piece of the code is doing. Why does it produce the plot that it produces?\nHint: to understand what the different ingredients do, try removing or altering some of them, and see how it changes the plot.\n\n\n\nCalculate the proportions of home and away games that the Courage won. Based on these, do your findings suggest a home-field advantage? Why or why not?\n\n\nSo far we have focused on whether the game was at home or away and whether the Courage won. Next, we dive deeper and focus on the number of points the Courage wins by, at home and away.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#exercise-4",
    "href": "labs/lab-2.html#exercise-4",
    "title": "Lab 2",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nHow many points do the Courage typically win by (on average)? Use the example code below to get started. You’ll encounter a new function: abs() is the absolute value function. It takes the absolute value of a number. Why do we want to use this absolute value function here?\n\nHint: We are only interested in games the Courage wins, therefore we should filter() for those games first.\n\ncourage |&gt;\n  filter(___) |&gt;\n  mutate(win_pts = abs(home_pts - away_pts)) |&gt;\n  summarize(___)",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#exercise-5",
    "href": "labs/lab-2.html#exercise-5",
    "title": "Lab 2",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nHow many points do NC Courage score when they win (on average)? Note this is different than how many points they “win by”. How many points do the Courage score when they lose on average?\n\nTo calculate this we first need to determine how many points NC Courage scored in every game. We can use if_else() logic again to find this value for each game, and store it in a new column, courage_pts.\n\ncourage &lt;- courage |&gt;\n  mutate(courage_pts = if_else(home_team == \"NC\", home_pts, away_pts))\n\ncourage |&gt;\n  group_by(___) |&gt;\n  summarize(___)",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#exercise-6",
    "href": "labs/lab-2.html#exercise-6",
    "title": "Lab 2",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nNext we’ll investigate visually whether or not NC Courage has a home-field advantage. Mutate the courage data frame to create two new variables:\n\ntotal_pts: Sum of points scored by both teams, i.e. home_pts + away_pts.\nopponent_pts: Points scored by the opposing team, i.e., total_pts - courage_pts.\n\nSave the resulting data frame as courage again and print the three points columns (total_pts, opponent_pts, courage_pts) to screen.\n\nHint:\n\nUse the mutate() function to create the columns.\n\n\ncourage &lt;- courage |&gt;\n  mutate(\n    total_pts = ___,\n    opponent_pts = ___\n    )\n\n\nUse the select() function to print them to screen:\n\n\ncourage |&gt;\n  select(total_pts, opponent_pts, courage_pts)",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#exercise-7",
    "href": "labs/lab-2.html#exercise-7",
    "title": "Lab 2",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nCreate a scatter plot:\n\nopponent_pts (y) vs. courage_pts (x)\nColor the scatter plot by whether NC Courage are home or away.\nRepresent the data with “jittered” points wth geom_jitter().\nOverlay a \\(y = x\\) line with geom_abline().\nFaceted by season.\n\nWhat does the line represent? What does it mean for a point to fall above the line? Below the line?\n\n\nggplot(courage, aes(x = ___, y = ___, color = ___)) + \n  geom_jitter(width = 0.1, height = 0.1) + \n  geom_abline(slope = 1, intercept = 0) +\n  facet_wrap(~ ___) +\n  labs(\n    x = \"___\", \n    y = \"___\", \n    title = \"___\", \n    color = \"___\"\n  )",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#exercise-8",
    "href": "labs/lab-2.html#exercise-8",
    "title": "Lab 2",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nIf we want to formally test whether the Courage have a home-field advantage, then we must first define what this means! In your own words, what do you think a home-field advantage means? Then, now that you’ve defined what it means to have a home field advantage, define what it means to not have a home-field advantage.\n\n\n\n\n\n\n\nNote\n\n\n\nWhile there is a right answer, this part is graded for completion, so don’t worry too much about answering this in exactly the right way. Although graded for completion, your response must make sense to receive full points.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#exercise-9",
    "href": "labs/lab-2.html#exercise-9",
    "title": "Lab 2",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nIMS - Chapter 2 exercises, #20: Vitamin supplements.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#exercise-10",
    "href": "labs/lab-2.html#exercise-10",
    "title": "Lab 2",
    "section": "Exercise 10",
    "text": "Exercise 10\n\nIMS - Chapter 2 exercises, #30: Screens, teens, and psychological well-being.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#lastly",
    "href": "labs/lab-2.html#lastly",
    "title": "Lab 2",
    "section": "Lastly…",
    "text": "Lastly…\nRecommend some music for us to listen to while we grade this.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#submitting",
    "href": "labs/lab-2.html#submitting",
    "title": "Lab 2",
    "section": "Submitting",
    "text": "Submitting\n\n\n\n\n\n\nImportant\n\n\n\nBefore you proceed, first, make sure that you have updated the document YAML with your name! Then, render your document one last time, for good measure.\n\n\nTo submit your assignment to Gradescope:\n\nGo to your Files pane and check the box next to the PDF output of your document (lab-2.pdf).\nThen, in the Files pane, go to More &gt; Export. This will download the PDF file to your computer. Save it somewhere you can easily locate, e.g., your Downloads folder or your Desktop.\nGo to the course Canvas page and click on Gradescope and then click on the assignment. You’ll be prompted to submit it.\nMark the pages associated with each exercise. All of the papers of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you fail to mark the pages associated with an exercise, that exercise won’t be graded. This means, if you fail to mark the pages for all exercises, you will receive a 0 on the assignment. The TAs can’t mark your pages for you, and for them to be able to grade, you must mark them.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#grading",
    "href": "labs/lab-2.html#grading",
    "title": "Lab 2",
    "section": "Grading",
    "text": "Grading\n\n\nExercise\nPoints\n\n\n\nExercise 1\n5\n\n\nExercise 2\n5\n\n\nExercise 3\n6\n\n\nExercise 4\n6\n\n\nExercise 5\n6\n\n\nExercise 6\n4\n\n\nExercise 7\n6\n\n\nExercise 8\n2\n\n\nExercise 9\n5\n\n\nExercise 10\n5\n\n\nTotal\n50",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#acknowledgements",
    "href": "labs/lab-2.html#acknowledgements",
    "title": "Lab 2",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis assignment was adapted from a similar exercise by Dr. Alex Fisher.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-3.html",
    "href": "labs/lab-3.html",
    "title": "Lab 3",
    "section": "",
    "text": "The goal of this lab is to solidify some of the skills and concepts from the first two weeks of the course.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#getting-started",
    "href": "labs/lab-3.html#getting-started",
    "title": "Lab 3",
    "section": "Getting started",
    "text": "Getting started\n\nUse these steps to navigate to the STA101 version of RStudio using the Duke Container Manager;\nUse these steps to download all of the lab 3 files from our Canvas page, upload them to your RStudio files, and move them into an appropriately named folder (lab-3, for instance);\nOnce lab-3.qmd is where it needs to be, open it, and verify that you can click the “Render” button in RStudio and get a PDF file. See this answer on Ed if you want more guidance here;\nNow proceed to complete the exercises in this lab.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#pointers",
    "href": "labs/lab-3.html#pointers",
    "title": "Lab 3",
    "section": "Pointers",
    "text": "Pointers\n\nFor all visualizations you create, be sure to include informative titles for the plot, axes, and legend;\nRespond in complete sentences as much as possible;\nBe sure to observe good code style:\n\nThere is a line break after each |&gt; in a pipeline or + in a ggplot;\nThere are spaces around = signs;\nThere is a space after each ,;\nCode is properly indented;\nCode doesn’t exceed 80 characters in each line, longer lines of code are spread across multiple lines with appropriately placed line breaks (so in the rendered PDF, your code shouldn’t run off the page);\nCode chunks are labeled, informatively and without spaces.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#packages",
    "href": "labs/lab-3.html#packages",
    "title": "Lab 3",
    "section": "Packages",
    "text": "Packages\nIn this lab we will work with the tidyverse packages, which is a collection of packages for doing data analysis in a “tidy” way.\n\nlibrary(tidyverse)",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#part-1-nobel-laureates",
    "href": "labs/lab-3.html#part-1-nobel-laureates",
    "title": "Lab 3",
    "section": "Part 1: Nobel laureates",
    "text": "Part 1: Nobel laureates\nWe will now consider a data set on the characteristics of winners (laureates) of a Nobel prize: nobel.csv. You can read it in using the following.\n\nnobel &lt;- read_csv(\"data/nobel.csv\")\n\n\n\n\n\n\n\nNote\n\n\n\nRecall that you may have to adjust the file path to match how you have organized your files and folders.\n\n\nThe descriptions of the variables are as follows:\n\n\nid: ID number\n\nfirstname: First name of laureate\n\nsurname: Surname\n\nyear: Year prize won\n\ncategory: Category of prize\n\naffiliation: Affiliation of laureate\n\ncity: City of laureate in prize year\n\ncountry: Country of laureate in prize year\n\nborn_date: Birth date of laureate\n\ndied_date: Death date of laureate\n\ngender: Gender of laureate\n\nborn_city: City where laureate was born\n\nborn_country: Country where laureate was born\n\nborn_country_code: Code of country where laureate was born\n\ndied_city: City where laureate died\n\ndied_country: Country where laureate died\n\ndied_country_code: Code of country where laureate died\n\noverall_motivation: Overall motivation for recognition\n\nshare: Number of other winners award is shared with\n\nmotivation: Motivation for recognition\n\nIn a few cases the name of the city/country changed after laureate was given (e.g. in 1975 Bosnia and Herzegovina was called the Socialist Federative Republic of Yugoslavia). In these cases the variables below reflect a different name than their counterparts without the suffix _original.\n\n\nborn_country_original: Original country where laureate was born\n\nborn_city_original: Original city where laureate was born\n\ndied_country_original: Original country where laureate died\n\ndied_city_original: Original city where laureate died\n\ncity_original: Original city where laureate lived at the time of winning the award\n\ncountry_original: Original country where laureate lived at the time of winning the award\n\nThere are some observations in this dataset that we will exclude from our analysis. This code creates a new data frame called nobel_living_science that filters for\n\nlaureates for whom country is available: !is.na(country);\nlaureates who are people as opposed to organizations, i.e., organizations are denoted with \"org\" as their gender: gender != \"org\";\nlaureates who are still alive, i.e., their died_date is NA: is.na(died_date).\nlaureates in the sciences (so not literature or peace).\n\n\nnobel_living_science &lt;- nobel |&gt;\n  filter(!is.na(country) & gender != \"org\" & is.na(died_date)) |&gt;\n  filter(category %in% c(\"Physics\", \"Medicine\", \"Chemistry\", \"Economics\"))\n\nOnce you have filtered for these characteristics you are left with a data frame with 228 observations (check this!).\n\nMost living Nobel laureates were based in the US when they won their prizes\n\n… says this Buzzfeed article. Let’s see if that’s true.\nFirst, we’ll create a new variable to identify whether the laureate was in the US when they won their prize. We’ll use the mutate() function for this. The following pipeline mutates the nobel_living_science data frame by adding a new variable called country_us. We use an if statement to create this variable. The first argument in the if_else() function we’re using to write this if statement is the condition we’re testing for. If country is equal to \"USA\", we set country_us to \"USA\". If not, we set the country_us to \"Other\".\n\nnobel_living_science &lt;- nobel_living_science |&gt;\n  mutate(\n    country_us = if_else(country == \"USA\", \"USA\", \"Other\")\n  )\n\nFor the following exercises, work with the nobel_living_science data frame you created above.\nExercise 1\n\nCreate a faceted bar plot visualizing the relationship between the category of prize and whether the laureate was in the US when they won the Nobel prize. Interpret your visualization, and say a few words about whether the Buzzfeed headline is supported by the data.\n\nYour visualization should be faceted by category;\nFor each facet you should have two bars, one for winners in the US and one for Other;\nFlip the coordinates so the bars are horizontal, not vertical;\nMake sure everything is clearly labeled!\n\n\nExercise 2\nNext, let’s investigate, of those US-based Nobel laureates, what proportion were born in other countries.\n\nCreate a new variable called born_country_us in nobel_living_science that has the value \"USA\" if the laureate is born in the US, and \"Other\" otherwise. How many of the winners are born in the US?\n\nExercise 3\n\nAdd a second variable to your visualization from Exercise 1 based on whether the laureate was born in the US or not.\nCreate two visualizations with this new variable added:\n\nPlot 1: Segmented frequency bar plot\nPlot 2: Segmented relative frequency bar plot (Hint: Add position = \"fill\" to geom_bar().)\n\nHere are some instructions that apply to both of these visualizations:\n\nYour final visualization should contain a facet for each category.\nWithin each facet, there should be two bars for whether the laureate won the award in the US or not.\nEach bar should have segments for whether the laureate was born in the US or not.\n\nWhich of these visualizations is a better fit for answering the following question: “Do the data appear to support Buzzfeed’s claim that of those US-based Nobel laureates, many were born in other countries?” First, state which plot you’re using to answer the question. Then, answer the question, explaining your reasoning in 1-2 sentences.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#part-2-practicing-our-coding-basics",
    "href": "labs/lab-3.html#part-2-practicing-our-coding-basics",
    "title": "Lab 3",
    "section": "Part 2: practicing our coding basics",
    "text": "Part 2: practicing our coding basics\nExercise 4\nThe file nsw-crime.csv contains monthly data on all criminal incidents recorded by police in New South Wales, Australia (the state that includes the city of Sydney). So a row in this data set corresponds to a month, and a column corresponds to a crime (murder, dealing cannabis, escaping custody, etc). The data count the number of cases of each crime in each month. In this exercise we will consider the variable offensive_language, an incident of disorderly conduct where the perpetrator…said some things.\n\nLoad the crime data into R and create four histogram plots of the variable offensive_language. In each plot, use a different number of histogram bins: 20, 40, 80, and 160. Decide which picture you think best visualizes the distribution of the crime counts, and explain why you think this.\n\nExercise 5\nLoad the data about the COVID delta variant (adjusting your file path as needed):\n\ndelta &lt;- read_csv(\"delta.csv\")\n\n\nConsider this sequence of commands:\n\n# part 1\n\ndelta |&gt;\n  count(vaccine, outcome)\n\n# part 2\n\ndelta |&gt;\n  count(vaccine, outcome) |&gt;\n  group_by(vaccine)\n\n# part 3\n\ndelta |&gt;\n  count(vaccine, outcome) |&gt;\n  group_by(vaccine) |&gt;\n  mutate(prop = n / sum(n))\n\nPick this code apart like a vulture and explain in complete sentences what is going on in each part. The more detail, the better.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#part-3-ims-exercises",
    "href": "labs/lab-3.html#part-3-ims-exercises",
    "title": "Lab 3",
    "section": "Part 3: IMS Exercises",
    "text": "Part 3: IMS Exercises\nThe exercises in this section do not require code. Make sure to answer the questions in full sentences.\nExercise 6\n\nIMS - Chapter 4 exercises, #4: Raise taxes.\n\nExercise 7\n\nIMS - Chapter 5 exercises, #4: Office productivity.\n\nExercise 8\n\nIMS - Chapter 5 exercises, #15: Distributions and appropriate statistics.\n\nExercise 9\n\nIMS - Chapter 5 exercises, #26: NYC marathon winners.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#part-4-waxing-poetic",
    "href": "labs/lab-3.html#part-4-waxing-poetic",
    "title": "Lab 3",
    "section": "Part 4: waxing poetic",
    "text": "Part 4: waxing poetic\nExercise 10\n\nDescribe a situation from your everyday life where you have to make a decision, but it is difficult to make a good decision because you face some uncertainty about the world. Common examples (which you should not now use!) might include deciding when to get food at the dining hall, because you are uncertain about the length of the lines, or deciding when to have a picnic, because you are uncertain about the weather. Next, describe some data (information) that, if you had access to it, would resolve some of the uncertainty you face and help you make a better decision. Describe two versions of the data: an ideal version that would theoretically resolve all of the uncertainty, and an imperfect version that you are more likely to actually encounter in practice. How would you use these data to guide your decision making?\n\n\n\n\n\n\n\nNote\n\n\n\nThis is basically going to be graded for completion, but I hope some of you will get creative, and I look forward to reading these!",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#lastly",
    "href": "labs/lab-3.html#lastly",
    "title": "Lab 3",
    "section": "Lastly",
    "text": "Lastly\nRecommend some music for us to listen to while we grade this.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#wrap-up",
    "href": "labs/lab-3.html#wrap-up",
    "title": "Lab 3",
    "section": "Wrap up",
    "text": "Wrap up\nSubmitting\n\n\n\n\n\n\nImportant\n\n\n\nBefore you proceed, first, make sure that you have updated the document YAML with your name! Then, render your document one last time, for good measure.\n\n\nTo submit your assignment to Gradescope:\n\nGo to your Files pane and check the box next to the PDF output of your document (lab-3.pdf).\nThen, in the Files pane, go to More &gt; Export. This will download the PDF file to your computer. Save it somewhere you can easily locate, e.g., your Downloads folder or your Desktop.\nGo to the course Canvas page and click on Gradescope and then click on the assignment. You’ll be prompted to submit it.\nMark the pages associated with each exercise. All of the papers of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you fail to mark the pages associated with an exercise, that exercise won’t be graded. This means, if you fail to mark the pages for all exercises, you will receive a 0 on the assignment. The TAs can’t mark your pages for you, and for them to be able to grade, you must mark them.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#grading",
    "href": "labs/lab-3.html#grading",
    "title": "Lab 3",
    "section": "Grading",
    "text": "Grading\n\n\nExercise\nPoints\n\n\n\nExercise 1\n8\n\n\nExercise 2\n6\n\n\nExercise 3\n8\n\n\nExercise 4\n6\n\n\nExercise 5\n6\n\n\nExercise 6\n2\n\n\nExercise 7\n2\n\n\nExercise 8\n5\n\n\nExercise 9\n4\n\n\nExercise 10\n3\n\n\nTotal\n50",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-4.html",
    "href": "labs/lab-4.html",
    "title": "Lab 4",
    "section": "",
    "text": "Use these steps to navigate to the STA101 version of RStudio using the Duke Container Manager;\nUse these steps to download all of the lab 4 files from our Canvas page, upload them to your RStudio files, and move them into an appropriately named folder (lab-4, for instance);\nOnce lab-4.qmd is where it needs to be, open it, and verify that you can click the “Render” button in RStudio and get a PDF file. See this answer on Ed if you want more guidance here;\nNow proceed to complete the exercises in this lab.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#getting-started",
    "href": "labs/lab-4.html#getting-started",
    "title": "Lab 4",
    "section": "",
    "text": "Use these steps to navigate to the STA101 version of RStudio using the Duke Container Manager;\nUse these steps to download all of the lab 4 files from our Canvas page, upload them to your RStudio files, and move them into an appropriately named folder (lab-4, for instance);\nOnce lab-4.qmd is where it needs to be, open it, and verify that you can click the “Render” button in RStudio and get a PDF file. See this answer on Ed if you want more guidance here;\nNow proceed to complete the exercises in this lab.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#pointers",
    "href": "labs/lab-4.html#pointers",
    "title": "Lab 4",
    "section": "Pointers",
    "text": "Pointers\n\nFor all visualizations you create, be sure to include informative titles for the plot, axes, and legend;\nRespond in complete sentences as much as possible;\nBe sure to observe good code style:\n\nThere is a line break after each |&gt; in a pipeline or + in a ggplot;\nThere are spaces around = signs;\nThere is a space after each ,;\nCode is properly indented;\nCode doesn’t exceed 80 characters in each line, longer lines of code are spread across multiple lines with appropriately placed line breaks (so in the rendered PDF, your code shouldn’t run off the page);\nCode chunks are labeled, informatively and without spaces.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#packages",
    "href": "labs/lab-4.html#packages",
    "title": "Lab 4",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse) \nlibrary(tidymodels)",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#part-1-do-you-even-lift",
    "href": "labs/lab-4.html#part-1-do-you-even-lift",
    "title": "Lab 4",
    "section": "Part 1: Do you even lift?",
    "text": "Part 1: Do you even lift?\nToday, we will be working with data from www.openpowerlifting.org. This data was sourced from Tidy Tuesday and contains international powerlifting records at various meets. At each meet, each lifter gets three attempts at lifting max weight on three lifts: the bench press, squat and deadlift.\n\nipf &lt;- read_csv(\"data/ipf.csv\")\n\n\n\n\n\n\n\nNote\n\n\n\nRecall that you may have to adjust the file path to match how you have organized your files and folders.\n\n\nThe data dictionary for this dataset from TidyTuesday is reproduced below:\n\n\n\n\n\n\nvariable\ndescription\n\n\n\nname\nIndividual lifter name\n\n\nsex\nBinary gender (M/F)\n\n\nevent\n\nThe type of competition that the lifter entered. Values are as follows:\n\nSBD: Squat-Bench-Deadlift, also commonly called “Full Power”\nBD: Bench-Deadlift, also commonly called “Ironman” or “Push-Pull”\nSD: Squat-Deadlift, very uncommon\nSB: Squat-Bench, very uncommon\nS: Squat-only\nB: Bench-only\nD: Deadlift-only\n\n\n\n\nequipment\n\nThe equipment category under which the lifts were performed. Values are as follows:\n\nRaw: Bare knees or knee sleeves\nWraps: Knee wraps were allowed\nSingle-ply: Equipped, single-ply suits\nMulti-ply: Equipped, multi-ply suits (includes Double-ply)\nStraps: Allowed straps on the deadlift (used mostly for exhibitions, not real meets)\n\n\n\n\nage\nThe age of the lifter on the start date of the meet, if known.\n\n\nage_class\nThe age class in which the filter falls, for example 40-45\n\n\n\ndivision\nFree-form UTF-8 text describing the division of competition, like Open or Juniors 20-23 or Professional.\n\n\nbodyweight_kg\nThe recorded bodyweight of the lifter at the time of competition, to two decimal places.\n\n\nweight_class_kg\n\nThe weight class in which the lifter competed, to two decimal places.\nWeight classes can be specified as a maximum or as a minimum. Maximums are specified by just the number, for example 90 means “up to (and including) 90kg.” minimums are specified by a + to the right of the number, for example 90+ means “above (and excluding) 90kg.”\n\n\n\nbest3squat_kg\n\nMaximum of the first three successful attempts for the lift.\nRarely may be negative: that is used by some federations to report the lowest weight the lifter attempted and failed.\n\n\n\nbest3bench_kg\n\nMaximum of the first three successful attempts for the lift.\nRarely may be negative: that is used by some federations to report the lowest weight the lifter attempted and failed.\n\n\n\nbest3deadlift_kg\n\nMaximum of the first three successful attempts for the lift.\nRarely may be negative: that is used by some federations to report the lowest weight the lifter attempted and failed.\n\n\n\nplace\n\nThe recorded place of the lifter in the given division at the end of the meet. Values are as follows:\n\nPositive number: the place the lifter came in.\nG: Guest lifter. The lifter succeeded, but wasn’t eligible for awards.\nDQ: Disqualified. Note that DQ could be for procedural reasons, not just failed attempts.\nDD: Doping Disqualification. The lifter failed a drug test.\nNS: No-Show. The lifter did not show up on the meet day.\n\n\n\n\ndate\nISO 8601 Date of the event\n\n\nfederation\nThe federation that hosted the meet. (limited to IPF for this data subset)\n\n\nmeet_name\nThe name of the meet. The name is defined to never include the year or the federation. For example, the meet officially called 2019 USAPL Raw National Championships would have the MeetName Raw National Championshps.\n\n\n\nFor all of the following exercises, you should include units on axes labels, e.g. “Bench press (lbs)” or “Bench press (kg)”. “Age (years)” etc. This is good practice.\nExercise 1\n\nLet’s begin by taking a look at the squat lifting records.\nTo begin, remove any observations that are negative for squat. Next, create a new column called best3_squat_lbs that converts the record from kg to lbs (you may have to Google the conversion). Save your data frame as ipf_squat. Report the number of rows and columns of this new data frame.\n\n\n\n\n\n\n\nHint\n\n\n\nFirst, you’re taking a dataset and filtering it for certain records, and then you’re mutate-ing that dataset to gain a new column, and you’re assigning the resulting dataset to a new object called ipf_squat.\n\n\nExercise 2\n\nUsing ipf_squat from the previous exercise, create a scatter plot to investigate the relationship between squat (in lbs) and age. Age should be on the x-axis. Adjust the alpha level of your points to get a better sense of the density of the data. Add a linear trend-line. Be sure to label all axes and give the plot a title. Comment on what you observe.\n\nExercise 3\n\nWrite down the linear model to predict lift squat lbs from age in \\(x\\), \\(y\\), \\(\\beta\\) notation. What is \\(x\\)? What is \\(y\\)? Next, fit the linear model, and save it as age_fit. Re-write your previous equation replacing \\(\\beta\\) with the numeric estimates. This is called the “fitted” linear model. Interpret each estimate of \\(\\beta\\). Are the interpretations sensible?\n\nExercise 4\n\nBuilding on your ipf_squat data frame, create a new column called age2 that takes the age of each lifter and squares it. Save it to your data frame ipf_squat. Next, plot squat in lbs vs age2 and add a linear best fit line. Does this model look like it fits the data better?\n\n\n\n\n\n\n\nHint\n\n\n\nTo raise a value to a power, use ^ in R, e.g.: 2 ^ 2 gives you 4, 2 ^ 3 gives you 8, etc.\n\n\nExercise 5\n\nOne metric to assess the fit of a model is \\(R^2\\). Fit the age\\(^2\\) model and save the object as age2_fit. Compare \\(R^2\\) of the age\\(^2\\) model to the \\(R^2\\) of the model from Exercise 3. Which has a higher \\(R^2\\)?\n\nExercise 6\n\nNext, let’s turn our attention to dead lifting records.\nRecreate the plot below. Make sure axes and title labels are exactly matching, including spelling, capitalization, etc. Based on the plot below, which impacts deadlift weight more, age category or sex?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\nYou will need to create a couple of new columns. One to classify age appropriately and one to convert best3deadlift_kg to the plotted units (lbs). Notice that there are no negative deadlift values on the x-axis.\n\n\n\n\n\n\n\n\nHint 2\n\n\n\nThese plots are called density plots. It’s just a smoothed out version of a histogram, and like the histogram it lets you visualize the distribution (center, spread, skew, etc) of a dataset. The geom_... that creates density plots is geom_density. Try it out!\n\n\nExercise 7\n\nFinally, let’s turn our attention to bench press records.\nTo begin, remove any observations that are negative for bench press, create two new columns: best3bench_lbs and bodyweight_lbs. Save the result in a new data frame called ipf_bench.\nThen, create a scatter plot to investigate the relationship between best bench press (in lbs) and the lifter’s bodyweight (in lbs). Bodyweight should be on the x-axis. Add a linear trend-line. Be sure to label all axes and give the plot a title. Comment on what you observe.\n\nExercise 8\n\nFit the linear model displayed in the previous exercise and write down the fitted model equation only, replacing \\(\\hat{\\beta}\\)s with their fitted estimates. Interpret the \\(\\hat{\\beta}\\)s (intercept and slope). Report \\(R^2\\). Is body weight an important predictor of bench press ability? Why or why not?",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#part-2-ims-exercises",
    "href": "labs/lab-4.html#part-2-ims-exercises",
    "title": "Lab 4",
    "section": "Part 2: IMS Exercises",
    "text": "Part 2: IMS Exercises\nThe exercises in this section do not require code. Make sure to answer the questions in full sentences.\nExercise 9\n\nIMS - Chapter 7 exercises, #18: Over-under, II.\n\nExercise 10\n\nIMS - Chapter 7 exercises, #24: Cats weights.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#lastly",
    "href": "labs/lab-4.html#lastly",
    "title": "Lab 4",
    "section": "Lastly",
    "text": "Lastly\nRecommend some music for us to listen to while we grade this.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#wrap-up",
    "href": "labs/lab-4.html#wrap-up",
    "title": "Lab 4",
    "section": "Wrap up",
    "text": "Wrap up\nSubmitting\n\n\n\n\n\n\nImportant\n\n\n\nBefore you proceed, first, make sure that you have updated the document YAML with your name! Then, render your document one last time, for good measure.\n\n\nTo submit your assignment to Gradescope:\n\nGo to your Files pane and check the box next to the PDF output of your document (lab-4.pdf).\nThen, in the Files pane, go to More &gt; Export. This will download the PDF file to your computer. Save it somewhere you can easily locate, e.g., your Downloads folder or your Desktop.\nGo to the course Canvas page and click on Gradescope and then click on the assignment. You’ll be prompted to submit it.\nMark the pages associated with each exercise. All of the papers of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you fail to mark the pages associated with an exercise, that exercise won’t be graded. This means, if you fail to mark the pages for all exercises, you will receive a 0 on the assignment. The TAs can’t mark your pages for you, and for them to be able to grade, you must mark them.\n\n\nGrading\n\n\nExercise\nPoints\n\n\n\nExercise 1\n3\n\n\nExercise 2\n5\n\n\nExercise 3\n5\n\n\nExercise 4\n5\n\n\nExercise 5\n5\n\n\nExercise 6\n8\n\n\nExercise 7\n6\n\n\nExercise 8\n7\n\n\nExercise 9\n1\n\n\nExercise 10\n5\n\n\nTotal\n50",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "course-policies.html",
    "href": "course-policies.html",
    "title": "Policies",
    "section": "",
    "text": "As a student in this course, you have agreed to uphold the Duke Community Standard and the practices specific to this course.",
    "crumbs": [
      "Syllabus",
      "Course policies"
    ]
  },
  {
    "objectID": "course-policies.html#duke-community-standard",
    "href": "course-policies.html#duke-community-standard",
    "title": "Policies",
    "section": "",
    "text": "As a student in this course, you have agreed to uphold the Duke Community Standard and the practices specific to this course.",
    "crumbs": [
      "Syllabus",
      "Course policies"
    ]
  },
  {
    "objectID": "course-policies.html#collaboration",
    "href": "course-policies.html#collaboration",
    "title": "Policies",
    "section": "Collaboration",
    "text": "Collaboration\n\nYou are encouraged to discuss and help one another with the labs, but you should not share solutions (e.g. emailing a friend your code). All submitted work must be your own;\nYou are forbidden from collaborating in any way on the exams;\nYou are enthusiastically encouraged to collaborate with your teammates on all aspects of the final project.",
    "crumbs": [
      "Syllabus",
      "Course policies"
    ]
  },
  {
    "objectID": "course-policies.html#communication",
    "href": "course-policies.html#communication",
    "title": "Policies",
    "section": "Communication",
    "text": "Communication\nIf you wish to ask content-related questions in writing, please do not do so via e-mail. Instead, please use the course discussion forum Ed Discussion. That way all members of the teaching team can see your question, and all students can benefit from the ensuing discussion. You are also encouraged to answer one another’s questions.\nIf you have questions about personal matters that may not be appropriate for the public course forum (e.g. illness, accommodations, etc), then please e-mail the instructor directly (john.zito@duke.edu).",
    "crumbs": [
      "Syllabus",
      "Course policies"
    ]
  },
  {
    "objectID": "course-policies.html#use-of-online-resources-including-ai",
    "href": "course-policies.html#use-of-online-resources-including-ai",
    "title": "Policies",
    "section": "Use of online resources, including AI",
    "text": "Use of online resources, including AI\nYou may make use of any online resources (e.g. StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nYou should treat generative AI, such as ChatGPT, like other online resources. Two guiding principles govern how to use AI in this course:\n\nCognitive dimension: Working with AI should not reduce your thinking ability. We will practice using AI to facilitate—rather than hinder—learning.\nEthical dimension: Students using AI should be transparent about their use and ensure it aligns with academic integrity.\n\n\n AI tools for code: You may use the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. You may use these guidelines to cite AI-generated content. The bare minimum citation must include the AI tool you’re using (e.g., ChatGPT) and your prompt. The prompt you use cannot be copied and pasted directly from the assignment; you must create a prompt yourself.\n AI tools for narrative: Unless instructed otherwise, you may not use generative AI to generate a narrative that you then copy-paste verbatim into an assignment or edit and then insert into your assignment.\n\nIn general, you may use generative AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content. Identifying AI-generated content is fairly straightforward. Any code identified as AI-generated but not cited as such and any narrative identified as AI-generated will be considered plagiarism and treated as such.",
    "crumbs": [
      "Syllabus",
      "Course policies"
    ]
  },
  {
    "objectID": "course-policies.html#late-work-and-extensions",
    "href": "course-policies.html#late-work-and-extensions",
    "title": "Policies",
    "section": "Late work and extensions",
    "text": "Late work and extensions\nNo late work will be accepted unless you request an extension in advance by e-mailing the instructor (john.zito@duke.edu). All reasonable requests will be entertained, but extensions will not be long.",
    "crumbs": [
      "Syllabus",
      "Course policies"
    ]
  },
  {
    "objectID": "course-policies.html#regrade-requests",
    "href": "course-policies.html#regrade-requests",
    "title": "Policies",
    "section": "Regrade requests",
    "text": "Regrade requests\nIf you receive a graded assignment back, and you believe that some part of it was graded incorrectly, you may dispute it. You have one week after you receive a grade to submit a regrade request in Gradescope. The instructor will do the regrading.\n\n\n\n\n\n\nWarning\n\n\n\nA regrade request can result in your grade going up, staying the same, or going down if the instructor determines that, in fact, the original grader was too lenient.",
    "crumbs": [
      "Syllabus",
      "Course policies"
    ]
  },
  {
    "objectID": "ae/ae-02-flint-sa.html",
    "href": "ae/ae-02-flint-sa.html",
    "title": "Exploring Flint’s water data",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers for the application exercise. They’re not necessarily complete or 100% accurate, they’re roughly what we develop in class while going through the exercises."
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#rstudio",
    "href": "ae/ae-02-flint-sa.html#rstudio",
    "title": "Exploring Flint’s water data",
    "section": "RStudio",
    "text": "RStudio\n\nFiles, plots, viewer, environment, etc. panes\nConsole\nEditor"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#r",
    "href": "ae/ae-02-flint-sa.html#r",
    "title": "Exploring Flint’s water data",
    "section": "R",
    "text": "R\n\nWriting code in the console\nBasic math with R\nCreating variables in R, the assignment operator (&lt;-), and the Environment pane\nR functions and packages and the Packages pane\nGetting help with R and the Help pane"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#quarto",
    "href": "ae/ae-02-flint-sa.html#quarto",
    "title": "Exploring Flint’s water data",
    "section": "Quarto",
    "text": "Quarto\n\nYAML: Metadata\nNarrative: Edited with the visual editor (or the source editor)\nCode: In code chunks\n\nChunk options (following #|)\nComments (following #)\nCode\n\nRunning individual code chunks vs. rendering a document"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#load-packages",
    "href": "ae/ae-02-flint-sa.html#load-packages",
    "title": "Exploring Flint’s water data",
    "section": "Load packages",
    "text": "Load packages\nWe’ll use the tidyverse package for analysis, which offers functionality for data import, wrangling, visualization, and more.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nLoading this package prints out a message. What does this message mean? How can we suppress the message from the output?"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#load-data",
    "href": "ae/ae-02-flint-sa.html#load-data",
    "title": "Exploring Flint’s water data",
    "section": "Load data",
    "text": "Load data\nThe read_csv() function can be used for reading CSV (comma separated values) files. The file we’re reading is called flint with the suffix (.csv) which indicates its file type. The file is in the data folder.\nBefore reading in the file, go to the data folder in the Files pane to confirm that it is, indeed, there. Then, read the file by running the code chunk below by clicking on the green triangle icon on the code chunk.\n\nflint &lt;- read_csv(\"data/flint.csv\")\n\nRows: 813 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): draw\ndbl (4): id, zip, ward, lead\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nOne of two things may have happened:\n\nThe file was read successfully and you now see a dataset called flint in your Environment pane.\nThe file was not read successfully and you see an error Error in read_csv(\"data/flint.csv\") : could not find function \"read_csv\".\n\nIf (1) happened, great!\nIf (2) happened, let’s troubleshoot first before continuing."
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#data-dictionary",
    "href": "ae/ae-02-flint-sa.html#data-dictionary",
    "title": "Exploring Flint’s water data",
    "section": "Data dictionary",
    "text": "Data dictionary\nThe following variables are in the flint data frame:\n\nid: sample ID number (identifies the home)\nzip: ZIP code in Flint of the sample’s location\nward: ward in Flint of the sample’s location\ndraw: which time point the water was sampled from\nlead: lead content in parts per billion (ppb)"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#populations-and-samples",
    "href": "ae/ae-02-flint-sa.html#populations-and-samples",
    "title": "Exploring Flint’s water data",
    "section": "Populations and samples",
    "text": "Populations and samples\nWe want to learn about the population using a sample.\nIn the case we want to learn about the lead content in all of Flint, MI homes but only have available water readings from a sample of homes (our data set).\nExercise 1: Look at the data, how many observations are there? How many variables?\n\nThere are 813 observations and 5 variables.\n\n\nnrow(flint)\n\n[1] 813\n\nncol(flint)\n\n[1] 5"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#frequencies",
    "href": "ae/ae-02-flint-sa.html#frequencies",
    "title": "Exploring Flint’s water data",
    "section": "Frequencies",
    "text": "Frequencies\nLet’s count() to find the number of different time points water was sampled with the count() function.\n\nThe first argument is flint: the data frame\nThe second argument is draw: the variable\n\n\ncount(flint, draw)\n\n# A tibble: 3 × 2\n  draw       n\n  &lt;chr&gt;  &lt;int&gt;\n1 first    271\n2 second   271\n3 third    271\n\n\nWe can achieve the same result with the following “piped” operation as well.\n\nThe first line is flint: the data frame\nThen the pipe operator, read as “and then”, which places what comes before it as the first argument of what comes after it\nThe second line is count(draw)\n\n\nflint |&gt;\n  count(draw)\n\n# A tibble: 3 × 2\n  draw       n\n  &lt;chr&gt;  &lt;int&gt;\n1 first    271\n2 second   271\n3 third    271\n\n\nWe can use a similar approach to fund out how many unique homes are in the data set:\n\nflint |&gt;\n  count(id)\n\n# A tibble: 269 × 2\n      id     n\n   &lt;dbl&gt; &lt;int&gt;\n 1     1     3\n 2     2     3\n 3     4     3\n 4     5     3\n 5     6     3\n 6     7     3\n 7     8     3\n 8     9     3\n 9    12     3\n10    13     3\n# ℹ 259 more rows\n\n\nExercise 2: How many samples were taken from each zip code?\n\nflint |&gt;\n  count(zip)\n\n# A tibble: 8 × 2\n    zip     n\n  &lt;dbl&gt; &lt;int&gt;\n1 48502     3\n2 48503   207\n3 48504   165\n4 48505   144\n5 48506   132\n6 48507   153\n7 48529     3\n8 48532     6\n\n\nExercise 3: Which ZIP code had the most samples drawn? Hint: See the help for count.\n\nThe zip code 48503 had the most samples drawn (207 samples).\n\n\nflint |&gt;\n  count(zip, sort = TRUE)\n\n# A tibble: 8 × 2\n    zip     n\n  &lt;dbl&gt; &lt;int&gt;\n1 48503   207\n2 48504   165\n3 48507   153\n4 48505   144\n5 48506   132\n6 48532     6\n7 48502     3\n8 48529     3"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#measures-of-central-tendency",
    "href": "ae/ae-02-flint-sa.html#measures-of-central-tendency",
    "title": "Exploring Flint’s water data",
    "section": "Measures of central tendency",
    "text": "Measures of central tendency\n\nmean\nmedian\nmode"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#measures-of-spread",
    "href": "ae/ae-02-flint-sa.html#measures-of-spread",
    "title": "Exploring Flint’s water data",
    "section": "Measures of spread",
    "text": "Measures of spread\n\nvariance\nstandard deviation\nrange\nquartiles\ninter-quartile range (IQR)"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#order-statistics",
    "href": "ae/ae-02-flint-sa.html#order-statistics",
    "title": "Exploring Flint’s water data",
    "section": "Order statistics",
    "text": "Order statistics\n\nquantiles\nminimum (0 percentile)\nmedian (50th percentile)\nmaximum (100 percentile)\n\n… and any other arbitrary function of the data you can come up with!\nExercise 4: Compute each of these statistics for lead ppb.\n\nflint |&gt;\n  summarize(\n    mean_lead = mean(lead),\n    median_lead = median(lead),\n    var_lead = var(lead),\n    sd_lead = sd(lead),\n    # etc.\n  )\n\n# A tibble: 1 × 4\n  mean_lead median_lead var_lead sd_lead\n      &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1      8.20        1.85    1718.    41.5"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#histograms",
    "href": "ae/ae-02-flint-sa.html#histograms",
    "title": "Exploring Flint’s water data",
    "section": "Histograms",
    "text": "Histograms\nLet’s take a look at the distribution of lead content in homes in Flint, MI.\n\nggplot(flint, aes(x = lead)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWe can make this plot look nicer/more useful by adjusting the number of bins and zooming into the x-axis.\n\nggplot(flint, aes(x = lead)) +\n  geom_histogram(bins = 50) +\n  coord_cartesian(xlim = c(0, 100))\n\n\n\n\n\n\n\n\nLet’s visualize some of our summary statistics on the plot.\nExercise 5: Add a new layer, geom_vline(xintercept = __, color = \"red\"), to the histogram below, filling in the blank with the mean.\n\nggplot(flint, aes(x = lead)) + \n  geom_histogram(bins = 50) + \n  coord_cartesian(xlim = c(0, 100)) +\n  geom_vline(xintercept = 8.202614, color = \"red\")\n\n\n\n\n\n\n\n\nExercise 6: Add one more layer which overlays the median, in a different color.\n\nggplot(flint, aes(x = lead)) + \n  geom_histogram(bins = 50) + \n  coord_cartesian(xlim = c(0, 100)) +\n  geom_vline(xintercept = 8.202614, color = \"red\") +\n  geom_vline(xintercept = 1.852, color = \"blue\")"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#box-plots",
    "href": "ae/ae-02-flint-sa.html#box-plots",
    "title": "Exploring Flint’s water data",
    "section": "Box plots",
    "text": "Box plots\nNext, let’s narrow our focus to the zip codes 48503, 48504, 48505, 48506, and 48507 and observations with lead values less than 1,000 ppb.\n\nflint_focus &lt;- flint |&gt;\n  filter(zip %in% 48503:48507 & lead &lt; 1000)\n\nExercise 7: Below are side-by-side box plots for the three flushing times in each of the five zip codes we considered. Add x and y labels; add a title by inserting title = \"title_name\" inside the labs() function.\n\nggplot(data = flint_focus, aes(y = factor(zip), x = lead)) +\n  geom_boxplot(aes(fill = factor(draw))) +\n  labs(x = \"Lead (ppb)\", y = \"Zip code\", fill = \"Flushing time\") +\n  scale_fill_discrete(\n    breaks = c(\"first\", \"second\", \"third\"),\n    labels = c(\"0 (sec)\", \"45 (sec)\", \"120 (sec)\")\n  )\n\n\n\n\n\n\n\n\nExercise 8: Add labels for x, y, a title, and subtitle to the code below to update the corresponding plot.\n\nggplot(data = flint_focus, aes(y = factor(zip), x = lead)) +\n  geom_boxplot(aes(fill = factor(draw))) + \n  labs(\n    x = \"Lead (ppb)\", y = \"Zip code\", fill = \"Flushing time\",\n    title = \"Lead amount by flushing time\",\n    subtitle = \"In five zip codes\"\n    ) +\n  scale_fill_discrete(\n    breaks = c(\"first\", \"second\", \"third\"),\n    labels = c(\"0 (sec)\", \"45 (sec)\", \"120 (sec)\")\n  ) +\n  coord_cartesian(xlim = c(0, 50)) +\n  theme_bw()\n\n\n\n\n\n\n\n\nExercise 9: What is the difference between the two plots? What are the advantages and disadvantages to each plot?\n\nThe first plot shows the extreme outliers, while the second plot makes it easier to see the bulk of the distribution."
  },
  {
    "objectID": "ae/ae-04-durham.html",
    "href": "ae/ae-04-durham.html",
    "title": "2020 Durham City and County Resident Survey",
    "section": "",
    "text": "The main question we’ll explore today is “What are the demographics and priorities of City of Durham residents?”"
  },
  {
    "objectID": "ae/ae-04-durham.html#exercise-1",
    "href": "ae/ae-04-durham.html#exercise-1",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 1",
    "text": "Exercise 1\nHow many rows and columns are in this dataset? What does each row represent and what does each column represent?\nAdd your answer here."
  },
  {
    "objectID": "ae/ae-04-durham.html#exercise-2",
    "href": "ae/ae-04-durham.html#exercise-2",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 2",
    "text": "Exercise 2\nThe variables we’ll use in this analysis are as follows. Rename the variables to the updated names shown below.\n\n\n\nOriginal name\nUpdated name\n\n\n\n\nprimary_language\nprimary_language\n\n\ndo_you_own_or_rent_your_current_resi_31\nown_rent\n\n\nwould_you_say_your_total_annual_hous_35\nincome\n\n\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-durham.html#exercise-3",
    "href": "ae/ae-04-durham.html#exercise-3",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 3",
    "text": "Exercise 3\nWhat language do Durham residents speak: primary_language?\n\nWhat is the primary language used in your household?\n\nAdd your answer here.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-durham.html#exercise-4",
    "href": "ae/ae-04-durham.html#exercise-4",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 4",
    "text": "Exercise 4\nMake similar bar plots of own_rent and income. What distinct values do these variables take?\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-durham.html#exercise-5",
    "href": "ae/ae-04-durham.html#exercise-5",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 5",
    "text": "Exercise 5\nThe variables own_rent and income are both categorical, but they’re stored as numbers. In R, categorical data are called factors. Recode these variables as factors with the as_factor() function.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-durham.html#exercise-6",
    "href": "ae/ae-04-durham.html#exercise-6",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 6",
    "text": "Exercise 6\nRecreate the visualization from the previous exerciseincome` barplot, improving it for both visual appeal and better communication of findings.\nAdd your answer here.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-durham.html#exercise-7",
    "href": "ae/ae-04-durham.html#exercise-7",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 7",
    "text": "Exercise 7\nRecreate the visualization from the previous exercise, but first calculate relative frequencies (proportions) of income (the marginal distribution) and plot the proportions instead of counts.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-durham.html#exercise-8",
    "href": "ae/ae-04-durham.html#exercise-8",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 8",
    "text": "Exercise 8\nVisualize and describe the relationship between income and home ownership of Durham residents.\nStretch goal: Customize the colors using named colors from http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf.\nAdd your answer here.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-durham.html#exercise-9",
    "href": "ae/ae-04-durham.html#exercise-9",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 9",
    "text": "Exercise 9\nCalculate the proportions of home owners for each category of Durham residents. Describe the relationship between these two variables, this time with the actual values from the conditional distribution of home ownership based on income level.\nAdd your answer here.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-durham.html#exercise-10",
    "href": "ae/ae-04-durham.html#exercise-10",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 10",
    "text": "Exercise 10\nStretch goal: Recode the levels of these two variables to be more informatively labeled and calculate the proportions from the previous exercise again.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-04-durham.html#conceptual",
    "href": "ae/ae-04-durham.html#conceptual",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Conceptual",
    "text": "Conceptual\nSome of the terms we introduced are:\n\nMarginal distribution: Distribution of a single variable.\nConditional distribution: Distribution of a variable conditioned on the values (or levels, in the context of categorical data) of another."
  },
  {
    "objectID": "ae/ae-04-durham.html#r",
    "href": "ae/ae-04-durham.html#r",
    "title": "2020 Durham City and County Resident Survey",
    "section": "R",
    "text": "R\nIn this application exercise we:\n\nDefined factors – the data type that R uses for categorical variables, i.e., variables that can take on values from a finite set of levels.\n\n\n\nReviewed data imports, visualization, and wrangling functions encountered before:\n\nImport: read_csv(): Read data from a CSV (comma separated values) file\nVisualization:\n\nggplot(): Create a plot using the ggplot2 package\naes(): Map variables from the data to aesthetic elements of the plot, generally passed as an argument to ggplot() or to geom_*() functions (define only x or y aesthetic)\ngeom_bar(): Represent data with bars, after calculating heights of bars under the hood\nlabs(): Label x axis, y axis, legend for color of plot, title` of plot, etc.\n\nWrangling:\n\nmutate(): Mutate the data frame by creating a new column or overwriting one of the existing columns\ncount(): Count the number of observations for each level of a categorical variable (factor) or each distinct value of any other type of variable\ngroup_by(): Perform each subsequent action once per each group of the variable, where groups can be defined based on the levels of one or more variables\n\n\nIntroduced new data wrangling functions:\n\nrename(): Rename columns in a data frame\nas_factor(): Convert a variable to a factor\ndrop_na(): Drop rows that have NA in one ore more specified variables\nif_else(): Write logic for what happens if a condition is true and what happens if it’s not\ncase_when(): Write a generalized if_else() logic for more than one codition\n\nIntroduced new data visualization functions:\n\ngeom_col(): Represent data with bars (columns), for heights that have already been calculated (must define x and y aesthetics)\nscale_fill_viridis_d(): Customize the discrete fill scale, using a color-blind friendly, ordinal discrete color scale\nscale_y_discrete(): Customize the discrete y scale\nscale_fill_manual(): Customize the fill scale by manually adjusting values for colors"
  },
  {
    "objectID": "ae/ae-04-durham.html#quarto",
    "href": "ae/ae-04-durham.html#quarto",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Quarto",
    "text": "Quarto\nWe also introduced chunk options for managing figure sizes:\n\nfig-width: Width of figure\nfig-asp: Aspect ratio of figure (height / width)\nfig-height: Height of figure – but I recommend using fig-width and fig-asp, instead of fig-width and fig-height"
  },
  {
    "objectID": "ae/ae-04-durham-sa.html",
    "href": "ae/ae-04-durham-sa.html",
    "title": "2020 Durham City and County Resident Survey",
    "section": "",
    "text": "The main question we’ll explore today is “What are the demographics and priorities of City of Durham residents?”"
  },
  {
    "objectID": "ae/ae-04-durham-sa.html#exercise-1",
    "href": "ae/ae-04-durham-sa.html#exercise-1",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 1",
    "text": "Exercise 1\nHow many rows and columns are in this dataset? What does each row represent and what does each column represent?"
  },
  {
    "objectID": "ae/ae-04-durham-sa.html#exercise-2",
    "href": "ae/ae-04-durham-sa.html#exercise-2",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 2",
    "text": "Exercise 2\nThe variables we’ll use in this analysis are as follows. Rename the variables to the updated names shown below.\n\n\n\nOriginal name\nUpdated name\n\n\n\n\nprimary_language\nprimary_language\n\n\ndo_you_own_or_rent_your_current_resi_31\nown_rent\n\n\nwould_you_say_your_total_annual_hous_35\nincome\n\n\n\n\ndurham &lt;- durham |&gt;\n  rename(\n    own_rent = do_you_own_or_rent_your_current_resi_31,\n    income = would_you_say_your_total_annual_hous_35\n  )"
  },
  {
    "objectID": "ae/ae-04-durham-sa.html#exercise-3",
    "href": "ae/ae-04-durham-sa.html#exercise-3",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 3",
    "text": "Exercise 3\nWhat language do Durham residents speak: primary_language?\n\nWhat is the primary language used in your household?\n\n\nggplot(durham, aes(x = primary_language)) +\n  geom_bar()"
  },
  {
    "objectID": "ae/ae-04-durham-sa.html#exercise-4",
    "href": "ae/ae-04-durham-sa.html#exercise-4",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 4",
    "text": "Exercise 4\nMake similar bar plots of own_rent and income. What distinct values do these variables take?\n\nggplot(durham, aes(x = own_rent)) +\n  geom_bar()\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_count()`).\n\n\n\n\n\n\n\n\nggplot(durham, aes(x = income)) +\n  geom_bar()\n\nWarning: Removed 110 rows containing non-finite outside the scale range\n(`stat_count()`)."
  },
  {
    "objectID": "ae/ae-04-durham-sa.html#exercise-5",
    "href": "ae/ae-04-durham-sa.html#exercise-5",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 5",
    "text": "Exercise 5\nThe variables own_rent and income are both categorical, but they’re stored as numbers. In R, categorical data are called factors. Recode these variables as factors with the as_factor() function.\n\ndurham &lt;- durham |&gt;\n  mutate(\n    income = as_factor(income),\n    own_rent = as_factor(own_rent)\n    )"
  },
  {
    "objectID": "ae/ae-04-durham-sa.html#exercise-6",
    "href": "ae/ae-04-durham-sa.html#exercise-6",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 6",
    "text": "Exercise 6\nRecreate the visualization from the previous exercise, improving it for both visual appeal and better communication of findings.\n\ndurham |&gt;\n  ggplot(aes(y = income, fill = income)) +\n  geom_bar(show.legend = FALSE) +\n  labs(\n    x = \"Count\",\n    y = NULL,\n    title = \"Would you say your total annual household income is...\"\n  ) + \n  scale_y_discrete(\n    labels = c(\n      \"1\" = \"Under $30,000\",\n      \"2\" = \"$30,000-$59,999\",\n      \"3\" = \"$60,000-$99,999\",\n      \"4\" = \"$100,000 or more\"\n    )\n  )"
  },
  {
    "objectID": "ae/ae-04-durham-sa.html#exercise-7",
    "href": "ae/ae-04-durham-sa.html#exercise-7",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 7",
    "text": "Exercise 7\nRecreate the visualization from the previous exercise, but first calculate relative frequencies (proportions) of income (the marginal distribution) and plot the proportions instead of counts.\n\nmy_proportions &lt;- durham |&gt;\n  count(income) |&gt;\n  mutate(prop = n / sum(n))\n\n\nggplot(my_proportions, aes(y = income, x = prop, fill = income)) +\n  geom_col(show.legend = FALSE) +\n  scale_fill_viridis_d(na.value = \"gray\") +\n  labs(\n    x = \"Proportion\",\n    y = NULL,\n    title = \"Would you say your total annual household income is...\"\n  ) +   \n  scale_y_discrete(\n    labels = c(\n      \"1\" = \"Under $30,000\",\n      \"2\" = \"$30,000-$59,999\",\n      \"3\" = \"$60,000-$99,999\",\n      \"4\" = \"$100,000 or more\"\n    )\n  )"
  },
  {
    "objectID": "ae/ae-04-durham-sa.html#exercise-8",
    "href": "ae/ae-04-durham-sa.html#exercise-8",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 8",
    "text": "Exercise 8\nVisualize and describe the relationship between income and home ownership of Durham residents.\n\ndurham |&gt;\n  select(income, own_rent) |&gt;\n  drop_na() |&gt;\n  ggplot(aes(y = income, fill = own_rent)) +\n  geom_bar(position = \"fill\") +\n  scale_y_discrete(\n    labels = c(\n      \"1\" = \"Under $30,000\",\n      \"2\" = \"$30,000-$59,999\",\n      \"3\" = \"$60,000-$99,999\",\n      \"4\" = \"$100,000 or more\"\n    )\n  ) +\n  scale_fill_manual(\n    values = c(\"1\" = \"cadetblue\", \"2\" = \"coral\"),\n    labels = c(\"1\" = \"Own\", \"2\" = \"Rent\")\n  ) +\n  labs(\n    x = \"Proportion\",\n    y = \"Would you say your total\\nannual household income is...\",\n    fill = \"Do you own\\nor rent\\nyour current\\nresidence?\",\n    title = \"Income vs. home ownership of Durham residents\"\n  )"
  },
  {
    "objectID": "ae/ae-04-durham-sa.html#exercise-9",
    "href": "ae/ae-04-durham-sa.html#exercise-9",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 9",
    "text": "Exercise 9\nCalculate the proportions of home owners for each category of Durham residents. Describe the relationship between these two variables, this time with the actual values from the conditional distribution of home ownership based on income level.\n\ndurham |&gt;\n  select(income, own_rent) |&gt;\n  drop_na() |&gt;\n  count(income, own_rent) |&gt;\n  group_by(income) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   income [4]\n  income own_rent     n   prop\n  &lt;fct&gt;  &lt;fct&gt;    &lt;int&gt;  &lt;dbl&gt;\n1 1      1           51 0.362 \n2 1      2           90 0.638 \n3 2      1          105 0.565 \n4 2      2           81 0.435 \n5 3      1          107 0.552 \n6 3      2           87 0.448 \n7 4      1          160 0.930 \n8 4      2           12 0.0698"
  },
  {
    "objectID": "ae/ae-04-durham-sa.html#exercise-10",
    "href": "ae/ae-04-durham-sa.html#exercise-10",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Exercise 10",
    "text": "Exercise 10\nStretch goal: Recode the levels of these two variables to be more informatively labeled.\n\ndurham &lt;- durham |&gt;\n  mutate(\n    income = case_when(\n      income == \"1\" ~ \"Under $30,000\",\n      income == \"2\" ~ \"$30,000-$59,999\",\n      income == \"3\" ~ \"$60,000-$99,999\",\n      income == \"4\" ~ \"$100,000 or more\"      \n    ),\n    own_rent = if_else(own_rent == 1, \"Own\", \"Rent\")\n  )\n\ndurham |&gt;\n  select(income, own_rent) |&gt;\n  drop_na() |&gt;\n  count(income, own_rent) |&gt;\n  group_by(income) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   income [4]\n  income           own_rent     n   prop\n  &lt;chr&gt;            &lt;chr&gt;    &lt;int&gt;  &lt;dbl&gt;\n1 $100,000 or more Own        160 0.930 \n2 $100,000 or more Rent        12 0.0698\n3 $30,000-$59,999  Own        105 0.565 \n4 $30,000-$59,999  Rent        81 0.435 \n5 $60,000-$99,999  Own        107 0.552 \n6 $60,000-$99,999  Rent        87 0.448 \n7 Under $30,000    Own         51 0.362 \n8 Under $30,000    Rent        90 0.638"
  },
  {
    "objectID": "ae/ae-04-durham-sa.html#conceptual",
    "href": "ae/ae-04-durham-sa.html#conceptual",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Conceptual",
    "text": "Conceptual\nSome of the terms we introduced are:\n\nMarginal distribution: Distribution of a single variable.\nConditional distribution: Distribution of a variable conditioned on the values (or levels, in the context of categorical data) of another."
  },
  {
    "objectID": "ae/ae-04-durham-sa.html#r",
    "href": "ae/ae-04-durham-sa.html#r",
    "title": "2020 Durham City and County Resident Survey",
    "section": "R",
    "text": "R\nIn this application exercise we:\n\nDefined factors – the data type that R uses for categorical variables, i.e., variables that can take on values from a finite set of levels.\n\n\n\nReviewed data imports, visualization, and wrangling functions encountered before:\n\nImport: read_csv(): Read data from a CSV (comma separated values) file\nVisualization:\n\nggplot(): Create a plot using the ggplot2 package\naes(): Map variables from the data to aesthetic elements of the plot, generally passed as an argument to ggplot() or to geom_*() functions (define only x or y aesthetic)\ngeom_bar(): Represent data with bars, after calculating heights of bars under the hood\nlabs(): Label x axis, y axis, legend for color of plot, title` of plot, etc.\n\nWrangling:\n\nmutate(): Mutate the data frame by creating a new column or overwriting one of the existing columns\ncount(): Count the number of observations for each level of a categorical variable (factor) or each distinct value of any other type of variable\ngroup_by(): Perform each subsequent action once per each group of the variable, where groups can be defined based on the levels of one or more variables\n\n\nIntroduced new data wrangling functions:\n\nrename(): Rename columns in a data frame\nas_factor(): Convert a variable to a factor\ndrop_na(): Drop rows that have NA in one ore more specified variables\nif_else(): Write logic for what happens if a condition is true and what happens if it’s not\ncase_when(): Write a generalized if_else() logic for more than one codition\n\nIntroduced new data visualization functions:\n\ngeom_col(): Represent data with bars (columns), for heights that have already been calculated (must define x and y aesthetics)\nscale_fill_viridis_d(): Customize the discrete fill scale, using a color-blind friendly, ordinal discrete color scale\nscale_y_discrete(): Customize the discrete y scale\nscale_fill_manual(): Customize the fill scale by manually adjusting values for colors"
  },
  {
    "objectID": "ae/ae-04-durham-sa.html#quarto",
    "href": "ae/ae-04-durham-sa.html#quarto",
    "title": "2020 Durham City and County Resident Survey",
    "section": "Quarto",
    "text": "Quarto\nWe also introduced chunk options for managing figure sizes:\n\nfig-width: Width of figure\nfig-asp: Aspect ratio of figure (height / width)\nfig-height: Height of figure – but I recommend using fig-width and fig-asp, instead of fig-width and fig-height"
  },
  {
    "objectID": "ae/ae-03-delta.html",
    "href": "ae/ae-03-delta.html",
    "title": "COVID vaccine and deaths from Delta variant",
    "section": "",
    "text": "The main question we’ll explore today is “How do deaths from COVID cases compare between vaccinated and unvaccinated?”\nWhat do you think?"
  },
  {
    "objectID": "ae/ae-03-delta.html#exercise-1",
    "href": "ae/ae-03-delta.html#exercise-1",
    "title": "COVID vaccine and deaths from Delta variant",
    "section": "Exercise 1",
    "text": "Exercise 1\nHow many rows and columns are in this dataset? Answer in a full sentence using inline code. What does each row represent and what does each column represent? For each variable, identify its type.\nAdd your answer here."
  },
  {
    "objectID": "ae/ae-03-delta.html#exercise-2",
    "href": "ae/ae-03-delta.html#exercise-2",
    "title": "COVID vaccine and deaths from Delta variant",
    "section": "Exercise 2",
    "text": "Exercise 2\nDo these data come from an observational study or experiment? Why?\nAdd your answer here."
  },
  {
    "objectID": "ae/ae-03-delta.html#exercise-3",
    "href": "ae/ae-03-delta.html#exercise-3",
    "title": "COVID vaccine and deaths from Delta variant",
    "section": "Exercise 3",
    "text": "Exercise 3\nCreate a visualization of health outcome by vaccine status that allows you to compare the proportion of deaths across those who are and are not vaccinated. What can you say about death rates in these two groups based on this visualization?\nAdd your answer here.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-03-delta.html#exercise-4",
    "href": "ae/ae-03-delta.html#exercise-4",
    "title": "COVID vaccine and deaths from Delta variant",
    "section": "Exercise 4",
    "text": "Exercise 4\nCalculate the proportion of deaths in among those who are vaccinated. Then, calculate the proportion among those who are not vaccinated.\nAdd your answer here.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-03-delta.html#exercise-5",
    "href": "ae/ae-03-delta.html#exercise-5",
    "title": "COVID vaccine and deaths from Delta variant",
    "section": "Exercise 5",
    "text": "Exercise 5\nCreate the visualization and calculate proportions from the two previous exercises, this time controlling for age. How do the proportions compare?\nAdd your answer here.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-03-delta.html#exercise-6",
    "href": "ae/ae-03-delta.html#exercise-6",
    "title": "COVID vaccine and deaths from Delta variant",
    "section": "Exercise 6",
    "text": "Exercise 6\nBased on your findings so far, fill in the blanks with more, less, or equally: Is there anything surprising about these statements? Speculate on what, if anything, the discrepancy might be due to.\n\nIn 2021, among those in the UK who were COVID Delta cases, the vaccinated were ___ likely to die than the unvaccinated.\nFor those under 50, those who were unvaccinated were ___ likely to die than those who were vaccinated.\nFor those 50 and up, those who were unvaccinated were ___ likely to die than those who were vaccinated.\n\nAdd your answer here."
  },
  {
    "objectID": "ae/ae-03-delta.html#exercise-7",
    "href": "ae/ae-03-delta.html#exercise-7",
    "title": "COVID vaccine and deaths from Delta variant",
    "section": "Exercise 7",
    "text": "Exercise 7\nLet’s rephrase the previous question which asked you to speculate on why deaths among vaccinated cases overall is higher while deaths among unvaccinated cases are higher when we split the data into two groups (below 50 and 50 and up). What might be the confounding variable in the relationship between vaccination and deaths?\nAdd your answer here."
  },
  {
    "objectID": "ae/ae-03-delta.html#exercise-8",
    "href": "ae/ae-03-delta.html#exercise-8",
    "title": "COVID vaccine and deaths from Delta variant",
    "section": "Exercise 8",
    "text": "Exercise 8\nVisualize and describe the distribution of seniors (50 and up) based on (a.k.a. conditional on) vaccination status. Hint: Your description will benefit from calculating proportions of seniors in each of the vaccination groups and working those values into your narrative.\nAdd your answer here.\n\n# add your code here"
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Course overview",
    "section": "",
    "text": "Introduction to statistics as a science of understanding and analyzing data. Themes include data collection, exploratory analysis, inference, and modeling. Focus on principles underlying quantitative research in social sciences, humanities, and public policy. Research projects teach the process of scientific discovery and synthesis and critical evaluation of research and statistical arguments. Readings give perspective on why in 1950, S. Wilks said, ‘Statistical thinking will one day be as necessary a qualification for efficient citizenship as the ability to read and write.’\nPrerequisites: none.",
    "crumbs": [
      "Syllabus",
      "Overview"
    ]
  },
  {
    "objectID": "course-overview.html#course-description",
    "href": "course-overview.html#course-description",
    "title": "Course overview",
    "section": "",
    "text": "Introduction to statistics as a science of understanding and analyzing data. Themes include data collection, exploratory analysis, inference, and modeling. Focus on principles underlying quantitative research in social sciences, humanities, and public policy. Research projects teach the process of scientific discovery and synthesis and critical evaluation of research and statistical arguments. Readings give perspective on why in 1950, S. Wilks said, ‘Statistical thinking will one day be as necessary a qualification for efficient citizenship as the ability to read and write.’\nPrerequisites: none.",
    "crumbs": [
      "Syllabus",
      "Overview"
    ]
  },
  {
    "objectID": "course-overview.html#class-meetings",
    "href": "course-overview.html#class-meetings",
    "title": "Course overview",
    "section": "Class meetings",
    "text": "Class meetings\n\n\n\n\n\n\n\n\n\nMeeting\nLocation\nTime\nStaff\n\n\n\n\nLectures\nSocial Sciences 139\nTue, Thu 03:05 PM - 04:20 PM\nJohn Z\n\n\nLab 1\nPerkins LINK 087 (Classroom 3)\nFri 10:05 AM - 11:20 AM\nJohn G, Camilla\n\n\nLab 2\nPerkins LINK 087 (Classroom 3)\nFri 11:45 AM - 01:00 PM\nKatie, Meghna\n\n\nLab 3\nPerkins LINK 087 (Classroom 3)\nFri 01:25 PM - 02:40 PM\nLeah, Nichole\n\n\nLab 4\nPerkins LINK 087 (Classroom 3)\nFri 08:30 AM - 09:45 AM\nBenjamin, Sayali\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nFor reasons unknown to rational people, the labs are not exactly numbered in chronological order. “Lab 4” is in fact the first one of the day.",
    "crumbs": [
      "Syllabus",
      "Overview"
    ]
  },
  {
    "objectID": "course-team.html",
    "href": "course-team.html",
    "title": "Teaching team",
    "section": "",
    "text": "See the course schedule here.\n\n\n\n\n\n\n\n\n\nName\nRole\nLab section\nOffice hours\n\n\n\n\nJohn Zito\nInstructor\n\nThu 07:00 PM - 09:00 PM\nOld Chem 207\n\n\nLeah Johnson\nHead TA + Lab Leader\n3 (01:25 PM)\nWed 02:00 PM - 04:00 PM\nOld Chem 203B\n\n\nBenjamin Dahl\nLab Leader\n4 (08:30 AM)\nThu 08:00 AM - 10:00 AM\nOld Chem 203B\n\n\nJohn Gillen\nLab Leader\n1 (10:05 AM)\nSun 12:00 PM - 01:00 PM\nTue 05:00 PM - 06:00 PM\nZoom (Canvas)\n\n\nKatie Solarz\nLab Leader\n2 (11:45 AM)\nMon 4:30 PM - 6:30 PM\nOld Chem 203B\n\n\nCamilla Hanson\nLab Helper\n1 (10:05 AM)\nTue 12:00 PM - 01:00 PM\nWed 11:00 AM - 12:00 PM\nOld Chem 203B\n\n\nMeghna Katyal\nLab Helper\n2 (11:45 AM)\nMon 6:30 PM - 8:30 PM\nZoom (Canvas)\n\n\nSayali Pingle\nLab Helper\n4 (08:30 AM)\nMon 02:30 PM - 04:30 PM\nZoom (Canvas)\n\n\nNichole Zhang\nLab Helper\n3 (01:25 PM)\nWed 7:00 PM - 9:00 PM\nOld Chem 025\n\n\n\nIn addition to the teaching assistants, there is a peer tutor named Emilie Dorrestein that you can visit on Sundays at 05:00 PM - 06:00 PM (Perkins 413) and at 08:00 PM - 09:00 PM (Zoom – see Canvas for details).",
    "crumbs": [
      "Syllabus",
      "Teaching team"
    ]
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you can identify when that is without getting too frustrated and feel comfortable seeking help."
  },
  {
    "objectID": "course-support.html#lectures-and-labs",
    "href": "course-support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone."
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone’s office hours here."
  },
  {
    "objectID": "course-support.html#slack",
    "href": "course-support.html#slack",
    "title": "Course support",
    "section": "Slack",
    "text": "Slack\nHave a question that can’t wait for office hours? Prefer to write out your question in detail rather than asking in person? The course Slack is the best venue for these! There is a chance another student has already asked a similar question, so please check the other posts on Slack before asking a new question. If you know the answer to a question that is posted, I encourage you to respond!"
  },
  {
    "objectID": "course-support.html#email",
    "href": "course-support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nPlease refrain from emailing any course content questions (those should go to Slack), and only use email for questions about personal matters that may not be appropriate for the public course forum (e.g., illness, accommodations, etc.). For such matters, you may email Dr. Mine Çetinkaya-Rundel at mc301@duke.edu.\nIf there is a question that’s not appropriate for the public forum, you are welcome to email me directly. If you email me, please include “STA 101” in the subject line. Barring extenuating circumstances, I will respond to STA 101 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday."
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917."
  },
  {
    "objectID": "course-support.html#mental-health-and-wellness",
    "href": "course-support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\nStudent mental health and wellness are of primary importance at Duke, and the university offers resources to support students in managing daily stress and self-care. Duke offers several resources for students to seek assistance on coursework and to nurture daily habits that support overall well-being, some of which are listed below.\n\nThe Academic Resource Center: (919) 684-5917, theARC@duke.edu, or arc.duke.edu.\nDuWell: (919) 681-8421, provides Moments of Mindfulness (stress management and resilience building) and meditation programming to assist students in developing a daily emotional well-being practice. To see schedules for programs please see https://studentaffairs.duke.edu/duwell. All are welcome and no experience necessary.\n\nIf your mental health concerns and/or stressful events negatively affect your daily emotional state, academic performance, or ability to participate in your daily activities, many resources are available to help you through difficult times. Duke encourages all students to access these resources.\n\nDukeReach: Provides comprehensive outreach services to identify and support students in managing all aspects of well-being. If you have concerns about a student’s behavior or health visit the website for resources and assistance: http://studentaffairs.duke.edu/dukereach.\nCounseling and Psychological Services (CAPS): CAPS services include individual and group counseling services, psychiatric services, and workshops. To initiate services, walk-in/call-in 9-4 M,W,Th,F and 9-6 Tuesdays. CAPS also provides referral to off-campus resources for specialized care. (919) 660-1000 or https://students.duke.edu/wellness/caps.\nTimelyCare: (formerly known as Blue Devils Care) An online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling: https://bluedevilscare.duke.edu."
  },
  {
    "objectID": "course-support.html#course-costs",
    "href": "course-support.html#course-costs",
    "title": "Course support",
    "section": "Course costs",
    "text": "Course costs\n\nTextbooks: The textbooks for this course are freely available on the web.\nLaptops: Each student is expected to have a laptop they can bring to each lecture and lab.\n\nIf you are having difficulty with costs associated with this course, here are some resources:\n\nContact the financial aid office (whether or not you are on aid). They have loans and resources for connecting students with programs on campus that might be able to help alleviate these costs.\nDukeLIFE offers course materials assistance for eligible students. Please note that students who are eligible for DukeLIFE benefits are notified prior to the start of the semester; program resources are limited.\nDuke Libraries offers textbook rentals through the Top Textbook Program, where you can rent out a textbook for 3 hours at a time.\nFor course-specific technology needs such as Digital Voice Recorder, HD Video Camera, TI-84 Plus CE, DSLR camera kit, Tripod, Shotgun Mic, iPad Mini 4, a Handheld Projector, or a GoPro, you can reserve rental equipment from the Link."
  },
  {
    "objectID": "course-support.html#assistance-with-canvas-and-zoom",
    "href": "course-support.html#assistance-with-canvas-and-zoom",
    "title": "Course support",
    "section": "Assistance with Canvas and Zoom",
    "text": "Assistance with Canvas and Zoom\nFor technical help with Canvas or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Canvas here.\nNote that we will be making minimal use of Canvas in this course (primarily for announcements and grade book). All assignment submission will take place on Gradescope and conversation on Slack.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person."
  },
  {
    "objectID": "computing/computing-pipe.html",
    "href": "computing/computing-pipe.html",
    "title": "Piping",
    "section": "",
    "text": "A pipe in R is a way of stitching together many commands to make your code easier for a human to read, and to keep it from running off the pages of the PDF documents you will submit to us.",
    "crumbs": [
      "Computing primers",
      "Piping"
    ]
  },
  {
    "objectID": "computing/computing-pipe.html#a-very-silly-example",
    "href": "computing/computing-pipe.html#a-very-silly-example",
    "title": "Piping",
    "section": "A very silly example",
    "text": "A very silly example\nThese two code chunks do exactly the same thing:\n\nsum(1, 2)\n\n[1] 3\n\n\n\n1 |&gt;\n  sum(2)\n\n[1] 3\n\n\nSo the pipe operator |&gt; passes (or pipes), the number 1 into the sum function as the first input. In a simple example like this, sum(1, 2) is definitely the way I would write the code, but as things get more elaborate, you will want to pipe.",
    "crumbs": [
      "Computing primers",
      "Piping"
    ]
  },
  {
    "objectID": "computing/computing-pipe.html#tallying-stuff-up-in-a-spreadsheet",
    "href": "computing/computing-pipe.html#tallying-stuff-up-in-a-spreadsheet",
    "title": "Piping",
    "section": "Tallying stuff up in a spreadsheet",
    "text": "Tallying stuff up in a spreadsheet\nLet’s consider the COVID data set from class on 9/3/2024:\n\nlibrary(tidyverse)\n\ndelta &lt;- read_csv(\"delta.csv\")\n\n\n\n\n\n\n\nNote\n\n\n\nRecalling the information here, be prepared to adjust the file path to match how you have organized your files and folders.\n\n\nA row in this data set is a person, and we record whether or not that person died from/with COVID, and whether or not they were vaccinated. So there are four categories in all:\n\nunvaccinated and died\nunvaccinated and survived\nvaccinated and died\nvaccinated and survived\n\nThe following code creates a nifty lil’ table that tallies up the number of people in each group and calculates the proportion of people that died versus survived within each vaccination group:\n\ndelta |&gt;\n  count(vaccine, outcome) |&gt;\n  group_by(vaccine) |&gt;\n  mutate(prop = n / sum(n))\n\n# A tibble: 4 × 4\n# Groups:   vaccine [2]\n  vaccine      outcome       n    prop\n  &lt;chr&gt;        &lt;chr&gt;     &lt;int&gt;   &lt;dbl&gt;\n1 Unvaccinated died        250 0.00166\n2 Unvaccinated survived 150802 0.998  \n3 Vaccinated   died        477 0.00407\n4 Vaccinated   survived 116637 0.996  \n\n\nSo within each vaccination group, the numbers sum to one. This code is equivalent, but it provides a truly horrific reading experience:\n\n  mutate(group_by(count(delta, vaccine, outcome), vaccine), prop = n / sum(n))\n\n# A tibble: 4 × 4\n# Groups:   vaccine [2]\n  vaccine      outcome       n    prop\n  &lt;chr&gt;        &lt;chr&gt;     &lt;int&gt;   &lt;dbl&gt;\n1 Unvaccinated died        250 0.00166\n2 Unvaccinated survived 150802 0.998  \n3 Vaccinated   died        477 0.00407\n4 Vaccinated   survived 116637 0.996",
    "crumbs": [
      "Computing primers",
      "Piping"
    ]
  },
  {
    "objectID": "computing/computing-pipe.html#now-you-try",
    "href": "computing/computing-pipe.html#now-you-try",
    "title": "Piping",
    "section": "Now you try",
    "text": "Now you try\nThe COVID data contains another variable indicating whether or not the person was older or younger than fifty. Write some code (it will be very similar to the code above) that produces a table that breaks things down by vaccination status, outcome, and age. How many rows should this table contain?",
    "crumbs": [
      "Computing primers",
      "Piping"
    ]
  },
  {
    "objectID": "computing/computing-moving.html",
    "href": "computing/computing-moving.html",
    "title": "Moving files around",
    "section": "",
    "text": "We will distribute files to you (datasets, Quarto documents, etc) by placing them in the Files section of the course Canvas page:\n\nFrom there, you will download them to your computer. The best way to do this is by following the “three dots” on the right hand side of the file name:\n\nOnce you have downloaded a file to your computer, you can then upload it to your RStudio instance using the yellow button in the Files tab in the lower right:\n\nIt may be the case that you do not see your uploaded file right away. Try clicking the Home button to “refresh” the file list:\n\nThe Files section in your RStudio instance is like a lil’ Dropbox or Google Drive account that you can use to store your STA101-related files during the semester. I recommend keeping it organized with folders, like this:\n\nThis button creates new folders:\n\nTo move files between the folders, check the box to the left of the file you want to move, and go here:",
    "crumbs": [
      "Computing primers",
      "Moving files around"
    ]
  },
  {
    "objectID": "computing/computing-mlr.html",
    "href": "computing/computing-mlr.html",
    "title": "Multiple linear regression (with two predictors)",
    "section": "",
    "text": "The multiple linear regression model relates several predictors to a single response via a linear function with error. Here is what it looks like with two predictors:\n\\[\ny=\\beta_0+\\beta_1x_1+\\beta_2x_2+\\varepsilon.\n\\]\nThis primer leads you down the path of least resistance to fitting this model when one of the predictors (\\(x_1\\)) is a numerical variable and the other (\\(x_2\\)) is a categorical variable with two levels. You will learn how to…",
    "crumbs": [
      "Computing primers",
      "Multiple linear regression"
    ]
  },
  {
    "objectID": "computing/computing-mlr.html#setup",
    "href": "computing/computing-mlr.html#setup",
    "title": "Multiple linear regression (with two predictors)",
    "section": "Setup",
    "text": "Setup\nThe commands for plotting are in the tidyverse package, and the commands for working with linear regressions are in the tidymodels package, so we crank that up:\n\nlibrary(tidyverse) \nlibrary(tidymodels) \n\nNext consider the dataset allbacks from the DAAG package (you may need to install this):\n\nlibrary(DAAG) \n\nallbacks\n\n   volume area weight cover\n1     885  382    800    hb\n2    1016  468    950    hb\n3    1125  387   1050    hb\n4     239  371    350    hb\n5     701  371    750    hb\n6     641  367    600    hb\n7    1228  396   1075    hb\n8     412    0    250    pb\n9     953    0    700    pb\n10    929    0    650    pb\n11   1492    0    975    pb\n12    419    0    350    pb\n13   1010    0    950    pb\n14    595    0    425    pb\n15   1034    0    725    pb\n\n\nThe dataset has 15 observations and 4 columns. Each observation represents a book. Note that volume is measured in cubic centimeters and weight is measured in grams. More information on the dataset can be found in the documentation for allbacks, with ?allbacks.\nWe are interested in the relationship between book volume (\\(x_1\\)) and book weight (\\(y\\)), but as you can see if you view the spreadsheet, some of the books are hardcover and some are paperback. We might expect a hardcover book to weigh more than a paperback book with the same volume because of the different materials used, and so we should account for that.",
    "crumbs": [
      "Computing primers",
      "Multiple linear regression"
    ]
  },
  {
    "objectID": "computing/computing-mlr.html#creating-a-grouped-scatterplot",
    "href": "computing/computing-mlr.html#creating-a-grouped-scatterplot",
    "title": "Multiple linear regression (with two predictors)",
    "section": "Creating a grouped scatterplot",
    "text": "Creating a grouped scatterplot\nThis code creates a scatterplot of volume vs. weight where the points have different color and shape depending on the value of cover:\n\nggplot(allbacks, aes(x = volume, y = weight)) +\n  geom_point(aes(color = cover, shape = cover)) +\n  labs(\n    x = \"Volume (cubic centimeters)\",\n    y = \"Weight (grams)\"\n  )\n\n\n\n\n\n\n\n\nThe only difference between this code and a simple scatter plot is that we included an aesthetic mapping aes(color = cover, shape = cover) inside the call to geom_point. You’re asking it to alter the color and shape of the points depending on the value of the variable cover. The computer then made some default choices for you about what the different colors and shapes will be.",
    "crumbs": [
      "Computing primers",
      "Multiple linear regression"
    ]
  },
  {
    "objectID": "computing/computing-mlr.html#adding-lines-of-best-fit",
    "href": "computing/computing-mlr.html#adding-lines-of-best-fit",
    "title": "Multiple linear regression (with two predictors)",
    "section": "Adding lines of best fit",
    "text": "Adding lines of best fit\nIf we want to add lines of best fit for each group, we just have to add one new layer to our code above:\n\nggplot(allbacks, aes(x = volume, y = weight)) +\n  geom_point(aes(color = cover, shape = cover)) + \n  geom_smooth(aes(color = cover), method = \"lm\", se = F) +\n  labs(\n    x = \"Volume (cubic centimeters)\",\n    y = \"Weight (grams)\"\n  )\n\n\n\n\n\n\n\n\nAgain, the only difference between this code and the code that would generate one line of best fit is that we added an aesthetic mapping aes(color = cover) to the arguments of geom_smooth, and the computer knows to plot several lines for each level of the variable cover, which only has two levels in this case.\nAs we expected, the line of best fit for the paperback books is below the line for the hardcover books, capturing our intuition that, for the same volume, a hardcover book will weigh a bit more.",
    "crumbs": [
      "Computing primers",
      "Multiple linear regression"
    ]
  },
  {
    "objectID": "computing/computing-mlr.html#getting-the-actual-coefficient-estimates",
    "href": "computing/computing-mlr.html#getting-the-actual-coefficient-estimates",
    "title": "Multiple linear regression (with two predictors)",
    "section": "Getting the actual coefficient estimates",
    "text": "Getting the actual coefficient estimates\nThis code will give you a table with the estimates:\n\nweight_cover_fit &lt;- linear_reg() |&gt;\n  fit(weight ~ volume + cover, data = allbacks)\n\ntidy(weight_cover_fit)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic      p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept)  198.      59.2         3.34 0.00584     \n2 volume         0.718    0.0615     11.7  0.0000000660\n3 coverpb     -184.      40.5        -4.55 0.000672    \n\n\nSo the fitted model is\n\\[\n\\begin{align*}\n\\widehat{\\text{weight}}&=\\hat{\\beta}_0+\\hat{\\beta}_1{\\text{volume}}+\\hat{\\beta}_2{\\text{cover}}\\\\\n&\\approx197.96+0.71\\cdot{\\text{volume}}-184.05\\cdot{\\text{cover}}.\n\\end{align*}\n\\] The interpretation of these estimates is:\n\n197.96 is the weight you would predict for a hardback book with zero volume (it’s a little silly that this is not zero, which highlights one limitation of a linear model here);\n0.71 is the amount (in grams) you would predict the weight to increase by if the volume of the book increased by 1 cubic centimeter (remember, slope = rise/run, so \\(\\Delta\\text{weight}/\\Delta\\text{volume}\\) in this case);\n-184.05 is the amount by which the line shifts downward (because it’s negative) to account for the fact that paperback books will typically be lighter than hardcover, even keeping the volume constant.\n\nThe only difference from the code for simple linear regression is that we added variables to the formula weight ~ volume + cover in the fit command. So in general, if you have a data frame df with columns y, x1, x2, and so on, you can fit a multiple linear regression with code that will look something like this:\n\nmy_regression_fit &lt;- linear_reg() |&gt;\n  fit(y ~ x1 + x2 + x3, data = df)\n\nTo add more predictors, you just add them to the formula y ~ x1 + x2 + x3 + ....",
    "crumbs": [
      "Computing primers",
      "Multiple linear regression"
    ]
  },
  {
    "objectID": "computing/computing-mlr.html#compute-the-r2-values",
    "href": "computing/computing-mlr.html#compute-the-r2-values",
    "title": "Multiple linear regression (with two predictors)",
    "section": "Compute the \\(R^2\\) values",
    "text": "Compute the \\(R^2\\) values\nOnce you have created a regression object with the code like linear_reg() |&gt; fit(), you can view the \\(R^2\\) values with the glance function to assess the goodness-of-fit of the model. Here they are for the simple linear regression that just has volume as a predictor:\n\nweight_fit &lt;- linear_reg() |&gt;\n  fit(weight ~ volume, data = allbacks)\n\nglance(weight_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic    p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.803         0.787  124.      52.9 0.00000626     1  -92.5  191.  193.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\nHere they are for the multiple linear regression that has volume and cover as predictors:\n\nweight_fit &lt;- linear_reg() |&gt;\n  fit(weight ~ volume + cover, data = allbacks)\n\nglance(weight_cover_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic     p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.927         0.915  78.2      76.7 0.000000145     2  -85.0  178.  181.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\nWe see that adjusted \\(R^2\\) increased substantially when we added cover as a predictor, supporting our intuition that including this covariate to the model ought to improve fit.",
    "crumbs": [
      "Computing primers",
      "Multiple linear regression"
    ]
  },
  {
    "objectID": "computing/computing-barplot.html",
    "href": "computing/computing-barplot.html",
    "title": "Barplot basics",
    "section": "",
    "text": "A barplot is similar to a histogram, but instead of visualizing numerical data, we are visualizing categorical data. Each bar in the chart is counting the number of observations (rows) that correspond to each level of the categorical variable.",
    "crumbs": [
      "Computing primers",
      "Barplot basics"
    ]
  },
  {
    "objectID": "computing/computing-barplot.html#load-a-data-set",
    "href": "computing/computing-barplot.html#load-a-data-set",
    "title": "Barplot basics",
    "section": "Load a data set",
    "text": "Load a data set\n\nlibrary(tidyverse)\n\nLet’s load the data from the 2020 Durham City and County Resident Survey (originally in the Canvas lecture 4 folder), where each row is a Durham resident:\n\ndurham &lt;- read_csv(\"durham-2020.csv\")\n\n\n\n\n\n\n\nNote\n\n\n\nRecalling the information here, be prepared to adjust the file path to match how you have organized your files and folders.\n\n\nOne of the columns in this data set is a categorical variable called would_you_say_your_total_annual_hous_35, with four levels corresponding to the resident’s income:\n\nUnder $30,000;\n$30,000-$59,999\n$60,000-$99,999\n$100,000 or more\n\nFurthermore, some folks left this part of the survey blank, and so their income information is missing, which effectively creates a fifth category. Before plotting, let us quickly modify the data to give this income variable a more concise name, as well as making it a proper factor type in R:\n\ndurham &lt;- durham |&gt;\n  rename(income = would_you_say_your_total_annual_hous_35) |&gt;\n  mutate(income = as_factor(income))",
    "crumbs": [
      "Computing primers",
      "Barplot basics"
    ]
  },
  {
    "objectID": "computing/computing-barplot.html#the-basic-plot",
    "href": "computing/computing-barplot.html#the-basic-plot",
    "title": "Barplot basics",
    "section": "The basic plot",
    "text": "The basic plot\n\nggplot(durham, aes(x = income)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nThe basic template here is very similar to what we saw for the histogram. The first layer uses ggplot to indicate what data you wish to plot. Then the next layer uses geom_bar to specifically make it a bar plot.\nIn the first layer we used x = inside aes to make the bars vertical, but we could have made them horizontal as well:\n\nggplot(durham, aes(y = income)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nDo you see what changed?",
    "crumbs": [
      "Computing primers",
      "Barplot basics"
    ]
  },
  {
    "objectID": "computing/computing-barplot.html#adding-layers-to-prettify-it",
    "href": "computing/computing-barplot.html#adding-layers-to-prettify-it",
    "title": "Barplot basics",
    "section": "Adding layers to prettify it",
    "text": "Adding layers to prettify it\nWe could call it a day at this point, but the basic plot is rather drab. Here is some code that would zhuzh it up in a big way:\n\ndurham |&gt;\n  ggplot(aes(y = income, fill = income)) +\n  geom_bar(show.legend = FALSE) +\n  labs(\n    x = \"Count\",\n    y = NULL,\n    title = \"Would you say your total annual household income is...\"\n  ) + \n  scale_y_discrete(\n    labels = c(\n      \"1\" = \"Under $30,000\",\n      \"2\" = \"$30,000-$59,999\",\n      \"3\" = \"$60,000-$99,999\",\n      \"4\" = \"$100,000 or more\"\n    )\n  )\n\n\n\n\n\n\n\n\n\nThe first ggplot layer tells it what data to use. We also added the fill = argument inside aes to apply a default color scheme;\nthe labs layer allows us to add a title and label the axes;\nthe scale_y_discrete layer allows us to replace the bar labels 1, 2, 3, 4 with more informative text that explains what the levels of the variable actually mean;\nin between every layer, we have a +. Gotta have that icing!",
    "crumbs": [
      "Computing primers",
      "Barplot basics"
    ]
  },
  {
    "objectID": "computing/computing-histograms.html",
    "href": "computing/computing-histograms.html",
    "title": "Histogram basics",
    "section": "",
    "text": "A histogram displays the distribution or variability of numerical data. It shows you where the data values are typically concentrated, how spread out they are, and whether or not there are any asymmetries.\nThis primer leads you down the path of least resistance to producing a histogram plot using R. Trust me; you would not want to do this by hand.",
    "crumbs": [
      "Computing primers",
      "Histogram basics"
    ]
  },
  {
    "objectID": "computing/computing-histograms.html#loading-a-package",
    "href": "computing/computing-histograms.html#loading-a-package",
    "title": "Histogram basics",
    "section": "Loading a package",
    "text": "Loading a package\nThe command for plotting a histogram is contained inside the tidyverse package, so you need to load that first:\n\nlibrary(tidyverse)",
    "crumbs": [
      "Computing primers",
      "Histogram basics"
    ]
  },
  {
    "objectID": "computing/computing-histograms.html#loading-a-dataset",
    "href": "computing/computing-histograms.html#loading-a-dataset",
    "title": "Histogram basics",
    "section": "Loading a dataset",
    "text": "Loading a dataset\nNext, we need something to plot, so let us load in a data set. We will consider the flint water data that was mentioned during the second lecture on 8/29/2024:\n\nflint &lt;- read_csv(\"flint.csv\")\n\nLet us unpack what this is doing:\n\nread_csv is a function, just like \\(f(x)=x^2\\) or \\(f(x)=ax+b\\) from your math class. It receives an input, and returns an output. The input is the name of a file: \"flint.csv\". The output is a data frame (a spreadsheet) in R;\nWhen you run read_csv, it returns a data frame. But if you don’t give that data frame a name and store it someplace, then you can’t actually use it. So that’s what the flint &lt;- part is doing. You are assigning the output of read_csv to a variable named “flint.” If this went as planned, you should see flint listed in the upper right Environment tab of RStudio:\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nRecalling the information here, you may have to modify the file path to something like \"~/lecture-2/flint.csv\" to match the particular way you have chosen to name and organize your files and folders.",
    "crumbs": [
      "Computing primers",
      "Histogram basics"
    ]
  },
  {
    "objectID": "computing/computing-histograms.html#plotting-a-histogram",
    "href": "computing/computing-histograms.html#plotting-a-histogram",
    "title": "Histogram basics",
    "section": "Plotting a histogram",
    "text": "Plotting a histogram\nHere is the basic command in all its glory:\n\nggplot(flint, aes(x = lead)) +\n  geom_histogram(bins = 250) + \n  coord_cartesian(xlim = c(0, 100))\n\n\n\n\n\n\n\n\nNow let’s talk about it:\n\nggplot(flint, aes(x = lead)) is where we tell R what data frame we are using (flint) and which variable (column) in that data set we want to plot (lead);\nNext, we use geom_histogram(bins = 250) to tell it that we specifically want a histogram with 250 bins;\nLast, we use coord_cartesian(xlim = c(0, 100)) to adjust the bounds of the horizontal axis: start at x = 0 and end at x = 100;\nWe stitch all of these requests together using the + sign, and to make things more readable (not run off the page), we put a new line after each +.",
    "crumbs": [
      "Computing primers",
      "Histogram basics"
    ]
  },
  {
    "objectID": "computing/computing-histograms.html#adding-a-vertical-line-to-the-histogram",
    "href": "computing/computing-histograms.html#adding-a-vertical-line-to-the-histogram",
    "title": "Histogram basics",
    "section": "Adding a vertical line to the histogram",
    "text": "Adding a vertical line to the histogram\nWhen plotting a histogram, it can also be useful to indicate on the plot the location of some particularly meaningful summary statistics, such as the mean or median. In order to do this, we can use the same basic command from the previous section, but then add some extra layers that will place vertical lines on the plot at those values:\n\nmean_value &lt;- mean(flint$lead)\nmedian_value &lt;- median(flint$lead)\n\nggplot(flint, aes(x = lead)) +\n  geom_histogram(bins = 250) + \n  coord_cartesian(xlim = c(0, 100)) + \n  geom_vline(xintercept = mean_value, color = \"red\") + \n  geom_vline(xintercept = median_value, color = \"blue\")\n\n\n\n\n\n\n\n\nNotice that the distribution of lead levels is positively skewed, which results in the mean being larger than the median.",
    "crumbs": [
      "Computing primers",
      "Histogram basics"
    ]
  },
  {
    "objectID": "computing/computing-histograms.html#now-you-try",
    "href": "computing/computing-histograms.html#now-you-try",
    "title": "Histogram basics",
    "section": "Now you try",
    "text": "Now you try\nTo double check that you can follow these instructions, redo everything above using a different data set. This may require you to modify the code in various ways:\n\nthe file path you provide to read_csv;\nthe name you assign to the resulting data frame;\nthe variable you plot in aes(x = lead);\nthe number of histogram bins;\nthe range of the horizontal axis.\n\nCheck that you are comfortable making these changes.",
    "crumbs": [
      "Computing primers",
      "Histogram basics"
    ]
  }
]