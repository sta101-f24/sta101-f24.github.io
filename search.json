[
  {
    "objectID": "lectures/01/01-welcome.html#teaching-team",
    "href": "lectures/01/01-welcome.html#teaching-team",
    "title": "Welcome to STA 101",
    "section": "Teaching team",
    "text": "Teaching team\n\n\nInstructor\nDr. Mine Çetinkaya-Rundel\nOld Chem 213\nmc301@duke.edu\n\nTeaching assistants\n\n\n\nShuo Wang\nHead + Lab TA\n\n\nSylvia Vincent\nLab TA\n\n\nJohn Gillen\nLab TA\n\n\nChris Oswald\nLab TA\n\n\nMinh Anh To\nTA\n\n\nHao Wang\nTA\n\n\nNoah Obuya\nTA\n\n\nMeghna Katyal\nTA\n\n\nAvery Hodges\nTA"
  },
  {
    "objectID": "lectures/01/01-welcome.html#timetable",
    "href": "lectures/01/01-welcome.html#timetable",
    "title": "Welcome to STA 101",
    "section": "Timetable",
    "text": "Timetable\n\nLectures at Gross Hall 103: Mon + Wed 1:25 - 2:40 pm\nLabs at Perkins LINK 087 (Classroom 3)\n\nLab 1: Fri 8:30 - 9:45 am\nLab 2: Fri 10:05 - 11:20 am\nLab 3: Fri 11:45 am - 1:00 pm\nLab 4: Fri 1:25 - 2:40 pm"
  },
  {
    "objectID": "lectures/01/01-welcome.html#learning-objectives",
    "href": "lectures/01/01-welcome.html#learning-objectives",
    "title": "Welcome to STA 101",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nRecognize the importance of data collection, identify limitations in data collection methods, and determine how they affect the scope of inference.\nUse statistical software to summarize data numerically and visually, and to perform data analysis.\nHave a conceptual understanding of the unified nature of statistical inference.\nApply estimation and testing methods to analyze single variables or the relationship between two variables in order to understand natural phenomena and make data-based decisions.\nModel numerical response variables using a single or multiple explanatory variables.\nInterpret results correctly, effectively, and in context without relying on statistical jargon.\nCritique data-based claims and evaluate data-based decisions.\nComplete research projects demonstrating mastery of statistical data analysis from exploratory analysis to inference to modeling."
  },
  {
    "objectID": "lectures/01/01-welcome.html#lets-play-a-game",
    "href": "lectures/01/01-welcome.html#lets-play-a-game",
    "title": "Welcome to STA 101",
    "section": "Let’s play a game!",
    "text": "Let’s play a game!\n\n\nForm a small group (2-4 people) with people sitting around you\nFirst, introduce yourselves to each other – name (and proper pronunciation of name), year, major, where are you from, etc.\nPlay the game: https://nyti.ms/3suUJHG"
  },
  {
    "objectID": "lectures/01/01-welcome.html#course-website",
    "href": "lectures/01/01-welcome.html#course-website",
    "title": "Welcome to STA 101",
    "section": "Course website",
    "text": "Course website\n\nsta101-f23.github.io\n\n\naka “the one link to rule them all”"
  },
  {
    "objectID": "lectures/01/01-welcome.html#lectures",
    "href": "lectures/01/01-welcome.html#lectures",
    "title": "Welcome to STA 101",
    "section": "Lectures",
    "text": "Lectures\n\nIn person\nAttendance is required (as long as you’re healthy!)\nA little bit of everything:\n\nTraditional lecture\nLive coding + demos\nShort exercises + solution discussion\n\nRecordings will be posted after class – to be used for review + make-up if you can’t make it to class due to health reasons, they’re not an alternative to class attendance"
  },
  {
    "objectID": "lectures/01/01-welcome.html#labs",
    "href": "lectures/01/01-welcome.html#labs",
    "title": "Welcome to STA 101",
    "section": "Labs",
    "text": "Labs\n\nAttendance is required (as long as you’re healthy!)\nOpportunity to work on course assignments with TA support\nOpportunity to work with teammates on projects"
  },
  {
    "objectID": "lectures/01/01-welcome.html#announcements",
    "href": "lectures/01/01-welcome.html#announcements",
    "title": "Welcome to STA 101",
    "section": "Announcements",
    "text": "Announcements\n\nPosted on Canvas (Announcements) and sent via email, be sure to check both regularly\nI’ll assume that you’ve read an announcement by the next “business” day"
  },
  {
    "objectID": "lectures/01/01-welcome.html#diversity-and-inclusion",
    "href": "lectures/01/01-welcome.html#diversity-and-inclusion",
    "title": "Welcome to STA 101",
    "section": "Diversity and inclusion",
    "text": "Diversity and inclusion\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know! Add your name pronunciation to your Canvas and Slack profiles.\nPlease let me know your preferred pronouns and add these to your Canvas and Slack profiles.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. I want to be a resource for you. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "lectures/01/01-welcome.html#accessibility",
    "href": "lectures/01/01-welcome.html#accessibility",
    "title": "Welcome to STA 101",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nWe will have in class exams. If you need special accommodations, please book the testing center ASAP!\nI am committed to making all course materials accessible and I’m always learning how to do this better. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "lectures/01/01-welcome.html#attendance-participation-5",
    "href": "lectures/01/01-welcome.html#attendance-participation-5",
    "title": "Welcome to STA 101",
    "section": "Attendance + participation (5%)",
    "text": "Attendance + participation (5%)\n\nRequired throughout the semester in lecture and lab\nStudents who attend at least 80% of the lectures and participate regularly in lecture and/or other course venues (lab + Slack) will receive full credit for this portion of their grade\nParticipation in labs as well as on Slack will also count towards this component\n\n\n\n\n\n\n\nTip\n\n\nIf you attend at least 80% of the classes, you’ll get all available points for this component."
  },
  {
    "objectID": "lectures/01/01-welcome.html#interactive-tutorials-5",
    "href": "lectures/01/01-welcome.html#interactive-tutorials-5",
    "title": "Welcome to STA 101",
    "section": "Interactive tutorials (5%)",
    "text": "Interactive tutorials (5%)\n\nOnline, individual, can discuss with classmates\nCover reading that is due since the previous quiz and up to and including the deadline for the given quiz\nMake sure to fill out your name and Net ID prior to generating the hash to submit (more info on this coming soon)\nDue by 5 pm ET (on the indicated day on the course schedule\n\n\n\n\n\n\n\nTip\n\n\nIf you complete at least 80% of the tutorials, you’ll get all available points for this component."
  },
  {
    "objectID": "lectures/01/01-welcome.html#labs-25",
    "href": "lectures/01/01-welcome.html#labs-25",
    "title": "Welcome to STA 101",
    "section": "Labs (25%)",
    "text": "Labs (25%)\n\nSubmitted on Gradescope, individual, can discuss with classmates\nLab sessions allocated to working on assignments and getting feedback from TAs\nDue by 5 pm ET on the indicated day on the course schedule\nWeekly deadlines to keep you on track, hard deadlines by exams or end of class\n\n\n\n\n\n\n\nTip\n\n\nLowest lab score is dropped, whether it’s an actual low score or a 0 from not turning it in."
  },
  {
    "objectID": "lectures/01/01-welcome.html#exams",
    "href": "lectures/01/01-welcome.html#exams",
    "title": "Welcome to STA 101",
    "section": "Exams",
    "text": "Exams\n\nTwo exams, each 20%\nEach exam comprised of two parts:\n\nIn class: 75 minute in-class exam. Closed book, one sheet of notes (“cheat sheet”, no larger than 8 1/2 x 11, both sides, must be prepared by you) – 70% of the grade\nTake home: 48 hours to complete the take home portion. The take home portion will follow from the in class exam and focus on the analysis of a dataset introduced in the take home exam – 30% of the grade\n\n\n\n\n\n\n\n\nCaution\n\n\nExam dates cannot be changed and no make-up exams will be given. If you can’t take the exams on these dates, you should drop this class."
  },
  {
    "objectID": "lectures/01/01-welcome.html#projects",
    "href": "lectures/01/01-welcome.html#projects",
    "title": "Welcome to STA 101",
    "section": "Projects",
    "text": "Projects\n\nProject 1 (10%)\n\nSame data, regression\nWrite-up only\n\nProject 2 (15%)\n\nDataset of your choice, method of your choice\nNew team\nPresentation and write-up\nPresentations on the final exam date\n\nInterim deadlines, peer review on content, peer evaluation for team contribution\nSome lab sessions allocated to working on projects, doing peer review, getting feedback from TAs\n\n\n\n\n\n\n\nCaution\n\n\nFinal presentation date cannot be changed. If you can’t present on that date, you should drop this class."
  },
  {
    "objectID": "lectures/01/01-welcome.html#teams",
    "href": "lectures/01/01-welcome.html#teams",
    "title": "Welcome to STA 101",
    "section": "Teams",
    "text": "Teams\n\nTeamwork\n\nProjects (required), in class exercises (recommended)\nAssigned different teams for each project\nPeer evaluation during teamwork and after completion\n\nExpectations and roles\n\nEveryone is expected to contribute equal effort\nEveryone is expected to understand all code turned in\nIndividual contribution evaluated by peer evaluation, commits, etc."
  },
  {
    "objectID": "lectures/01/01-welcome.html#covid-policies",
    "href": "lectures/01/01-welcome.html#covid-policies",
    "title": "Welcome to STA 101",
    "section": "COVID policies",
    "text": "COVID policies\n\nWear a mask if the university requires\nStay home if you’re sick and follow guidance\nRead and follow university guidance"
  },
  {
    "objectID": "lectures/01/01-welcome.html#late-work-policy",
    "href": "lectures/01/01-welcome.html#late-work-policy",
    "title": "Welcome to STA 101",
    "section": "Late work policy",
    "text": "Late work policy\n\nInteractive tutorials: Late submissions past the hard deadlines not accepted\nLabs:\n\nLate, but within 24 hours of deadline: -20% of available points\nAny later: No credit, and we will not provide written feedback\nNote that lowest lab score will be dropped, even if that score is a 0\n\nProject write-ups:\n\nLate, but within 24 hours of deadline: -20% of available points\nAny later: No credit, and we will not provide written feedback\nTwo days late or later: No credit, and we will not provide written feedback\n\nProject presentation: Late submissions not accepted\nPeer evaluation:\n\nLate submissions not accepted\nMust turn in peer evaluation if you want your own score from others"
  },
  {
    "objectID": "lectures/01/01-welcome.html#collaboration-policy",
    "href": "lectures/01/01-welcome.html#collaboration-policy",
    "title": "Welcome to STA 101",
    "section": "Collaboration policy",
    "text": "Collaboration policy\n\nOnly work that is clearly assigned as team work should be completed collaboratively (projects)\nExams must be completed individually, you may not discuss answers with teammates, clarification questions should only be asked to myself and the TAs\nLabs must be completed individually. You may not directly share answers / code with others, however you are welcome to discuss the problems in general and ask for advice"
  },
  {
    "objectID": "lectures/01/01-welcome.html#sharing-reusing-code-policy",
    "href": "lectures/01/01-welcome.html#sharing-reusing-code-policy",
    "title": "Welcome to STA 101",
    "section": "Sharing / reusing code policy",
    "text": "Sharing / reusing code policy\n\nWe are aware that a huge volume of code is available on the web, and many tasks may have solutions posted\nUnless explicitly stated otherwise, this course’s policy is that you may make use of any online resources (e.g., StackOverflow) but you must explicitly cite where you obtained any code you directly use or use as inspiration in your solution(s)\nAny recycled code that is discovered and is not explicitly cited will be treated as plagiarism, regardless of source"
  },
  {
    "objectID": "lectures/01/01-welcome.html#generative-ai-policy",
    "href": "lectures/01/01-welcome.html#generative-ai-policy",
    "title": "Welcome to STA 101",
    "section": "Generative AI policy",
    "text": "Generative AI policy\nYou should treat generative AI, such as ChatGPT, the same as other online resources. There are two guiding principles that govern how you can use AI in this course:1\n(1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning.\n(2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\n✅ AI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\n❌ AI tools for narrative: Unless instructed otherwise, you may not use generative AI to write narrative on assignments. In general, you may use generative AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content.\n\nThese guiding principles are based on Course Policies related to ChatGPT and other AI Tools developed by Joel Gladd, Ph.D."
  },
  {
    "objectID": "lectures/01/01-welcome.html#academic-integrity",
    "href": "lectures/01/01-welcome.html#academic-integrity",
    "title": "Welcome to STA 101",
    "section": "Academic integrity",
    "text": "Academic integrity\nTo uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\n\n\nmost importantly:\nask if you’re not sure if something violates a policy!"
  },
  {
    "objectID": "lectures/01/01-welcome.html#office-hours",
    "href": "lectures/01/01-welcome.html#office-hours",
    "title": "Welcome to STA 101",
    "section": "Office hours",
    "text": "Office hours\n\nMine: Tuesdays 3:30 - 4:30 pm - Old Chem 213 + by appointment (on Zoom or in person depending on day/time)\nTAs: See the course team and course support pages on the course website. We have a total of 17 TA office hours per week!\n+ lots more resources listed on the syllabus!"
  },
  {
    "objectID": "lectures/01/01-welcome.html#wellness",
    "href": "lectures/01/01-welcome.html#wellness",
    "title": "Welcome to STA 101",
    "section": "Wellness",
    "text": "Wellness\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don’t hesitate to ask.\n\nYou never owe me personal information about your health (mental or physical) but you’re always welcome to talk to me. If I can’t help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded."
  },
  {
    "objectID": "lectures/01/01-welcome.html#rstudio",
    "href": "lectures/01/01-welcome.html#rstudio",
    "title": "Welcome to STA 101",
    "section": "RStudio",
    "text": "RStudio\n\nhttps://posit.cloud\n\n\nBrowser based RStudio instance(s) provided by Posit\nRequires internet connection to access\nProvides consistency in hardware and software environments\nLocal R installations are fine but we will not guarantee support"
  },
  {
    "objectID": "lectures/01/01-welcome.html#slack",
    "href": "lectures/01/01-welcome.html#slack",
    "title": "Welcome to STA 101",
    "section": "Slack",
    "text": "Slack\n\nOnline forum for asking and answering questions\nPrivate repo in the course organization\nYou will need to join the course organization for access\nAsk and answer questions related to course logistics, assignment, etc. here\nPersonal questions (e.g., extensions, illnesses, etc.) should be via email to me\nOnce you join, browse the channels to make sure you’re posting questions in the right channel, update your profile with your name, photo/avatar of you that matches your GitHub profile, and your pronouns\nUnfortunately Slack is not the best place to in-depth questions, but it’s a great place for real-time connection and collaboration"
  },
  {
    "objectID": "lectures/01/01-welcome.html#to-do-before-1",
    "href": "lectures/01/01-welcome.html#to-do-before-1",
    "title": "Welcome to STA 101",
    "section": "To do before…",
    "text": "To do before…\nwe move on\nSee course announcement (on Canvas or in your email) and click on the links to\n\nLog in to Posit Cloud – and update your profile\nLog in to Slack – and update your profile with your photo, pronouns, name pronunciation\n\nthe next class on Wednesday\n\nRead the syllabus\nComplete the Getting to know you survey on Canvas\nComplete the readings\n\nthe end of the week\n\nGet started on the lab assignment\nComplete the interactive tutorials"
  },
  {
    "objectID": "lectures/01/01-welcome.html#application-exercise-un-votes",
    "href": "lectures/01/01-welcome.html#application-exercise-un-votes",
    "title": "Welcome to STA 101",
    "section": "Application exercise: UN Votes",
    "text": "Application exercise: UN Votes\n\nGo to Posit Cloud and start the project called UN Votes. Render the document titled unvotes.qmd. Review the narrative and the data visualization you just created. Then, change “Turkey” to another country of your choice. Re-render the document. Show the plot you created to your neighbor and discuss (1) why you chose that country and (2) how this new visualization is different than the original (and what that says about country politics, if anything).\nTime permitting: How were these data collected?\n\n\n\n\n\n🔗 sta101-f23.github.io"
  },
  {
    "objectID": "computing/computing-cheatsheets.html",
    "href": "computing/computing-cheatsheets.html",
    "title": "R cheatsheets",
    "section": "",
    "text": "The following cheatsheets come from https://posit.co/resources/cheatsheets. We haven’t covered every function and functionality listed on them, but you might still find them useful as references.",
    "crumbs": [
      "Computing",
      "Cheatsheets"
    ]
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you can identify when that is without getting too frustrated and feel comfortable seeking help."
  },
  {
    "objectID": "course-support.html#lectures-and-labs",
    "href": "course-support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone."
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone’s office hours here."
  },
  {
    "objectID": "course-support.html#slack",
    "href": "course-support.html#slack",
    "title": "Course support",
    "section": "Slack",
    "text": "Slack\nHave a question that can’t wait for office hours? Prefer to write out your question in detail rather than asking in person? The course Slack is the best venue for these! There is a chance another student has already asked a similar question, so please check the other posts on Slack before asking a new question. If you know the answer to a question that is posted, I encourage you to respond!"
  },
  {
    "objectID": "course-support.html#email",
    "href": "course-support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nPlease refrain from emailing any course content questions (those should go to Slack), and only use email for questions about personal matters that may not be appropriate for the public course forum (e.g., illness, accommodations, etc.). For such matters, you may email Dr. Mine Çetinkaya-Rundel at mc301@duke.edu.\nIf there is a question that’s not appropriate for the public forum, you are welcome to email me directly. If you email me, please include “STA 101” in the subject line. Barring extenuating circumstances, I will respond to STA 101 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday."
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917."
  },
  {
    "objectID": "course-support.html#mental-health-and-wellness",
    "href": "course-support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\nStudent mental health and wellness are of primary importance at Duke, and the university offers resources to support students in managing daily stress and self-care. Duke offers several resources for students to seek assistance on coursework and to nurture daily habits that support overall well-being, some of which are listed below.\n\nThe Academic Resource Center: (919) 684-5917, theARC@duke.edu, or arc.duke.edu.\nDuWell: (919) 681-8421, provides Moments of Mindfulness (stress management and resilience building) and meditation programming to assist students in developing a daily emotional well-being practice. To see schedules for programs please see https://studentaffairs.duke.edu/duwell. All are welcome and no experience necessary.\n\nIf your mental health concerns and/or stressful events negatively affect your daily emotional state, academic performance, or ability to participate in your daily activities, many resources are available to help you through difficult times. Duke encourages all students to access these resources.\n\nDukeReach: Provides comprehensive outreach services to identify and support students in managing all aspects of well-being. If you have concerns about a student’s behavior or health visit the website for resources and assistance: http://studentaffairs.duke.edu/dukereach.\nCounseling and Psychological Services (CAPS): CAPS services include individual and group counseling services, psychiatric services, and workshops. To initiate services, walk-in/call-in 9-4 M,W,Th,F and 9-6 Tuesdays. CAPS also provides referral to off-campus resources for specialized care. (919) 660-1000 or https://students.duke.edu/wellness/caps.\nTimelyCare: (formerly known as Blue Devils Care) An online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling: https://bluedevilscare.duke.edu."
  },
  {
    "objectID": "course-support.html#course-costs",
    "href": "course-support.html#course-costs",
    "title": "Course support",
    "section": "Course costs",
    "text": "Course costs\n\nTextbooks: The textbooks for this course are freely available on the web.\nLaptops: Each student is expected to have a laptop they can bring to each lecture and lab.\n\nIf you are having difficulty with costs associated with this course, here are some resources:\n\nContact the financial aid office (whether or not you are on aid). They have loans and resources for connecting students with programs on campus that might be able to help alleviate these costs.\nDukeLIFE offers course materials assistance for eligible students. Please note that students who are eligible for DukeLIFE benefits are notified prior to the start of the semester; program resources are limited.\nDuke Libraries offers textbook rentals through the Top Textbook Program, where you can rent out a textbook for 3 hours at a time.\nFor course-specific technology needs such as Digital Voice Recorder, HD Video Camera, TI-84 Plus CE, DSLR camera kit, Tripod, Shotgun Mic, iPad Mini 4, a Handheld Projector, or a GoPro, you can reserve rental equipment from the Link."
  },
  {
    "objectID": "course-support.html#assistance-with-canvas-and-zoom",
    "href": "course-support.html#assistance-with-canvas-and-zoom",
    "title": "Course support",
    "section": "Assistance with Canvas and Zoom",
    "text": "Assistance with Canvas and Zoom\nFor technical help with Canvas or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Canvas here.\nNote that we will be making minimal use of Canvas in this course (primarily for announcements and grade book). All assignment submission will take place on Gradescope and conversation on Slack.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person."
  },
  {
    "objectID": "exam-review/exam-1-review.html",
    "href": "exam-review/exam-1-review.html",
    "title": "Exam 1 Review",
    "section": "",
    "text": "In 2020, employees of Blizzard Entertainment circulated a spreadsheet to anonymously share salaries and recent pay increases amidst rising tension in the video game industry over wage disparities and executive compensation. (Source: Blizzard Workers Share Salaries in Revolt Over Pay)\nThe name of the data frame used for this analysis is blizzard_salary and the relevant variables are:\nThe top six rows of blizzard_salary are shown below:\n# A tibble: 409 × 4\n   percent_incr salary_type annual_salary performance_rating\n          &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;             \n 1          1   Salaried               1  High              \n 2          1   Salaried               1  Successful        \n 3          1   Salaried               1  High              \n 4          1   Hourly             33987. Successful        \n 5         NA   Hourly             34798. High              \n 6         NA   Hourly             35360  &lt;NA&gt;              \n 7         NA   Hourly             37440  &lt;NA&gt;              \n 8          0   Hourly             37814. &lt;NA&gt;              \n 9          4   Hourly             41101. Top               \n10          1.2 Hourly             42328  &lt;NA&gt;              \n# ℹ 399 more rows"
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-1",
    "href": "exam-review/exam-1-review.html#question-1",
    "title": "Exam 1 Review",
    "section": "Question 1",
    "text": "Question 1\nHow rows observations are there in the blizzard_salary dataset and what does each row represent?"
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-2",
    "href": "exam-review/exam-1-review.html#question-2",
    "title": "Exam 1 Review",
    "section": "Question 2",
    "text": "Question 2\nFigure 1 (a) and Figure 1 (b) show the distributions of annual salaries of hourly and salaried workers. The two figures show the same data, with the facets organized across rows and across columns. Which of the two figures is better for comparing the median annual salaries of hourly and salaried workers. Explain your reasoning.\n\n\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\n\nFigure 1: Distribution of annual salaries of Blizzard employees"
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-3",
    "href": "exam-review/exam-1-review.html#question-3",
    "title": "Exam 1 Review",
    "section": "Question 3",
    "text": "Question 3\nSuppose your teammate wrote the following code as part of their analysis of the data.\nThey then printed out the results shown below. Unfortunately one of the number got erased from the printout, it’s indicated with _____ below.\n# A tibble: 2 × 3\n  salary_type mean_annual_salary median_annual_salary\n  &lt;chr&gt;                    &lt;dbl&gt;                &lt;dbl&gt;\n1 Hourly                  63003.               54246.\n2 Salaried                90183.               _____\nWhich of the following is the best estimate for that erased value?\n\n30,000\n50,000\n80,000\n100,000"
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-4",
    "href": "exam-review/exam-1-review.html#question-4",
    "title": "Exam 1 Review",
    "section": "Question 4",
    "text": "Question 4\nWhich distribution has a higher standard deviation?\n\nHourly workers\nSalaried workers\nRoughly the same"
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-5",
    "href": "exam-review/exam-1-review.html#question-5",
    "title": "Exam 1 Review",
    "section": "Question 5",
    "text": "Question 5\nWhich of the following alternate plots would also be useful for visualizing the distributions of annual salaries of hourly and salaried workers?\nI.  Box plot\nII. Density plot\nIII. Pie chart\nIV. Waffle chart\n\nI\nI and II\nI, II, and III\nIII and IV"
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-6",
    "href": "exam-review/exam-1-review.html#question-6",
    "title": "Exam 1 Review",
    "section": "Question 6",
    "text": "Question 6\nNext, you fit a model for predicting raises (percent_incr) from salaries (annual_salary). We’ll call this model raise_1_fit. A tidy output of the model is shown below.\n\n\n# A tibble: 2 × 5\n  term           estimate  std.error statistic   p.value\n  &lt;chr&gt;             &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)   1.87      0.432           4.33 0.0000194\n2 annual_salary 0.0000155 0.00000452      3.43 0.000669 \n\n\nWhich of the following is the best interpretation of the slope coefficient?\n\nFor every additional $1,000 of annual salary, the model predicts the raise to be higher, on average, by 1.55%.\nFor every additional $1,000 of annual salary, the raise goes up by 0.0155%.\nFor every additional $1,000 of annual salary, the model predicts the raise to be higher, on average, by 0.0155%.\nFor every additional $1,000 of annual salary, the model predicts the raise to be higher, on average, by 1.87%."
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-7",
    "href": "exam-review/exam-1-review.html#question-7",
    "title": "Exam 1 Review",
    "section": "Question 7",
    "text": "Question 7\nYou then fit a model for predicting raises (percent_incr) from salaries (annual_salary) and performance ratings (performance_rating). We’ll call this model raise_2_fit. Which of the following is definitely true based on the information you have so far?\n\nIntercept of raise_2_fit is higher than intercept of raise_1_fit.\nRMSE of raise_2_fit is higher than RMSE of raise_1_fit.\nAdjusted \\(R^2\\) of raise_2_fit is higher than adjusted \\(R^2\\) of raise_1_fit.\n\\(R^2\\) of raise_2_fit is higher \\(R^2\\) of raise_1_fit."
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-8",
    "href": "exam-review/exam-1-review.html#question-8",
    "title": "Exam 1 Review",
    "section": "Question 8",
    "text": "Question 8\nThe tidy model output for the raise_2_fit model you fit is shown below.\n\n\n# A tibble: 5 × 5\n  term                            estimate  std.error statistic  p.value\n  &lt;chr&gt;                              &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                   3.55       0.508           6.99 1.99e-11\n2 annual_salary                 0.00000989 0.00000436      2.27 2.42e- 2\n3 performance_ratingPoor       -4.06       1.42           -2.86 4.58e- 3\n4 performance_ratingSuccessful -2.40       0.397          -6.05 4.68e- 9\n5 performance_ratingTop         2.99       0.715           4.18 3.92e- 5\n\n\nWhen your teammate sees this model output, they remark “The coefficient for performance_ratingSuccessful is negative, that’s weird. I guess it means that people who get successful performance ratings get lower raises.” How would you respond to your teammate?"
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-9",
    "href": "exam-review/exam-1-review.html#question-9",
    "title": "Exam 1 Review",
    "section": "Question 9",
    "text": "Question 9\nUltimately, your teammate decides they don’t like the negative slope coefficients in the model output you created (not that there’s anything wrong with negative slope coefficients!), does something else, and comes up with the following model output.\n\n\n# A tibble: 5 × 5\n  term                            estimate  std.error statistic    p.value\n  &lt;chr&gt;                              &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 (Intercept)                  -0.511      1.47          -0.347 0.729     \n2 annual_salary                 0.00000989 0.00000436     2.27  0.0242    \n3 performance_ratingSuccessful  1.66       1.42           1.17  0.242     \n4 performance_ratingHigh        4.06       1.42           2.86  0.00458   \n5 performance_ratingTop         7.05       1.53           4.60  0.00000644\n\n\nUnfortunately they didn’t write their code in a Quarto document, instead just wrote some code in the Console and then lost track of their work. They remember using the fct_relevel() function and doing something like the following:\nWhat should they put in the blanks to get the same model output as above?\n\n“Poor”, “Successful”, “High”, “Top”\n“Successful”, “High”, “Top”\n“Top”, “High”, “Successful”, “Poor”\nPoor, Successful, High, Top"
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-10",
    "href": "exam-review/exam-1-review.html#question-10",
    "title": "Exam 1 Review",
    "section": "Question 10",
    "text": "Question 10\nFinally, your teammate creates the following two plots and ask you for help deciding which one to use in the final report for visualizing the relationship between performance rating and salary type. In 1-3 sentences, can you help them make a decision, justify your choice, and write the narrative that should go with the plot?\n\n\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\n\nFigure 2: Distribution of salary type by performance rating"
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-11",
    "href": "exam-review/exam-1-review.html#question-11",
    "title": "Exam 1 Review",
    "section": "Question 11",
    "text": "Question 11\nA friend with a keen eye points out that the number of observations in Figure 2 (a) seems lower than the total number of observations in blizzard_salary. What might be going on here? Explain your reasoning."
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-12",
    "href": "exam-review/exam-1-review.html#question-12",
    "title": "Exam 1 Review",
    "section": "Question 12",
    "text": "Question 12\nShow the proportions of performance ratings for hourly and salaried workers in a table and ask students to place those numbers on the segments of Figure 2 (b).\n\n\n# A tibble: 4 × 3\n  performance_rating Hourly Salaried\n  &lt;fct&gt;               &lt;dbl&gt;    &lt;dbl&gt;\n1 Successful          0.686   0.521 \n2 High                0.2     0.384 \n3 Top                 0.114   0.0760\n4 Poor                0       0.0190"
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-13",
    "href": "exam-review/exam-1-review.html#question-13",
    "title": "Exam 1 Review",
    "section": "Question 13",
    "text": "Question 13\nFigure 3 is yet another visualization of the relationship between salary type and performance rating. What type of plot is ths, and what does it display that Figure 2 (b) doesn’t?\n\n\n\n\n\n\n\n\nFigure 3: Another visualization of salary type by performance rating"
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-14",
    "href": "exam-review/exam-1-review.html#question-14",
    "title": "Exam 1 Review",
    "section": "Question 14",
    "text": "Question 14\nSuppose we fit a model to predict percent_incr from annual_salary and salary_type. A tidy output of the model is shown below.\n\n\n# A tibble: 3 × 5\n  term                 estimate  std.error statistic p.value\n  &lt;chr&gt;                   &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)         1.24      0.570           2.18 0.0300 \n2 annual_salary       0.0000137 0.00000464      2.96 0.00329\n3 salary_typeSalaried 0.913     0.544           1.68 0.0938 \n\n\nWhich of the following visualizations represent this model? Explain your reasoning.\n\n\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Option 3\n\n\n\n\n\n\n\n\n\n\n\n(d) Option 4\n\n\n\n\n\n\n\nFigure 4: Visualizations of the relationship between percent increase, annual salary, and salary type"
  },
  {
    "objectID": "exam-review/exam-1-review.html#question-15",
    "href": "exam-review/exam-1-review.html#question-15",
    "title": "Exam 1 Review",
    "section": "Question 15",
    "text": "Question 15\nDefine the term parsimonious model."
  },
  {
    "objectID": "exam-review/exam-1-review.html#bonus",
    "href": "exam-review/exam-1-review.html#bonus",
    "title": "Exam 1 Review",
    "section": "Bonus",
    "text": "Bonus\nPick a concept we introduced in class so far that you’ve been struggling with and explain it in your own words."
  },
  {
    "objectID": "exam-review/exam-2-review-sa.html",
    "href": "exam-review/exam-2-review-sa.html",
    "title": "Exam 2 Review",
    "section": "",
    "text": "explanatory: income bracket; response: preferred alcoholic beverage\n\nIV and V\n\n\\(H_0\\): Income bracket and preference for alcoholic beverage are independent.\n\\(H_A\\): Income bracket and preference for alcoholic beverage are dependent.\n\\(E = 250 \\times \\frac{500}{1000} = 125\\)\nThe shaded area below represents the p-value.\n\n\n\n\n\n\n\n\n\n\n\nAdd up the heights of the bars that contain simulated sample statistics with a value of 4.74 or higher and divide by the number of simulations. Approximately 352 (113+76+51+36+30+19+8+6+7+2+3+0+1) simulations out of 1,000 meet this criteria, resulting in a p-value of approximately 0.352.\n\n\n\n\n\n\n\n\n\n\n\nThe p-value is much larger than 0.05, therefore the data do not provide convincing evidence that income bracket and preference for alcoholic beverage are dependent.\nTake a random sample of size 25, with replacement, from the original sample. Calculate the proportion of students in this simulated sample who work 5 or more hours. Repeat this process 1000 times to build the bootstrap distribution. Take the middle 95% of this distribution to construct a 95% confidence interval for the true proportion of statistics majors who work 5 or more hours.\nThe exact 95% CI is (40%, 80%). Answers reasonably close to the upper and lower bounds would be accepted.\n(e) None of the above. The correct interpretation is “We are 95% confident that 40% to 80% of statistics majors work at least 5 hours per week.”\nRange of the bootstrap distribution is 0.90 - 0.30 = 0.60. This spans roughly 6 standard errors. Therefore, the approximate standard error is 0.60 / 6 = 0.10.\n(c) We are 95% confident that the mean number of texts per month of all American teens is between 1450 and 1550.\n(a) I &gt; II\na. Power of the test is the probability of rejecting the null hypothesis when the null hypothesis is false.\nb. Type 1 error rate is the probability of rejecting the null hypothesis when the null hypothesis is true.\nc. Type 1 error rate is the probability of failing to reject the null hypothesis when the null hypothesis is false.\nd. 0.05.\na. False. It will be centered at \\(p\\), the true population proportion.\nb. False. Increasing the number of bootstrap samples does not affect the variability of the sample statistic.\nc. True."
  },
  {
    "objectID": "course-team.html",
    "href": "course-team.html",
    "title": "Teaching team",
    "section": "",
    "text": "Dr. Mine Çetinkaya-Rundel (she/her) is Professor of the Practice and Director of Undergraduate Studies at the Department of Statistical Science at Duke University and an affiliated faculty in the Computational Media, Arts, and Cultures. Mine’s work focuses on innovation in statistics and data science pedagogy, with an emphasis on computing, reproducible research, student-centered learning, and open-source education as well as pedagogical approaches for enhancing retention of women and under-represented minorities in STEM.\n\n\n\nOffice hours\nLocation\n\n\n\n\nTue 3:30 - 5:30 pm\nOld Chem 213",
    "crumbs": [
      "Syllabus",
      "Teaching team"
    ]
  },
  {
    "objectID": "course-team.html#instructor",
    "href": "course-team.html#instructor",
    "title": "Teaching team",
    "section": "",
    "text": "Dr. Mine Çetinkaya-Rundel (she/her) is Professor of the Practice and Director of Undergraduate Studies at the Department of Statistical Science at Duke University and an affiliated faculty in the Computational Media, Arts, and Cultures. Mine’s work focuses on innovation in statistics and data science pedagogy, with an emphasis on computing, reproducible research, student-centered learning, and open-source education as well as pedagogical approaches for enhancing retention of women and under-represented minorities in STEM.\n\n\n\nOffice hours\nLocation\n\n\n\n\nTue 3:30 - 5:30 pm\nOld Chem 213",
    "crumbs": [
      "Syllabus",
      "Teaching team"
    ]
  },
  {
    "objectID": "course-team.html#teaching-assistants",
    "href": "course-team.html#teaching-assistants",
    "title": "Teaching team",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n\n\nName\nRole\nLab section\nOffice hours\n\n\n\n\n\nShuo Wang\nHead + Lab TA\nFri 8:30 - 9:45 am\nMon 2:45 - 4:45 pm\nOld Chem 203B\n\n\n\nSylvia Vincent\nLab TA\nFri 10:05 - 11:20 am\nWed 3 - 5 pm\nOld Chem 025\n\n\n\nJohn Gillen\nLab TA\nFri 11:45 am - 1:00 pm\nWed 10:30 am - 12:30 pm\nZoom\n\n\n\nChris Oswald\nLab TA\nFri 1:25 - 2:40 pm\nMon 9 - 10 am\nTue 9 - 10 am\nJones Open Lab (Bostock Library, 1st Floor)\n\n\n\nMinh Anh To\nTA\n\nMon 10 am - 12 pm\nOld Chem 203B\n\n\n\nHao Wang\nTA\n\nTue 10 am - 12 pm\nOld Chem 203B\n\n\n\nNoah Obuya\nTA\n\nSun 12 - 2 pm\nZoom\n\n\n\nMeghna Katyal\nTA\n\nMon 7:30 - 8:30 pm\nZoom\n\n\n\nAvery Hodges\nTA\n\nMon 5 - 7 pm\nZoom",
    "crumbs": [
      "Syllabus",
      "Teaching team"
    ]
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Course overview",
    "section": "",
    "text": "This is the homepage for STA 101 - Data Analysis and Statistical Inference taught by Dr. Mine Çetinkaya-Rundel in Fall 2023 at Duke University. All course materials will be posted on this site.\nYou can find the course syllabus here and the course schedule here.",
    "crumbs": [
      "Syllabus",
      "Overview"
    ]
  },
  {
    "objectID": "course-overview.html#class-meetings",
    "href": "course-overview.html#class-meetings",
    "title": "Course overview",
    "section": "Class meetings",
    "text": "Class meetings\n\n\n\n\n\n\n\n\n\nMeeting\nLocation\nTime\nInstructor / Lab leader\n\n\n\n\nLectures\nGross Hall 103\nMon & Wed 1:25 - 2:40 pm\nMine\n\n\nLab 1\nPerkins LINK 087 (Classroom 3)\nFri 8:30 - 9:45 am\nShuo\n\n\nLab 2\nPerkins LINK 087 (Classroom 3)\nFri 10:05 - 11:20 am\nSylvia\n\n\nLab 3\nPerkins LINK 087 (Classroom 3)\nFri 11:45 am - 1:00 pm\nJohn\n\n\nLab 4\nPerkins LINK 087 (Classroom 3)\nFri 1:25 - 2:40 pm\nChris",
    "crumbs": [
      "Syllabus",
      "Overview"
    ]
  },
  {
    "objectID": "course-overview.html#license",
    "href": "course-overview.html#license",
    "title": "Course overview",
    "section": "License",
    "text": "License\n\nThis online work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International. Visit here for more information about the license.",
    "crumbs": [
      "Syllabus",
      "Overview"
    ]
  },
  {
    "objectID": "ae/ae-02-flint.html",
    "href": "ae/ae-02-flint.html",
    "title": "Exploring Flint’s water data",
    "section": "",
    "text": "By the end of this application exercise you will\n\nmeet the computational toolkit for the course\npractice using glimpse(), names(), nrow(), ncol(), count()\ndefine and compute various statistics\nbegin to gain familiarity with making data visualizations with ggplot()\n\nWe will do this using water lead content data from Flint, MI. The following paragraph will be useful in evaluating the lead amount values we’ll see in the dataset.\n\nWhile there is no completely safe amount of lead consumption, the limit allowed by the Lead and Copper Rule (LCR) of 1991 is 15 parts per billion (ppb). If this is exceeded in more than 10% of homes tested (or if the 90th percentile value of the total sample is above 15 ppb), action is required. And to make sure problems are caught, sampling for lead in water is supposed to target the “worst-case” homes – those in areas served by lead pipes."
  },
  {
    "objectID": "ae/ae-02-flint.html#rstudio",
    "href": "ae/ae-02-flint.html#rstudio",
    "title": "Exploring Flint’s water data",
    "section": "RStudio",
    "text": "RStudio\n\nFiles, plots, viewer, environment, etc. panes\nConsole\nEditor"
  },
  {
    "objectID": "ae/ae-02-flint.html#r",
    "href": "ae/ae-02-flint.html#r",
    "title": "Exploring Flint’s water data",
    "section": "R",
    "text": "R\n\nWriting code in the console\nBasic math with R\nCreating variables in R, the assignment operator (&lt;-), and the Environment pane\nR functions and packages and the Packages pane\nGetting help with R and the Help pane"
  },
  {
    "objectID": "ae/ae-02-flint.html#quarto",
    "href": "ae/ae-02-flint.html#quarto",
    "title": "Exploring Flint’s water data",
    "section": "Quarto",
    "text": "Quarto\n\nYAML: Metadata\nNarrative: Edited with the visual editor (or the source editor)\nCode: In code chunks\n\nChunk options (following #|)\nComments (following #)\nCode\n\nRunning individual code chunks vs. rendering a document"
  },
  {
    "objectID": "ae/ae-02-flint.html#load-packages",
    "href": "ae/ae-02-flint.html#load-packages",
    "title": "Exploring Flint’s water data",
    "section": "Load packages",
    "text": "Load packages\nWe’ll use the tidyverse package for analysis, which offers functionality for data import, wrangling, visualization, and more.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nLoading this package prints out a message. What does this message mean? How can we suppress the message from the output?"
  },
  {
    "objectID": "ae/ae-02-flint.html#load-data",
    "href": "ae/ae-02-flint.html#load-data",
    "title": "Exploring Flint’s water data",
    "section": "Load data",
    "text": "Load data\nThe read_csv() function can be used for reading CSV (comma separated values) files. The file we’re reading is called flint with the suffix (.csv) which indicates its file type. The file is in the data folder.\nBefore reading in the file, go to the data folder in the Files pane to confirm that it is, indeed, there. Then, read the file by running the code chunk below by clicking on the green triangle icon on the code chunk.\n\nflint &lt;- read_csv(\"data/flint.csv\")\n\nRows: 813 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): draw\ndbl (4): id, zip, ward, lead\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nOne of two things may have happened:\n\nThe file was read successfully and you now see a dataset called flint in your Environment pane.\nThe file was not read successfully and you see an error Error in read_csv(\"data/flint.csv\") : could not find function \"read_csv\".\n\nIf (1) happened, great!\nIf (2) happened, let’s troubleshoot first before continuing."
  },
  {
    "objectID": "ae/ae-02-flint.html#data-dictionary",
    "href": "ae/ae-02-flint.html#data-dictionary",
    "title": "Exploring Flint’s water data",
    "section": "Data dictionary",
    "text": "Data dictionary\nThe following variables are in the flint data frame:\n\nid: sample ID number (identifies the home)\nzip: ZIP code in Flint of the sample’s location\nward: ward in Flint of the sample’s location\ndraw: which time point the water was sampled from\nlead: lead content in parts per billion (ppb)"
  },
  {
    "objectID": "ae/ae-02-flint.html#populations-and-samples",
    "href": "ae/ae-02-flint.html#populations-and-samples",
    "title": "Exploring Flint’s water data",
    "section": "Populations and samples",
    "text": "Populations and samples\nWe want to learn about the population using a sample.\nIn the case we want to learn about the lead content in all of Flint, MI homes but only have available water readings from a sample of homes (our data set).\nExercise 1: Look at the data, how many observations are there? How many variables?\n\n# add code here"
  },
  {
    "objectID": "ae/ae-02-flint.html#frequencies",
    "href": "ae/ae-02-flint.html#frequencies",
    "title": "Exploring Flint’s water data",
    "section": "Frequencies",
    "text": "Frequencies\nLet’s count() to find the number of different time points water was sampled with the count() function.\n\nThe first argument is flint: the data frame\nThe second argument is draw: the variable\n\n\ncount(flint, draw)\n\n# A tibble: 3 × 2\n  draw       n\n  &lt;chr&gt;  &lt;int&gt;\n1 first    271\n2 second   271\n3 third    271\n\n\nWe can achieve the same result with the following “piped” operation as well.\n\nThe first line is flint: the data frame\nThen the pipe operator, read as “and then”, which places what comes before it as the first argument of what comes after it\nThe second line is count(draw)\n\n\nflint |&gt;\n  count(draw)\n\n# A tibble: 3 × 2\n  draw       n\n  &lt;chr&gt;  &lt;int&gt;\n1 first    271\n2 second   271\n3 third    271\n\n\nWe can use a similar approach to fund out how many unique homes are in the data set:\n\nflint |&gt;\n  count(id)\n\n# A tibble: 269 × 2\n      id     n\n   &lt;dbl&gt; &lt;int&gt;\n 1     1     3\n 2     2     3\n 3     4     3\n 4     5     3\n 5     6     3\n 6     7     3\n 7     8     3\n 8     9     3\n 9    12     3\n10    13     3\n# ℹ 259 more rows\n\n\nExercise 2: How many samples were taken from each zip code?\n\n# add code here\n\nExercise 3: Which ZIP code had the most samples drawn? Hint: See the help for count.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-02-flint.html#measures-of-central-tendency",
    "href": "ae/ae-02-flint.html#measures-of-central-tendency",
    "title": "Exploring Flint’s water data",
    "section": "Measures of central tendency",
    "text": "Measures of central tendency\n\nmean\nmedian\nmode"
  },
  {
    "objectID": "ae/ae-02-flint.html#measures-of-spread",
    "href": "ae/ae-02-flint.html#measures-of-spread",
    "title": "Exploring Flint’s water data",
    "section": "Measures of spread",
    "text": "Measures of spread\n\nvariance\nstandard deviation\nrange\nquartiles\ninter-quartile range (IQR)"
  },
  {
    "objectID": "ae/ae-02-flint.html#order-statistics",
    "href": "ae/ae-02-flint.html#order-statistics",
    "title": "Exploring Flint’s water data",
    "section": "Order statistics",
    "text": "Order statistics\n\nquantiles\nminimum (0 percentile)\nmedian (50th percentile)\nmaximum (100 percentile)\n\n… and any other arbitrary function of the data you can come up with!\nExercise 4: Compute each of these statistics for lead ppb.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-02-flint.html#histograms",
    "href": "ae/ae-02-flint.html#histograms",
    "title": "Exploring Flint’s water data",
    "section": "Histograms",
    "text": "Histograms\nLet’s take a look at the distribution of lead content in homes in Flint, MI.\n\nggplot(flint, aes(x = lead)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWe can make this plot look nicer/more useful by adjusting the number of bins and zooming into the x-axis.\n\nggplot(flint, aes(x = lead)) +\n  geom_histogram(bins = 50) +\n  coord_cartesian(xlim = c(0, 100))\n\n\n\n\n\n\n\n\nLet’s visualize some of our summary statistics on the plot.\nExercise 5: Add a new layer, geom_vline(xintercept = __, color = \"red\"), to the histogram below, filling in the blank with the mean.\n\nggplot(flint, aes(x = lead)) + \n  geom_histogram(bins = 50) + \n  coord_cartesian(xlim = c(0, 100))\n\n\n\n\n\n\n\n\nExercise 6: Add one more layer which overlays the median, in a different color.\n\n# add code here"
  },
  {
    "objectID": "ae/ae-02-flint.html#box-plots",
    "href": "ae/ae-02-flint.html#box-plots",
    "title": "Exploring Flint’s water data",
    "section": "Box plots",
    "text": "Box plots\nNext, let’s narrow our focus to the zip codes 48503, 48504, 48505, 48506, and 48507 and observations with lead values less than 1,000 ppb.\n\nflint_focus &lt;- flint |&gt;\n  filter(zip %in% 48503:48507 & lead &lt; 1000)\n\nExercise 7: Below are side-by-side box plots for the three flushing times in each of the five zip codes we considered. Add x and y labels; add a title by inserting title = \"title_name\" inside the labs() function.\n\nggplot(data = flint_focus, aes(y = factor(zip), x = lead)) +\n  geom_boxplot(aes(fill = factor(draw))) +\n  labs(x = \"___\", y = \"___\", fill = \"Flushing time\") +\n  scale_fill_discrete(\n    breaks = c(\"first\", \"second\", \"third\"),\n    labels = c(\"0 (sec)\", \"45 (sec)\", \"120 (sec)\")\n  )\n\n\n\n\n\n\n\n\nExercise 8: Add labels for x, y, a title, and subtitle to the code below to update the corresponding plot.\n\nggplot(data = flint_focus, aes(y = factor(zip), x = lead)) +\n  geom_boxplot(aes(fill = factor(draw))) + \n  labs(\n    x = \"___\", y = \"___\", fill = \"Flushing time\",\n    title = \"___\",\n    subtitle = \"___\"\n    ) +\n  scale_fill_discrete(\n    breaks = c(\"first\", \"second\", \"third\"),\n    labels = c(\"0 (sec)\", \"45 (sec)\", \"120 (sec)\")\n  ) +\n  coord_cartesian(xlim = c(0, 50)) +\n  theme_bw()\n\n\n\n\n\n\n\n\nExercise 9: What is the difference between the two plots? What are the advantages and disadvantages to each plot?\n[Add your answer here]"
  },
  {
    "objectID": "ae/ae-01-unvotes.html",
    "href": "ae/ae-01-unvotes.html",
    "title": "UN Votes",
    "section": "",
    "text": "How do various countries vote in the United Nations General Assembly, how have their voting patterns evolved throughout time, and how similarly or differently do they view certain issues? Answering these questions (at a high level) is the focus of this analysis.\n\n\nWe will use the tidyverse, lubridate, and scales packages for data wrangling and visualization, and the DT package for interactive display of tabular output, and the unvotes package for the data.\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(DT)\nlibrary(unvotes)\nlibrary(ggthemes)\n\n\n\n\nThe data we’re using originally come from the unvotes package. In the chunk below we modify the data by joining the various data frames provided in the package to help you get started with the analysis.\n\nunvotes &lt;- un_votes |&gt;\n  inner_join(un_roll_calls, by = \"rcid\") |&gt;\n  inner_join(un_roll_call_issues, by = \"rcid\", relationship = \"many-to-many\")"
  },
  {
    "objectID": "ae/ae-01-unvotes.html#introduction",
    "href": "ae/ae-01-unvotes.html#introduction",
    "title": "UN Votes",
    "section": "",
    "text": "How do various countries vote in the United Nations General Assembly, how have their voting patterns evolved throughout time, and how similarly or differently do they view certain issues? Answering these questions (at a high level) is the focus of this analysis.\n\n\nWe will use the tidyverse, lubridate, and scales packages for data wrangling and visualization, and the DT package for interactive display of tabular output, and the unvotes package for the data.\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(DT)\nlibrary(unvotes)\nlibrary(ggthemes)\n\n\n\n\nThe data we’re using originally come from the unvotes package. In the chunk below we modify the data by joining the various data frames provided in the package to help you get started with the analysis.\n\nunvotes &lt;- un_votes |&gt;\n  inner_join(un_roll_calls, by = \"rcid\") |&gt;\n  inner_join(un_roll_call_issues, by = \"rcid\", relationship = \"many-to-many\")"
  },
  {
    "objectID": "ae/ae-01-unvotes.html#un-voting-patterns",
    "href": "ae/ae-01-unvotes.html#un-voting-patterns",
    "title": "UN Votes",
    "section": "UN voting patterns",
    "text": "UN voting patterns\nLet’s create a data visualization that displays how the voting record of the UK & NI changed over time on a variety of issues, and compares it to two other countries: US and Turkey.\nWe can easily change which countries are being plotted by changing which countries the code above filters for. Note that the country name should be spelled and capitalized exactly the same way as it appears in the data. See the Appendix for a list of the countries in the data.\n\nunvotes |&gt;\n  filter(country %in% c(\"United Kingdom\", \"United States\", \"Turkey\")) |&gt;\n  mutate(year = year(date)) |&gt;\n  group_by(country, year, issue) |&gt;\n  summarize(percent_yes = mean(vote == \"yes\")) |&gt;\n  ggplot(mapping = aes(x = year, y = percent_yes, color = country)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  facet_wrap(~issue) +\n  scale_y_continuous(labels = percent) +\n  scale_color_colorblind() +\n  labs(\n    title = \"Percentage of 'Yes' votes in the UN General Assembly\",\n    subtitle = \"1946 to 2019\",\n    y = \"% Yes\",\n    x = \"Year\",\n    color = \"Country\"\n  )"
  },
  {
    "objectID": "ae/ae-01-unvotes.html#references",
    "href": "ae/ae-01-unvotes.html#references",
    "title": "UN Votes",
    "section": "References",
    "text": "References\n\nRobinson D (2021). unvotes: United Nations General Assembly Voting Data. R package version 0.3.0, https://github.com/dgrtwo/unvotes.\nErik Voeten “Data and Analyses of Voting in the UN General Assembly” Routledge Handbook of International Organization, edited by Bob Reinalda (published May 27, 2013).\nMuch of the analysis has been modeled on the examples presented in the unvotes package vignette."
  },
  {
    "objectID": "ae/ae-01-unvotes.html#appendix",
    "href": "ae/ae-01-unvotes.html#appendix",
    "title": "UN Votes",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of countries in the dataset:"
  },
  {
    "objectID": "labs/lab-1.html",
    "href": "labs/lab-1.html",
    "title": "Lab 1: Hello R!",
    "section": "",
    "text": "The goal of this lab is to acquaint you with R (the computing language), RStudio (the IDE, integrated development environment), and Posit Cloud (the browser based service we will use to access RStudio).",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#yaml",
    "href": "labs/lab-1.html#yaml",
    "title": "Lab 1: Hello R!",
    "section": "YAML",
    "text": "YAML\nThe top portion of your Quarto Markdown file (aka .qmd), you’ll find three dashed lines. Between the dashed lines is called YAML. YAML stands for “YAML Ain’t Markup Language”. It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\nChange the author name to your name and update the date with today’s date. Click the Render to render the document. What do you notice?\n\n\n\n\n\n\nNote\n\n\n\nTo avoid issues that can occur while rendering, it is a good idea to render early and often. At least after every exercise.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#packages",
    "href": "labs/lab-1.html#packages",
    "title": "Lab 1: Hello R!",
    "section": "Packages",
    "text": "Packages\nIn this lab we will work with three packages: the tidyverse package which is a collection of packages for doing data analysis in a “tidy” way, the datasauRus package which contains the data set for the first part of your lab.\n\nlibrary(tidyverse) \nlibrary(datasauRus)\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you are using R on Posit Cloud, packages we use should already be installed and only need to be loaded with the function library(). If you are using a local version of R you probably have to run the following code in the console to install the packages (one time only!)\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"datasauRus\")",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-1",
    "href": "labs/lab-1.html#exercise-1",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nBased on the help file, how many rows and how many columns does the datasaurus_dozen file have? What are the variables included in the data frame? Add your responses to your lab report under “Exercise 1”.\n\nLet’s take a look at the names of the data sets inside of datasaurus_dozen. To do so this, we can make a frequency table of the “data set” variable. Run the code chunk below. Note: when you run the code chunk below, a table “prints” to the screen. In general, we say “print to screen” to mean that the output of your code should show up on your screen (when asked to ‘print to screen’ in an assignment, you should make sure the output displays in your rendered document).\n\ndatasaurus_dozen |&gt;\n  count(dataset)\n\n# A tibble: 13 × 2\n   dataset        n\n   &lt;chr&gt;      &lt;int&gt;\n 1 away         142\n 2 bullseye     142\n 3 circle       142\n 4 dino         142\n 5 dots         142\n 6 h_lines      142\n 7 high_lines   142\n 8 slant_down   142\n 9 slant_up     142\n10 star         142\n11 v_lines      142\n12 wide_lines   142\n13 x_shape      142\n\n\nThe original Datasaurus (dino) data was created by Alberto Cairo. The other Dozen were generated using simulated annealing and the process is described in the paper Same Stats, Different Graphs: Generating data sets with Varied Appearance and Identical Statistics through Simulated Annealing by Justin Matejka and George Fitzmaurice. In the paper, the authors simulate a variety of data sets that have the same summary statistics as the original Datasaurus but have very different data.\n\n\n\n\n\n\nNote\n\n\n\nYou can view the whole data frame by running the code view(datasaurus_dozen) in the console. This will open the data frame in a new tab. Try it out!",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-2",
    "href": "labs/lab-1.html#exercise-2",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nPlot y vs. x for the dino data set. Then, calculate the correlation coefficient between x and y for this data set. Make sure that this value is printed in your document.\n\nBelow is the code you will need to complete this exercise. Basically, the answer is already given, but you need to include relevant bits in your .qmd document and successfully render it and view the results.\nStart with the datasaurus_dozen and pipe it into the filter function to filter for observations where dataset == \"dino\". Store the resulting filtered data frame as a new data frame called dino_data.\n\ndino_data &lt;- datasaurus_dozen |&gt;\n  filter(dataset == \"dino\")\n\nThere is a lot going on here, so let’s slow down and unpack it a bit.\nFirst, the pipe operator: |&gt;, takes what comes before it and sends it as the first argument to what comes after it. So here, we’re saying filter the datasaurus_dozen data frame for observations where dataset == \"dino\".\nSecond, the assignment operator: &lt;-, assigns the name dino_data to the filtered data frame.\n\n\n\n\n\n\nNote\n\n\n\nNote in R you may use either &lt;- or = for an assignment operator. We’ll use &lt;- in this class as it’s the more commonly used assignment operator, but when you look for R help online, you might see = being used as well.\n\n\nNext, we need to visualize these data. We will use the ggplot function for this. Its first argument is the data you’re visualizing. Next we define the aesthetic mappings. In other words, the columns of the data that get mapped to certain aesthetic features of the plot, e.g. the x axis will represent the variable called x and the y axis will represent the variable called y. Then, we add another layer to this plot where we define which geometric shapes we want to use to represent each observation in the data. In this case we want these to be points, hence geom_point.\n\nggplot(dino_data, aes(x = x, y = y)) +\n  geom_point()\n\n\n\n\n\n\n\nFor the second part of this exercise, we need to calculate a summary statistic: the correlation coefficient. The correlation coefficient (r) measures the strength and direction of the linear association between two variables. You will see that some of the pairs of variables we plot do not have a linear relationship between them. This is exactly why we want to visualize first: visualize to assess the form of the relationship, and calculate r only if relevant.\nIn this case, calculating a correlation coefficient really doesn’t make sense since the relationship between x and y is definitely not linear, but is instead more ‘dinosaur-esque’.\nFor illustrative purposes only, let’s calculate the correlation coefficient between x and y.\n\ndino_data |&gt;\n  summarize(r = cor(x, y))\n\n# A tibble: 1 × 1\n        r\n    &lt;dbl&gt;\n1 -0.0645",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-3",
    "href": "labs/lab-1.html#exercise-3",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nPlot y vs. x for the star dataset. You can (and should) reuse code we introduced above, just replace the dataset name with the desired dataset. Then, calculate the correlation coefficient between x and y for this dataset. How does this value compare to the r of dino?\n\nTo begin, edit the name of the code chunks from ex-3-1 and ex-3-2 to something more meaningful, e.g: plot-star and r-star respectively.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-4",
    "href": "labs/lab-1.html#exercise-4",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nFinally, let’s plot all datasets at once. In order to do this we will make use of faceting, given by the code below:\n\nggplot(datasaurus_dozen, aes(x = x, y = y, color = dataset)) +\n  geom_point() +\n  facet_wrap(~ dataset, ncol = 3)\n\nAnd we can use the group_by function to generate all the summary correlation coefficients. We’ll see these functions again and again.\n\ndatasaurus_dozen |&gt;\n  group_by(dataset) |&gt;\n  summarize(r = cor(x, y))",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-5",
    "href": "labs/lab-1.html#exercise-5",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nDescribe what |&gt; does. Hint: run the following two code chunks. What do you notice?\n\ndino_data |&gt;\n  summarize(\n    mu_x = mean(x),\n    mu_y = mean(y)\n  )\n\n\nsummarize(dino_data, mu_x = mean(x), mu_y = mean(y))",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-6",
    "href": "labs/lab-1.html#exercise-6",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nIn the above code chunk, identify each of the following as an argument or a function:\n\nsummarize\ndino_data\nmean\nx\ny\nmu_x = mean(x)",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-7",
    "href": "labs/lab-1.html#exercise-7",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nCombine the code from exercises 4 and 5 to compute the mean(x) and mean(y) for each data set. Print your result to the screen. What do you notice? What does this say about the importance of visualizing your data as opposed to only looking at summary statistics?",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-8",
    "href": "labs/lab-1.html#exercise-8",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nIMS - Chapter 1 exercises, #4: Cheaters, study components.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-9",
    "href": "labs/lab-1.html#exercise-9",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nIMS - Chapter 1 exercises, #14: UN Votes.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#exercise-10",
    "href": "labs/lab-1.html#exercise-10",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 10",
    "text": "Exercise 10\n\nIMS - Chapter 1 exercises, #16: Shows on Netflix.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#submitting",
    "href": "labs/lab-1.html#submitting",
    "title": "Lab 1: Hello R!",
    "section": "Submitting",
    "text": "Submitting\n\n\n\n\n\n\nImportant\n\n\n\nBefore you proceed, first, make sure that you have updated the document YAML with your name! Then, render your document one last time, for good measure.\n\n\nTo submit your assignment to Gradescope:\n\nGo to your Files pane and check the box next to the PDF output of your document (lab-1.pdf).\nThen, in the Files pane, go to More &gt; Export. This will download the PDF file to your computer. Save it somewhere you can easily locate, e.g., your Downloads folder or your Desktop.\nGo to the course Canvas page and click on Gradescope and then click on the assignment. You’ll be prompted to submit it.\nMark the pages associated with each exercise. All of the papers of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you fail to mark the pages associated with an exercise, that exercise won’t be graded. This means, if you fail to mark the pages for all exercises, you will receive a 0 on the assignment. The TAs can’t mark your pages for you, and for them to be able to grade, you must mark them.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#grading",
    "href": "labs/lab-1.html#grading",
    "title": "Lab 1: Hello R!",
    "section": "Grading",
    "text": "Grading\n\n\nExercise\nPoints\n\n\n\nExercise 1\n5\n\n\nExercise 2\n4\n\n\nExercise 3\n6\n\n\nExercise 4\n5\n\n\nExercise 5\n2\n\n\nExercise 6\n6\n\n\nExercise 7\n7\n\n\nExercise 8\n5\n\n\nExercise 9\n5\n\n\nExercise 10\n5\n\n\nTotal\n50",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#acknowledgements",
    "href": "labs/lab-1.html#acknowledgements",
    "title": "Lab 1: Hello R!",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis assignment was adapted from a lab in Data Science in a Box.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "ae/ae-02-flint-sa.html",
    "href": "ae/ae-02-flint-sa.html",
    "title": "Exploring Flint’s water data",
    "section": "",
    "text": "Important\n\n\n\nThese are suggested answers for the application exercise. They’re not necessarily complete or 100% accurate, they’re roughly what we develop in class while going through the exercises."
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#rstudio",
    "href": "ae/ae-02-flint-sa.html#rstudio",
    "title": "Exploring Flint’s water data",
    "section": "RStudio",
    "text": "RStudio\n\nFiles, plots, viewer, environment, etc. panes\nConsole\nEditor"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#r",
    "href": "ae/ae-02-flint-sa.html#r",
    "title": "Exploring Flint’s water data",
    "section": "R",
    "text": "R\n\nWriting code in the console\nBasic math with R\nCreating variables in R, the assignment operator (&lt;-), and the Environment pane\nR functions and packages and the Packages pane\nGetting help with R and the Help pane"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#quarto",
    "href": "ae/ae-02-flint-sa.html#quarto",
    "title": "Exploring Flint’s water data",
    "section": "Quarto",
    "text": "Quarto\n\nYAML: Metadata\nNarrative: Edited with the visual editor (or the source editor)\nCode: In code chunks\n\nChunk options (following #|)\nComments (following #)\nCode\n\nRunning individual code chunks vs. rendering a document"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#load-packages",
    "href": "ae/ae-02-flint-sa.html#load-packages",
    "title": "Exploring Flint’s water data",
    "section": "Load packages",
    "text": "Load packages\nWe’ll use the tidyverse package for analysis, which offers functionality for data import, wrangling, visualization, and more.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nLoading this package prints out a message. What does this message mean? How can we suppress the message from the output?"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#load-data",
    "href": "ae/ae-02-flint-sa.html#load-data",
    "title": "Exploring Flint’s water data",
    "section": "Load data",
    "text": "Load data\nThe read_csv() function can be used for reading CSV (comma separated values) files. The file we’re reading is called flint with the suffix (.csv) which indicates its file type. The file is in the data folder.\nBefore reading in the file, go to the data folder in the Files pane to confirm that it is, indeed, there. Then, read the file by running the code chunk below by clicking on the green triangle icon on the code chunk.\n\nflint &lt;- read_csv(\"data/flint.csv\")\n\nRows: 813 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): draw\ndbl (4): id, zip, ward, lead\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nOne of two things may have happened:\n\nThe file was read successfully and you now see a dataset called flint in your Environment pane.\nThe file was not read successfully and you see an error Error in read_csv(\"data/flint.csv\") : could not find function \"read_csv\".\n\nIf (1) happened, great!\nIf (2) happened, let’s troubleshoot first before continuing."
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#data-dictionary",
    "href": "ae/ae-02-flint-sa.html#data-dictionary",
    "title": "Exploring Flint’s water data",
    "section": "Data dictionary",
    "text": "Data dictionary\nThe following variables are in the flint data frame:\n\nid: sample ID number (identifies the home)\nzip: ZIP code in Flint of the sample’s location\nward: ward in Flint of the sample’s location\ndraw: which time point the water was sampled from\nlead: lead content in parts per billion (ppb)"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#populations-and-samples",
    "href": "ae/ae-02-flint-sa.html#populations-and-samples",
    "title": "Exploring Flint’s water data",
    "section": "Populations and samples",
    "text": "Populations and samples\nWe want to learn about the population using a sample.\nIn the case we want to learn about the lead content in all of Flint, MI homes but only have available water readings from a sample of homes (our data set).\nExercise 1: Look at the data, how many observations are there? How many variables?\n\nThere are 813 observations and 5 variables.\n\n\nnrow(flint)\n\n[1] 813\n\nncol(flint)\n\n[1] 5"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#frequencies",
    "href": "ae/ae-02-flint-sa.html#frequencies",
    "title": "Exploring Flint’s water data",
    "section": "Frequencies",
    "text": "Frequencies\nLet’s count() to find the number of different time points water was sampled with the count() function.\n\nThe first argument is flint: the data frame\nThe second argument is draw: the variable\n\n\ncount(flint, draw)\n\n# A tibble: 3 × 2\n  draw       n\n  &lt;chr&gt;  &lt;int&gt;\n1 first    271\n2 second   271\n3 third    271\n\n\nWe can achieve the same result with the following “piped” operation as well.\n\nThe first line is flint: the data frame\nThen the pipe operator, read as “and then”, which places what comes before it as the first argument of what comes after it\nThe second line is count(draw)\n\n\nflint |&gt;\n  count(draw)\n\n# A tibble: 3 × 2\n  draw       n\n  &lt;chr&gt;  &lt;int&gt;\n1 first    271\n2 second   271\n3 third    271\n\n\nWe can use a similar approach to fund out how many unique homes are in the data set:\n\nflint |&gt;\n  count(id)\n\n# A tibble: 269 × 2\n      id     n\n   &lt;dbl&gt; &lt;int&gt;\n 1     1     3\n 2     2     3\n 3     4     3\n 4     5     3\n 5     6     3\n 6     7     3\n 7     8     3\n 8     9     3\n 9    12     3\n10    13     3\n# ℹ 259 more rows\n\n\nExercise 2: How many samples were taken from each zip code?\n\nflint |&gt;\n  count(zip)\n\n# A tibble: 8 × 2\n    zip     n\n  &lt;dbl&gt; &lt;int&gt;\n1 48502     3\n2 48503   207\n3 48504   165\n4 48505   144\n5 48506   132\n6 48507   153\n7 48529     3\n8 48532     6\n\n\nExercise 3: Which ZIP code had the most samples drawn? Hint: See the help for count.\n\nThe zip code 48503 had the most samples drawn (207 samples).\n\n\nflint |&gt;\n  count(zip, sort = TRUE)\n\n# A tibble: 8 × 2\n    zip     n\n  &lt;dbl&gt; &lt;int&gt;\n1 48503   207\n2 48504   165\n3 48507   153\n4 48505   144\n5 48506   132\n6 48532     6\n7 48502     3\n8 48529     3"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#measures-of-central-tendency",
    "href": "ae/ae-02-flint-sa.html#measures-of-central-tendency",
    "title": "Exploring Flint’s water data",
    "section": "Measures of central tendency",
    "text": "Measures of central tendency\n\nmean\nmedian\nmode"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#measures-of-spread",
    "href": "ae/ae-02-flint-sa.html#measures-of-spread",
    "title": "Exploring Flint’s water data",
    "section": "Measures of spread",
    "text": "Measures of spread\n\nvariance\nstandard deviation\nrange\nquartiles\ninter-quartile range (IQR)"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#order-statistics",
    "href": "ae/ae-02-flint-sa.html#order-statistics",
    "title": "Exploring Flint’s water data",
    "section": "Order statistics",
    "text": "Order statistics\n\nquantiles\nminimum (0 percentile)\nmedian (50th percentile)\nmaximum (100 percentile)\n\n… and any other arbitrary function of the data you can come up with!\nExercise 4: Compute each of these statistics for lead ppb.\n\nflint |&gt;\n  summarize(\n    mean_lead = mean(lead),\n    median_lead = median(lead),\n    var_lead = var(lead),\n    sd_lead = sd(lead),\n    # etc.\n  )\n\n# A tibble: 1 × 4\n  mean_lead median_lead var_lead sd_lead\n      &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1      8.20        1.85    1718.    41.5"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#histograms",
    "href": "ae/ae-02-flint-sa.html#histograms",
    "title": "Exploring Flint’s water data",
    "section": "Histograms",
    "text": "Histograms\nLet’s take a look at the distribution of lead content in homes in Flint, MI.\n\nggplot(flint, aes(x = lead)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWe can make this plot look nicer/more useful by adjusting the number of bins and zooming into the x-axis.\n\nggplot(flint, aes(x = lead)) +\n  geom_histogram(bins = 50) +\n  coord_cartesian(xlim = c(0, 100))\n\n\n\n\n\n\n\n\nLet’s visualize some of our summary statistics on the plot.\nExercise 5: Add a new layer, geom_vline(xintercept = __, color = \"red\"), to the histogram below, filling in the blank with the mean.\n\nggplot(flint, aes(x = lead)) + \n  geom_histogram(bins = 50) + \n  coord_cartesian(xlim = c(0, 100)) +\n  geom_vline(xintercept = 8.202614, color = \"red\")\n\n\n\n\n\n\n\n\nExercise 6: Add one more layer which overlays the median, in a different color.\n\nggplot(flint, aes(x = lead)) + \n  geom_histogram(bins = 50) + \n  coord_cartesian(xlim = c(0, 100)) +\n  geom_vline(xintercept = 8.202614, color = \"red\") +\n  geom_vline(xintercept = 1.852, color = \"blue\")"
  },
  {
    "objectID": "ae/ae-02-flint-sa.html#box-plots",
    "href": "ae/ae-02-flint-sa.html#box-plots",
    "title": "Exploring Flint’s water data",
    "section": "Box plots",
    "text": "Box plots\nNext, let’s narrow our focus to the zip codes 48503, 48504, 48505, 48506, and 48507 and observations with lead values less than 1,000 ppb.\n\nflint_focus &lt;- flint |&gt;\n  filter(zip %in% 48503:48507 & lead &lt; 1000)\n\nExercise 7: Below are side-by-side box plots for the three flushing times in each of the five zip codes we considered. Add x and y labels; add a title by inserting title = \"title_name\" inside the labs() function.\n\nggplot(data = flint_focus, aes(y = factor(zip), x = lead)) +\n  geom_boxplot(aes(fill = factor(draw))) +\n  labs(x = \"Lead (ppb)\", y = \"Zip code\", fill = \"Flushing time\") +\n  scale_fill_discrete(\n    breaks = c(\"first\", \"second\", \"third\"),\n    labels = c(\"0 (sec)\", \"45 (sec)\", \"120 (sec)\")\n  )\n\n\n\n\n\n\n\n\nExercise 8: Add labels for x, y, a title, and subtitle to the code below to update the corresponding plot.\n\nggplot(data = flint_focus, aes(y = factor(zip), x = lead)) +\n  geom_boxplot(aes(fill = factor(draw))) + \n  labs(\n    x = \"Lead (ppb)\", y = \"Zip code\", fill = \"Flushing time\",\n    title = \"Lead amount by flushing time\",\n    subtitle = \"In five zip codes\"\n    ) +\n  scale_fill_discrete(\n    breaks = c(\"first\", \"second\", \"third\"),\n    labels = c(\"0 (sec)\", \"45 (sec)\", \"120 (sec)\")\n  ) +\n  coord_cartesian(xlim = c(0, 50)) +\n  theme_bw()\n\n\n\n\n\n\n\n\nExercise 9: What is the difference between the two plots? What are the advantages and disadvantages to each plot?\n\nThe first plot shows the extreme outliers, while the second plot makes it easier to see the bulk of the distribution."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 101 Data Analysis and Statistical Inference",
    "section": "",
    "text": "Below is a prospective outline for the course, but things may change with advanced notice:\n\n\n\n\n\n\n\n\nWEEK\nDATE\nTOPIC\nPREPARE\nMATERIALS\nDUE\n\n\n\n\n1\nTue, Aug 27\nWelcome!\n\n\n\n\n\n\n\n\n\n\nThu, Aug 29\nData\n\n\n\n\n\n\n\n\n\n\nFri, Aug 30\nLab 1\n\n\n\n\n\n\n\n\n2\nTue, Sep 3\nStudy design\n\n\n\n\n\n\n\n\n\n\nThu, Sep 5\nCategorical data\n\n\n\n\n\n\n\n\n\n\nFri, Sep 6\nLab 2\n\n\n\n\n\n\n\n\n3\nTue, Sep 10\nNumerical data\n\n\n\n\n\n\n\n\n\n\nThu, Sep 12\nRegression 1\n\n\n\n\n\n\n\n\n\n\nFri, Sep 13\nLab 3\n\n\n\n\n\n\n\n\n4\nTue, Sep 17\nRegression 2\n\n\n\n\n\n\n\n\n\n\nThu, Sep 19\nModel selection\n\n\n\n\n\n\n\n\n\n\nFri, Sep 20\nLab 4\n\n\n\n\n\n\n\n\n5\nTue, Sep 24\nRegression overview\n\n\n\n\n\n\n\n\n\n\nThu, Sep 26\nLogistic regression 1\n\n\n\n\n\n\n\n\n\n\nFri, Sep 27\nLab: Exam Review\n\n\n\n\n\n\n\n\n6\nTue, Oct 1\nIn-class Exam 1\n\n\n\n\n\n\n\n\n\n\nThu, Oct 3\nNo lecture\n\n\n\n\n\n\n\n\n\n\nFri, Oct 4\nNo lab\n\n\n\n\n\n\n\n\n7\nTue, Oct 8\nLogistic Regression 2\n\n\n\n\n\n\n\n\n\n\nThu, Oct 10\nHypothesis testing\n\n\n\n\n\n\n\n\n\n\nFri, Oct 11\nNo lab\n\n\n\n\n\n\n\n\n8\nTue, Oct 15\nNo lecture\n\n\n\n\n\n\n\n\n\n\nThu, Oct 17\nConfidence intervals\n\n\n\n\n\n\n\n\n\n\nFri, Oct 18\nLab 5\n\n\n\n\n\n\n\n\n9\nTue, Oct 22\nDecision errors\n\n\n\n\n\n\n\n\n\n\nThu, Oct 24\nInference with mathematical models\n\n\n\n\n\n\n\n\n\n\nFri, Oct 25\nLab 6\n\n\n\n\n\n\n\n\n10\nTue, Oct 29\nInference for one proportion\n\n\n\n\n\n\n\n\n\n\nThu, Oct 31\nComparing two proportions\n\n\n\n\n\n\n\n\n\n\nFri, Nov 1\nLab 7\n\n\n\n\n\n\n\n\n11\nTue, Nov 5\nInference for two-way tables\n\n\n\n\n\n\n\n\n\n\nThu, Nov 7\nProportions overview\n\n\n\n\n\n\n\n\n\n\nFri, Nov 8\nLab 8\n\n\n\n\n\n\n\n\n12\nTue, Nov 12\nInference for one mean\n\n\n\n\n\n\n\n\n\n\nThu, Nov 14\nInference for two means\n\n\n\n\n\n\n\n\n\n\nFri, Nov 15\nLab: Exam Review\n\n\n\n\n\n\n\n\n13\nTue, Nov 19\nIn-class Exam 2\n\n\n\n\n\n\n\n\n\n\nThu, Nov 21\nNo lecture\n\n\n\n\n\n\n\n\n\n\nFri, Nov 22\nNo lab\n\n\n\n\n\n\n\n\n14\nTue, Nov 26\nANOVA\n\n\n\n\n\n\n\n\n\n\nThu, Nov 28\nNo lecture\n\n\n\n\n\n\n\n\n\n\nFri, Nov 29\nNo lab\n\n\n\n\n\n\n\n\n15\nTue, Dec 3\nEthics\n\n\n\n\n\n\n\n\n\n\nThu, Dec 5\nTelling a (data) story\n\n\n\n\n\n\n\n\n\n\nFri, Dec 6\nNo lab",
    "crumbs": [
      "Syllabus",
      "Schedule"
    ]
  },
  {
    "objectID": "exam-review/exam-2-review.html",
    "href": "exam-review/exam-2-review.html",
    "title": "Exam 2 Review",
    "section": "",
    "text": "Gallup polls have consistently found large differences in alcohol consumption among education and income subgroups over time. The income and education differences in drinking are typically larger than those seen by other demographic characteristics, such as gender, age, race, region, and religion.\nThe table below shows the distribution of data from a Gallup poll that asked respondents about their preferred alcoholic beverage (beer, wine, or liquor) and their income bracket.\n\n\n\n\n\n\n\n\n\nIncome\nBeer\nWine\nLiquor\nTotal\n\n\n\n\nLess than $30,000\n83\n67\n44\n194\n\n\n$30,000 - $74,999\n213\n161\n126\n500\n\n\n$75,000 or more\n110\n116\n80\n306\n\n\nTotal\n406\n344\n250\n1000\n\n\n\n\n\n\n\n\n\nIn evaluating the relationship between these two variables, what is the response variable and what is the explanatory variable?\n\n\n\nWhich of the following are appropriate visualizations for these data? Check all that apply.\nI.   Pie chart\nII.  Ridge plot\nIII. Side-by-side box plots\nIV.  Mosaic plot\nV.  Stacked bar plot\n\nI\nI and II\nII and III\nIV and V\nOnly V\n\n\n\n\nWhat are the hypotheses for evaluating whether there is a relationship between income bracket and preferred alcoholic beverage?\n\n\n\nIf in fact the null hypothesis is true, how many Americans who make between XXX would we expect to have liquor as their preferred alcoholic beverage?\n\n\n\nThe following plot is a histogram of the null distribution for this hypothesis test, created using the code below. The observed statistic is 4.74. Shade the area corresponding to the p-value for this test on the histogram of the null distribution below.\n\nset.seed(1234)\n\nnull_dist &lt;- income_alcohol |&gt;\n  specify(response = alcohol, explanatory = income) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\") |&gt;\n  calculate(stat = \"Chisq\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstimate the p-value. In your answer, describe how you arrived at your answer.\n\n\n\nBased on your answer to the previous question, what is the conclusion of the hypothesis test at the 5% discernibility level?"
  },
  {
    "objectID": "exam-review/exam-2-review.html#question-1",
    "href": "exam-review/exam-2-review.html#question-1",
    "title": "Exam 2 Review",
    "section": "",
    "text": "In evaluating the relationship between these two variables, what is the response variable and what is the explanatory variable?"
  },
  {
    "objectID": "exam-review/exam-2-review.html#question-2",
    "href": "exam-review/exam-2-review.html#question-2",
    "title": "Exam 2 Review",
    "section": "",
    "text": "Which of the following are appropriate visualizations for these data? Check all that apply.\nI.   Pie chart\nII.  Ridge plot\nIII. Side-by-side box plots\nIV.  Mosaic plot\nV.  Stacked bar plot\n\nI\nI and II\nII and III\nIV and V\nOnly V"
  },
  {
    "objectID": "exam-review/exam-2-review.html#question-3",
    "href": "exam-review/exam-2-review.html#question-3",
    "title": "Exam 2 Review",
    "section": "",
    "text": "What are the hypotheses for evaluating whether there is a relationship between income bracket and preferred alcoholic beverage?"
  },
  {
    "objectID": "exam-review/exam-2-review.html#question-4",
    "href": "exam-review/exam-2-review.html#question-4",
    "title": "Exam 2 Review",
    "section": "",
    "text": "If in fact the null hypothesis is true, how many Americans who make between XXX would we expect to have liquor as their preferred alcoholic beverage?"
  },
  {
    "objectID": "exam-review/exam-2-review.html#question-5",
    "href": "exam-review/exam-2-review.html#question-5",
    "title": "Exam 2 Review",
    "section": "",
    "text": "The following plot is a histogram of the null distribution for this hypothesis test, created using the code below. The observed statistic is 4.74. Shade the area corresponding to the p-value for this test on the histogram of the null distribution below.\n\nset.seed(1234)\n\nnull_dist &lt;- income_alcohol |&gt;\n  specify(response = alcohol, explanatory = income) |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\") |&gt;\n  calculate(stat = \"Chisq\")"
  },
  {
    "objectID": "exam-review/exam-2-review.html#question-6",
    "href": "exam-review/exam-2-review.html#question-6",
    "title": "Exam 2 Review",
    "section": "",
    "text": "Estimate the p-value. In your answer, describe how you arrived at your answer."
  },
  {
    "objectID": "exam-review/exam-2-review.html#question-7",
    "href": "exam-review/exam-2-review.html#question-7",
    "title": "Exam 2 Review",
    "section": "",
    "text": "Based on your answer to the previous question, what is the conclusion of the hypothesis test at the 5% discernibility level?"
  },
  {
    "objectID": "exam-review/exam-2-review.html#question-8",
    "href": "exam-review/exam-2-review.html#question-8",
    "title": "Exam 2 Review",
    "section": "Question 8",
    "text": "Question 8\nDescribe how you can set up a simulation to estimate the proportion of statistics majors who work 5 or more hours each week based on this sample."
  },
  {
    "objectID": "exam-review/exam-2-review.html#question-9",
    "href": "exam-review/exam-2-review.html#question-9",
    "title": "Exam 2 Review",
    "section": "Question 9",
    "text": "Question 9\nA bootstrap distribution with 1000 simulations is show below. Approximate the bounds of the 95% confidence interval based on this distribution."
  },
  {
    "objectID": "exam-review/exam-2-review.html#question-10",
    "href": "exam-review/exam-2-review.html#question-10",
    "title": "Exam 2 Review",
    "section": "Question 10",
    "text": "Question 10\nSuppose the lower bound of the confidence interval from the previous question is L and the upper bound is U. Which of the following is correct?\na. Between L to U of statistics majors work at least 5 hours per week.\nb. 95% of the time the true proportion of statistics majors who work at least 5 hours per week is between L and U.\nc. Between L and U of random samples of 25 statistics majors are expected to yield confidence intervals that contain the true proportion of statistics majors who work at least 5 hours per week.\nd. 95% of random samples of 25 statistics majors will yield confidence intervals between L and U.\ne. None of the above."
  },
  {
    "objectID": "exam-review/exam-2-review.html#question-11",
    "href": "exam-review/exam-2-review.html#question-11",
    "title": "Exam 2 Review",
    "section": "Question 11",
    "text": "Question 11\nEstimate the standard error of the bootstrap distribution."
  },
  {
    "objectID": "exam-review/exam-2-review.html#question-12",
    "href": "exam-review/exam-2-review.html#question-12",
    "title": "Exam 2 Review",
    "section": "Question 12",
    "text": "Question 12\nChoose the best answer.\nA survey based on a random sample of 2,045 American teenagers found that a 95% confidence interval for the mean number of texts sent per month was (1450, 1550). A valid interpretation of this interval is\n\n95% of all teens who text send between 1450 and 1550 text messages per month.\nIf a new survey with the same sample size were to be taken, there is a 95% chance that the mean number of texts in the sample would be between 1450 and 1550.\nWe are 95% confident that the mean number of texts per month of all American teens is between 1450 and 1550.\nWe are 95% confident that, were we to repeat this survey, the mean number of texts per month of those taking part in the survey would be between 1450 and 1550."
  },
  {
    "objectID": "exam-review/exam-2-review.html#question-13",
    "href": "exam-review/exam-2-review.html#question-13",
    "title": "Exam 2 Review",
    "section": "Question 13",
    "text": "Question 13\nWhich is bigger?\nA researcher is planning to conduct a test of two proportions. The null hypothesis is XXX. The researcher has found that in their data XXX.\nI. P-value associated if XXX II. P-value associated if XXX\n\nI &gt; II\nI &lt; II\nI = II"
  },
  {
    "objectID": "exam-review/exam-2-review.html#question-14",
    "href": "exam-review/exam-2-review.html#question-14",
    "title": "Exam 2 Review",
    "section": "Question 14",
    "text": "Question 14\nFill in the blanks.\na. Power of the test is the probability of ___.\nb. Type 1 error rate is the probability of ___.\nc. Type 2 error rate is the probability of ___.\nd. Unbeknownst to you, let’s say that the null hypothesis is actually true in the population. You plan to run a study anyway. If the level of discernibility you choose (i.e., the cutoff for your p-value) is 0.05, the probability that you will mistakenly reject the null hypothesis is ____."
  },
  {
    "objectID": "exam-review/exam-2-review.html#question-15",
    "href": "exam-review/exam-2-review.html#question-15",
    "title": "Exam 2 Review",
    "section": "Question 15",
    "text": "Question 15\nTrue or false. And, if false, explain your reasoning.\na. The central limit theorem tells us that the sampling distribution of a sample proportion will be centered at XXX.\nb. Increasing the number of bootstrap samples will decrease the width of the confidence interval.\nc. The bootstrap distribution of a sample proportion, XXX, will be centered at XXX."
  },
  {
    "objectID": "exam-review/exam-2-review.html#bonus",
    "href": "exam-review/exam-2-review.html#bonus",
    "title": "Exam 2 Review",
    "section": "Bonus",
    "text": "Bonus\nPick a concept we introduced in class so far that you’ve been struggling with and explain it in your own words."
  },
  {
    "objectID": "exam-review/exam-1-review-sa.html",
    "href": "exam-review/exam-1-review-sa.html",
    "title": "Exam 1 Review",
    "section": "",
    "text": "There are 409 rows in the blizzard_salary dataset. Each row represents a Blizzard Entertainment worker who filled out the spreadsheet.\na - Figure 1 - A shared x-axis makes it easier to compare summary statistics for the variable on the x-axis.\nc - It’s a value higher than the median for hourly but lower than the mean for salaried.\nb - There is more variability around the mean compared to the hourly distribution.\nb - Pie charts and waffle charts are for categorical data only.\nc - For every additional $1,000 of annual salary, the model predicts the raise to be higher, on average, by 0.0155%.\nd - \\(R^2\\) of raise_2_fit is higher than \\(R^2\\) of raise_1_fit since raise_2_fit has one more predictor and \\(R^2\\) always goes up with the addition of a predictor.\nThe reference level of performance_rating is High, since it’s the first level alphabetically. Therefore, the coefficient -2.40% is the predicted difference in raise comparing High to Successful. In this context a negative coefficient makes sense since we would expect those with High performance rating to get higher raises than those with Successful performance.\na - “Poor”, “Successful”, “High”, “Top”\nChoose Option 2 since it shows the proportions of employees with top, high, successful, and poor performance within each salary type, and is not affected by there being much fewer hourly paid employees. Proportions of employees with top and successful performance ratings are higher for employees paid hourly than salaried.\nThere may be some NAs in these two variables that are not visible in the plot.\nThe proportions under Hourly would go in the Hourly bar, and those under Salaried would go in the Salaried bar.\nThis is a mosaic plot. It shows the marginal distribution of salary type (proportion of hourly and salaried employees), which is not displayed in the previous plot.\nc - Option 3. Parallel lines and salaried line has a higher intercept since Hourly is the reference level in raise_3_fit and the slope for salary_typeSalaried is positive.\nA parsimonious model is the simplest model with the best predictive performance."
  },
  {
    "objectID": "project/project-2.html",
    "href": "project/project-2.html",
    "title": "Project 2",
    "section": "",
    "text": "Team assignments are posted at https://canvas.duke.edu/courses/4625/files?preview=549493.\nThe deliverable for this project (what you will turn in) is a written report and a pre-recorded presentation. See below for more details.",
    "crumbs": [
      "Project"
    ]
  },
  {
    "objectID": "project/project-2.html#criteria-for-datasets",
    "href": "project/project-2.html#criteria-for-datasets",
    "title": "Project 2",
    "section": "Criteria for datasets",
    "text": "Criteria for datasets\nThe data sets should meet the following criteria:\n\nAt least 100 observations\nAt least 5 columns\nAt least 4 of the columns must be useful and unique explanatory variables.\n\nIdentifier variables such as “name”, “social security number”, etc. are not useful explanatory variables.\nIf you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique explanatory variables.\n\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\n\n\n\n\n\n\n\nTip\n\n\n\nPlease ask a member of the teaching team if you’re unsure whether your data set meets the criteria.\n\n\nIf you set your hearts on a dataset that has fewer observations or variables than what’s suggested here, that might still be ok; use these numbers as guidance for a successful proposal, not as minimum requirements.",
    "crumbs": [
      "Project"
    ]
  },
  {
    "objectID": "project/project-2.html#resources",
    "href": "project/project-2.html#resources",
    "title": "Project 2",
    "section": "Resources for datasets",
    "text": "Resources for datasets\nYou can find data wherever you like, but here are some recommendations to get you started. You shouldn’t feel constrained to datasets that are already in a tidy format, you can start with data that needs cleaning and tidying, scrape data off the web, or collect your own data.\n\nAwesome public datasets\nBikeshare data portal\nCDC\nData.gov\nData is Plural\nDurham Open Data Portal\nEdinburgh Open Data\nElection Studies\nEuropean Statistics\nCORGIS: The Collection of Really Great, Interesting, Situated Datasets\nGeneral Social Survey\nGoogle Dataset Search\nHarvard Dataverse\nInternational Monetary Fund\nIPUMS survey data from around the world\nLos Angeles Open Data\nNational Crime Victimization Survey\nNHS Scotland Open Data\nNYC OpenData\nOpen access to Scotland’s official statistics\nPew Research\nPRISM Data Archive Project\nStatistics Canada\nThe National Bureau of Economic Research\nTidyTuesday\nUCI Machine Learning Repository\nUK Government Data\nUNICEF Data\nUnited Nations Data\nUnited Nations Statistics Division\nUS Census Data\nUS Government Data\nWorld Bank Data\nYouth Risk Behavior Surveillance System (YRBSS)",
    "crumbs": [
      "Project"
    ]
  },
  {
    "objectID": "project/project-2.html#proposal-conversation-grading",
    "href": "project/project-2.html#proposal-conversation-grading",
    "title": "Project 2",
    "section": "Proposal conversation grading",
    "text": "Proposal conversation grading\nEach component will be graded as follows:\n\nMeets expectations (full credit): All team members are present and contribute to the conversation. The team has a dataset and research question identified. There is a plan for completing the project as envisioned.\nClose to expectations (half credit): Not all team members are present and contribute to the conversation (without any excused absences). The team does not have a dataset and/or research question identified. The plan for completing the project as envisioned is not well designed.\nDoes not meet expectations (no credit): Not all team members are present and contribute to the conversation (without any excused absences). The team does not have a dataset or research question identified. There is no plan for completing the project as envisioned.\n\nEven if you earn full credit, it may not mean that your proposal is perfect.",
    "crumbs": [
      "Project"
    ]
  },
  {
    "objectID": "project/project-2.html#components",
    "href": "project/project-2.html#components",
    "title": "Project 2",
    "section": "Components",
    "text": "Components\nYou should include, at a minimum, the following sections in your report.\n\nIntroduction (7 pts)\nThe introduction provides motivation and context for your research.\nTo begin, introduce the data set in a few short sentences. Next, create a code book (aka a “data dictionary”) of the variables in the data set. Although a code book is provided above, you should include one in your report as well so that your report is self-contained. Specifically, only include in your report a code book of the variables that you use.\nComplete the introduction by providing a concise, clear statement of your research question and hypotheses. Be sure to motivate why the research question is interesting/useful.\nExample research question and hypotheses (if we were predicting penguin weights instead of baby weights):\nCan we predict body mass with bill depth? We hypothesize that penguins with deeper bills will also have more mass.\n\n\nMethodology (15 pts)\nHere you should introduce any statistical methods you use and describe why you choose the methods you do to answer your question. You might also include any preliminary summary statistics or figures you use to explore the data.\n\n\nResults (15 pts)\nPlace figure(s) here to illustrate the main results from your analysis. 1 beautiful figure is worth more than several poorly formatted figures. You must have at least 1 figure.\nProvide only the main results from your analysis. The goal is not to do an exhaustive data analysis (calculate every possible statistic and create every possible model for all variables). Rather, you should demonstrate that you are proficient at asking meaningful questions and answering them using data, that you are skilled in writing about and interpreting results, and that you can accomplish these tasks using R. More is not better.\n\n\nDiscussion (6 pts)\nThis section is a conclusion and discussion. You should\n\nSummarize your main finding in a sentence or two.\nDiscuss your finding and why it is useful (put in the context of your motivation from the introduction).\nCritique your own analyses and include a brief paragraph on what you would do differently if you were able to start the project over.\n\n\n\nAppendix (2 pts)\nList a brief (1 or 2 sentence) summary of the relative contributions of each team member, e.g., “Aang built the models, Katara implemented them in R, and Sokka wrote the introduction and discussion.”\n\n\n\n\n\n\nImportant\n\n\n\nAll team members should be comfortable describing all aspects of the project and understanding all code.\n\n\n\n\nFormatting (5 pts)\nYour project should be professionally formatted. For example, this means labeling graphs and figures, turning off code chunks, using proper citations and cross-references, and following typical style guidelines.",
    "crumbs": [
      "Project"
    ]
  },
  {
    "objectID": "project/project-2.html#submission",
    "href": "project/project-2.html#submission",
    "title": "Project 2",
    "section": "Submission",
    "text": "Submission\n\nSelect one team member to upload the team’s PDF submission to Gradescope.\nBe sure to select every team member’s name in Gradescope.\nAssociate all pages with “Full report”.",
    "crumbs": [
      "Project"
    ]
  },
  {
    "objectID": "project/project-2.html#slides",
    "href": "project/project-2.html#slides",
    "title": "Project 2",
    "section": "Slides",
    "text": "Slides\nFor your presentation, you must create presentation slides that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and provide some conclusions. These slides should serve as a brief visual accompaniment to your write-up and will be graded for content and quality.\nHere is a suggested outline as you think through the slides; you do not have to use this exact format for the slide deck.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3 - 4: Highlights from exploratory data analysis\nSlide 4 - 5: Highlights from inference and/or modeling\nSlide 6: Conclusions + critique/shortcomings\n\nYou can create your slides with any software you like (Keynote, PowerPoint, Google Slides, etc.). We recommend choosing an option that’s easy to collaborate with, e.g., Google Slides.\n\n\n\n\n\n\nNote\n\n\n\nYou can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!",
    "crumbs": [
      "Project"
    ]
  },
  {
    "objectID": "project/project-2.html#recording",
    "href": "project/project-2.html#recording",
    "title": "Project 2",
    "section": "Recording",
    "text": "Recording\nPresentations will be submitted as a pre-recorded video by the due date.\nFor recording, you may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\nOnce your video is ready, upload the video to Warpwire or another video platform (e.g., YouTube), then add a link to your video at https://docs.google.com/spreadsheets/d/1mGLkIqhtUEylFR4Ovlpuysv4xWCz6L4FdWqFGmjUKPw/edit?usp=sharing.\nTo upload your video to Warpwire:\n\nClick the Warpwire tab in the course Canvas site.\nClick the “+” and select “Upload files”.\nLocate the video on your computer and click to upload.\nOnce you’ve uploaded the video to Warpwire, click to share the video and copy the video’s URL. You will need this when you post the video in the Project 2 spreadsheet.",
    "crumbs": [
      "Project"
    ]
  },
  {
    "objectID": "project/project-2.html#grading-summary",
    "href": "project/project-2.html#grading-summary",
    "title": "Project 2",
    "section": "Grading summary",
    "text": "Grading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.",
    "crumbs": [
      "Project"
    ]
  },
  {
    "objectID": "project/project-2.html#late-work-policy",
    "href": "project/project-2.html#late-work-policy",
    "title": "Project 2",
    "section": "Late work policy",
    "text": "Late work policy\nBe sure to turn in your work early to avoid any technological mishaps.\n\n\n\n\n\n\nWarning\n\n\n\nThere is no late work accepted on this project.",
    "crumbs": [
      "Project"
    ]
  },
  {
    "objectID": "computing/computing-access.html",
    "href": "computing/computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access RStudio in the browser, go to the Posit Cloud space for this course.\nAt the beginning of the semester you should have received a link to join this space. If you haven’t yet joined, you can find the link in Canvas Announcements or ask for it on the course Slack.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  },
  {
    "objectID": "computing/computing-troubleshooting.html",
    "href": "computing/computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If you’re having difficulty launching an RStudio session from Posit Cloud, go to status.posit.co and check under Posit Cloud.\n\nIf it shows “Operational”, this means the system is expected to be working. Check your internet connection, if need be, restart your computer to ensure a fresh new connection. If your issue persists, post on the course Slack with details on what you’ve tried and the errors you see (including verbatim errors and/or screenshots).\nIf it shows “Partial Outage” or “Outage” (or anything other than “Operational”), this means there is a known incident with the containers. Check back later to see if it’s been resolved. If there’s a deadline coming up soon, post on the course Slack to let us know that there’s an issue. We can look into how quickly it might get resolved and decide on what to do about the deadline accordingly. Note: We don’t anticipate this to happen regularly, the systems are Operational a huge majority of the time!s",
    "crumbs": [
      "Computing",
      "Troubleshooting"
    ]
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "This course introduces students to the discipline of statistics as a science of understanding and analyzing data. Themes include data collection, exploratory analysis, inference, and modeling. Focus on principles underlying quantitative research in social sciences, humanities, and public policy. Research projects teach the process of scientific discovery and synthesis and critical evaluation of research and statistical arguments. Readings give perspective on why in 1950, S. Wilks said, “Statistical thinking will one day be as necessary a qualification for efficient citizenship as the ability to read and write.”\nIn this course, students learn how to effectively make use of data in the face of uncertainty: how to collect data, how to analyze data, and how to use data to make inferences and conclusions about real world phenomena. Critiquing data-based claims and evaluating data-based decisions is at the core of this course. Throughout the course students acquire a conceptual understanding and mastery of statistical and quantitative reasoning tools in order to be able to make such critiques and evaluations.\nIn addition, students are presented with novel data sets and application examples on a daily basis, and they use these data to model outcomes and make inferences about unknown population characteristics. Students learn that the first step of any analysis is identifying the assumptions and conditions necessary to apply the statistical technique(s) required to answer the research question at hand. Students not only learn the mechanics of the quantitative analysis, but also how to interpret conclusions based on quantitative evidence in context of the data and the research questions as well as identifying limitations due to data collection and study design.\nFor the lab component of this course students prepare weekly lab reports presenting statistical analysis of real data. In addition, students complete two independent data analysis projects where they answer significant research questions via the analysis of real data using statistical inference and modeling tools."
  },
  {
    "objectID": "course-syllabus.html#course-description",
    "href": "course-syllabus.html#course-description",
    "title": "Syllabus",
    "section": "",
    "text": "This course introduces students to the discipline of statistics as a science of understanding and analyzing data. Themes include data collection, exploratory analysis, inference, and modeling. Focus on principles underlying quantitative research in social sciences, humanities, and public policy. Research projects teach the process of scientific discovery and synthesis and critical evaluation of research and statistical arguments. Readings give perspective on why in 1950, S. Wilks said, “Statistical thinking will one day be as necessary a qualification for efficient citizenship as the ability to read and write.”\nIn this course, students learn how to effectively make use of data in the face of uncertainty: how to collect data, how to analyze data, and how to use data to make inferences and conclusions about real world phenomena. Critiquing data-based claims and evaluating data-based decisions is at the core of this course. Throughout the course students acquire a conceptual understanding and mastery of statistical and quantitative reasoning tools in order to be able to make such critiques and evaluations.\nIn addition, students are presented with novel data sets and application examples on a daily basis, and they use these data to model outcomes and make inferences about unknown population characteristics. Students learn that the first step of any analysis is identifying the assumptions and conditions necessary to apply the statistical technique(s) required to answer the research question at hand. Students not only learn the mechanics of the quantitative analysis, but also how to interpret conclusions based on quantitative evidence in context of the data and the research questions as well as identifying limitations due to data collection and study design.\nFor the lab component of this course students prepare weekly lab reports presenting statistical analysis of real data. In addition, students complete two independent data analysis projects where they answer significant research questions via the analysis of real data using statistical inference and modeling tools."
  },
  {
    "objectID": "course-syllabus.html#learning-objectives",
    "href": "course-syllabus.html#learning-objectives",
    "title": "Syllabus",
    "section": "Learning objectives",
    "text": "Learning objectives\nThe course learning objectives are as follows:\n\nRecognize the importance of data collection, identify limitations in data collection methods, and determine how they affect the scope of inference.\nUse statistical software to summarize data numerically and visually, and to perform data analysis.\nHave a conceptual understanding of the unified nature of statistical inference.\nApply estimation and testing methods to analyze single variables or the relationship between two variables in order to understand natural phenomena and make data-based decisions.\nModel numerical response variables using a single or multiple explanatory variables.\nInterpret results correctly, effectively, and in context without relying on statistical jargon.\nCritique data-based claims and evaluate data-based decisions.\nComplete research projects demonstrating mastery of statistical data analysis from exploratory analysis to inference to modeling."
  },
  {
    "objectID": "course-syllabus.html#prerequisites",
    "href": "course-syllabus.html#prerequisites",
    "title": "Syllabus",
    "section": "Prerequisites",
    "text": "Prerequisites\nThis course has no pre-requisites."
  },
  {
    "objectID": "course-syllabus.html#workload",
    "href": "course-syllabus.html#workload",
    "title": "Syllabus",
    "section": "Workload",
    "text": "Workload\nYou are expected to put in ~6 hours of work / week outside of class. Some of you will do well with less time than this, and some of you will need more."
  },
  {
    "objectID": "course-syllabus.html#tips-for-success",
    "href": "course-syllabus.html#tips-for-success",
    "title": "Syllabus",
    "section": "Tips for success",
    "text": "Tips for success\n\nComplete the reading before a new unit begins, and then review again after the unit is over.\nBe an active participant during lectures and labs.\nAsk questions - during class or office hours, or by email. Ask me, your TAs, and your classmates.\nDo the problem sets - start early and make sure you attempt and understand all questions.\nStart your project early and and allow adequate time to complete it.\nGive yourself plenty of time time to prepare a good cheat sheet for exams. This requires going through the material and taking the time to review the concepts that you’re not comfortable with.\nDo not procrastinate - don’t let a unit go by with unanswered questions as it will just make the following unit’s material even more difficult to follow."
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nReadings for the course will come from the following textbooks. They are freely available online and you do not need to purchase a physical copy of either book to succeed in this class.\n\n[ims]: Mine Çetinkaya-Rundel and Jo Hardin. Introduction to Modern Statistics. (in progress) 2nd edition. OpenIntro, 2023.\n[r4ds]: Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund. R for Data Science. 2nd edition. O’Reilly, 2022."
  },
  {
    "objectID": "course-syllabus.html#course-community",
    "href": "course-syllabus.html#course-community",
    "title": "Syllabus",
    "section": "Course community",
    "text": "Course community\n\nDuke Community Standard\nAll students must adhere to the Duke Community Standard (DCS): Duke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nTo uphold the Duke Community Standard, students agree:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\n\n\n\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know! You’ll be able to note this in the Getting to know you survey.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nPronouns\nPronouns are meaningful tools to communicate identities and experiences, and using pronouns supports a campus environment where all community members can thrive.\nPlease update your gender pronouns in Duke Hub. You can learn more at the Center for Sexual and Gender Diversity’s website.\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website: sta101-f23.github.io.\nI will regularly send course announcements via email and Canvas, make sure to check one or the other of these regularly. If an announcement is sent Monday through Thursday, I will assume that you have read the announcement by the next day. If an announcement is sent on a Friday or over the weekend, I will assume that you have read it by Monday.\n\n\nWhere to get help\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the course Slack. There is a chance another student has already asked a similar question, so please check the other posts on Slack before adding a new question. If you know the answer to a question posted on Slack, I encourage you to respond!\n\nCheck out the Support page for more resources.\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don’t hesitate to ask.\n\nYou never owe me personal information about your health (mental or physical) but you’re always welcome to talk to me. If I can’t help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this crisis."
  },
  {
    "objectID": "course-syllabus.html#lectures-and-lab",
    "href": "course-syllabus.html#lectures-and-lab",
    "title": "Syllabus",
    "section": "Lectures and lab",
    "text": "Lectures and lab\nThe goal of both the lectures and the labs is for them to be as interactive as possible. My role as instructor is to introduce you new tools and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities throughout each lecture and lab. Attendance will not be taken during class but you are expected to attend all lecture and lab sessions and meaningfully contribute to in-class exercises and discussion.\nYou are expected to bring a laptop to each class so that you can take part in the in-class exercises. Please make sure your laptop is fully charged before you come to class as the number of outlets in the classroom will not be sufficient to accommodate everyone. See Duke LIFE loaner laptop program if you need a loaner laptop."
  },
  {
    "objectID": "course-syllabus.html#assessments-and-grading",
    "href": "course-syllabus.html#assessments-and-grading",
    "title": "Syllabus",
    "section": "Assessments and grading",
    "text": "Assessments and grading\nThe final course grade will be calculated as follows:\n\n\n\nCategory\nPercentage\n\n\n\n\nAttendance and participation\n5%\n\n\nInteractive tutorials\n5%\n\n\nLabs\n25%\n\n\nExam 1\n20%\n\n\nExam 2\n20%\n\n\nProject 1\n10%\n\n\nProject 2\n15%\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n&gt;= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n&lt; 60\n\n\n\nThese are upper bounds for grade cutoffs, depending on the class performance the cutoffs may be lowered but they won’t be increased.\nAll work is expected to be submitted by the deadline and there are no make ups for any missed assessments. See Section 10.2 for policies on late work.\n\nAttendance and participation\nYou are expected to be present at class meeting and actively participate in the discussion. Your attendance and participation during class, as well as your activity on the course Slack will make up a non-insignificant portion of your grade in this class. While I might sometimes call on you during the class discussion, it is your responsibility to be an active participant without being called on.\nIf you attend at least 80% of the classes, you’ll get all available points for this component.\n\n\nInteractive tutorials\nYou will be assigned a number of interactive tutorials each week from the textbook. You will be asked to submit these on a weekly basis and graded on a check/no check basis.\nMake sure to add your name and your Net ID before generating the hash. Submit these in Canvas.\nIf you’ve completed at least 80% of the tutorials, you’ll get all available points for this component.\n\n\nLabs\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios. Labs will focus on both computation and conceptualization. Lab assignments will be completed using Quarto and submitted as PDF for grading in Gradescope. While you may collaborate with others on lab assignments, your final solution should be your own.\nLowest lab score will be dropped.\n\n\nExams\nThere will be two exams. Each exam will be comprised of two components:\n\nIn class: 75 minute in-class exam. This exam is closed book, however you are allowed to use one sheet of notes (“cheat sheet”) to the midterm and the final. This sheet must be no larger than 8 1/2 x 11, and must be prepared by you. You may use both sides of the sheet. (70% of the grade)\nTake home: Following the in class exam, you’ll have 48 hours to complete the take home portion of your exam. The take home portion will follow from the in class exam and focus on the analysis of a dataset introduced in the take home exam. (30% of the grade)\n\nThrough these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. Each exam will include small analyses and computational tasks related to the content in application exercises and labs. More details about the content and structure of the exams will be discussed during the semester.\nSee Section 12 for dates and times of the exams. Exam dates cannot be changed and no make-up exams will be given. If you can’t take the exams on these dates, you should drop this class.\n\n\nProjects\nThere will be a mid-semester prediction project and a final project. The prediction project will introduce you to conducting independent analyses and writing a formal report using a pre-specified data set. The final project allows you to explore a question and data set of your own. More details about the projects will be provided during the semester. Projects will be completed in teams.\nYou will be assigned to a different team for each of your two projects. You are encouraged to sit with your teammates in lecture and you will also work with them in the lab sessions. All team members are expected to contribute equally to the completion of each project and you will be asked to evaluate your team members after each assignment is due. Failure to adequately contribute to an assignment will result in a penalty to your mark relative to the team’s overall mark.\nSee Section 12 for dates and times of project deadlines. Project deadlines cannot be changed. If you can’t be in class for the final project presentation, you should drop this class."
  },
  {
    "objectID": "course-syllabus.html#course-policies",
    "href": "course-syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nAcademic honesty\nTL;DR: Don’t cheat!\nPlease abide by the following as you work on assignments in this course:\n\nCollaboration: Only work that is clearly assigned as team work should be completed collaboratively.\n\nThe labs must also be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what’s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to lab questions (including any code) with anyone other than myself and the teaching assistants.\nFor the projects, collaboration within teams is not only allowed, but expected. Communication between teams at a high level is also allowed however you may not share code or components of the project across teams.\nOn individual assignments you may not directly share code with another student in this class, and on team assignments you may not directly share code with another team in this class.\n\nOnline resources: I am well aware that a huge volume of code is available on the web to solve any number of problems. Unless I explicitly tell you not to use something, the course’s policy is that you may make use of any online resources (e.g., StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nUse of generative artificial intelligence (AI): You should treat generative AI, such as ChatGPT, the same as other online resources. There are two guiding principles that govern how you can use AI in this course:1 (1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning. (2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\n✅ AI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. You may use these guidelines for citing AI-generated content.\n❌ AI tools for narrative: Unless instructed otherwise, you may not use generative AI to write narrative on assignments. In general, you may use generative AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content.\n\n\nRegardless of course delivery format, it is the responsibility of all students to understand and follow all Duke policies, including academic integrity (e.g., completing one’s own work, following proper citation of sources, adhering to guidance around group work projects, and more). Ignoring these requirements is a violation of the Duke Community Standard. Any questions and/or concerns regarding academic integrity can be directed to the Office of Student Conduct and Community Standards at conduct@duke.edu.\nAny violations in academic honesty standards as outlined in the Duke Community Standard and those specific to this course will\n\nautomatically result in a 0 for the assignment,\ncan further impact your overall course grade, and\nwill be reported to the Office of Student Conduct for further action.\n\n\n\nLate work & extensions\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback within a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline.\nPolicy on late work depends on the particular course component:\n\nLabs:\n\nLate, but within 24 hours of deadline: -20% of available points.\nAny later: No credit, and we will not provide written feedback.\nNote that lowest lab score will be dropped, even if that score is a 0.\n\nExams:\n\nIn class portions of the exams can obviously not be turned in late.\nLate exams are not accepted.\n\nProjects: The following three components contribute to your project score.\n\nPresentation: Late presentations are not accepted and there are no make ups for missed presentations.\nWrite up: GitHub repositories will be closed to contributions at the deadline. If you need to submit your work late, Slack/email me to reopen your repository.\n\nLate, but within 24 hours of deadline: -20% of available points.\nAny later: No credit, and we will not provide written feedback.\n\nPeer evaluation: Late peer evaluations are not accepted. If you do not turn in your peer evaluation, you get 0 points for your own peer score as well, regardless of how your teammates have evaluated you.\n\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab or homework assignment by the stated due date, you may email the Head TA (Shuo Wang, shuo.wang717@duke.edu) before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used for once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let me know if you need help contacting your academic dean.\n\n\nRegrade requests\nEvery effort will be made to mark your work accurately. We are on your side, and want you to receive every point you have worked to earn. However, sometimes grading mistakes happen. If you believe that an error has been made, return the paper to the instructor within four days, stating your claim in writing.\nThe following claims will be considered for re-grading:\n\npoints are not totaled correctly;\nthe grader did not see a correct answer that is on your paper;\nyour answer is the same as the correct answer, but in a different form (e.g., you wrote a correct answer as 1/3 and the grader was looking for 0.333);\nyour answer to a free response question is essentially correct but stated slightly differently than the grader’s expectation.\n\nThe following claims will not be considered for re-grading:\n\narguments about the number of points lost;\narguments about question wording.\n\nConsidering re-grades consumes time and resources that TAs and the instructor would rather spend helping you understand material. Please bring only claims of type 1-4 to our attention.\nNote that during the regrade process your score could go up or go down or not change.\n\n\n\n\n\n\nWarning\n\n\n\nNo grades will be changed after the project presentations.\n\n\n\n\nAttendance policy\nResponsibility for class attendance rests with individual students. Since regular and punctual class attendance is expected, students must accept the consequences of failure to attend. More details on Trinity attendance policies are available here.\nHowever, there may be many reasons why you cannot be in class on a given day, particularly with possible extra personal and academic stress and health concerns this semester. All course lectures will be recorded and available to enrolled students after class. If you miss a lecture, make sure to watch the recording and review the material before the next class session. Lab time is dedicated to working on your assignments and collaborating with your teammates on your project. If you miss a lab session, make sure to communicate with your team about how you can make up your contribution. Given the technologies we use in the course, this is straightforward to do asynchronously. If you know you’re going to miss a lab session and you’re feeling well enough to do so, notify your teammates ahead of time. Overall these policies are put in place to ensure communication between team members, respect for each others’ time, and also to give you a safety net in the case of illness or other reasons that keep you away from attending class.\nNote that attendance and participation is part of your grade as well.\n\n\nAttendance policy related to COVID symptoms, exposure, or infection\nStudent health, safety, and well-being are the university’s top priorities. To help ensure your well-being and the well-being of those around you, please do not come to class if you have tested positive for COVID-19 or have possible symptoms and have not yet been tested. If any of these situations apply to you, you must follow university guidance related to the ongoing COVID-19 pandemic and current health and safety protocols. If you are experiencing any COVID-19 symptoms, contact student health (dshcheckin@duke.edu, 919- 681-9355). Learn more about current university policy related to COVID-19 at https://coronavirus.duke.edu. To keep the university community as safe and healthy as possible, you will be expected to follow these guidelines. Please reach out to me and your academic dean as soon as possible if you need to quarantine or isolate so that we can discuss arrangements for your continued participation in class.\n\n\nInclement weather policy\nIn the event of inclement weather or other connectivity-related events that prohibit class attendance, I will notify you how we will make up missed course content and work. This might entail holding the class on Zoom synchronously, we may rely on Duke’s designated make-up days, or you may be asked to watch a recording of the class.\n\n\nPolicy on video recording course content\nAll lectures will be recorded and available on Panopto, so students should not need to create their own recordings of lectures. If you feel that you need record the lectures yourself, you must get permission from me ahead of time and these recordings should be used for personal study only, no for distribution. The full policy on recording of lectures falls under the Duke University Policy on Intellectual Property Rights, available at https://policies.provost.duke.edu/docs/faculty-handbook-appendix-m-intellectual-property. Unauthorized distribution is a cause for disciplinary action by the Judicial Board."
  },
  {
    "objectID": "course-syllabus.html#accommodations",
    "href": "course-syllabus.html#accommodations",
    "title": "Syllabus",
    "section": "Accommodations",
    "text": "Accommodations\n\nAcademic accommodations\nIf you are a student with a disability and need accommodations for this class, it is your responsibility to register with the Student Disability Access Office (SDAO) and provide them with documentation of your disability. SDAO will work with you to determine what accommodations are appropriate for your situation. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu.\n\n\nReligious accommodations\nStudents are permitted by university policy to be absent from class to observe a religious holiday. Accordingly, Trinity College of Arts & Sciences and the Pratt School of Engineering have established procedures to be followed by students for notifying their instructors of an absence necessitated by the observance of a religious holiday. Please submit requests for religious accommodations at the beginning of the semester so that we can work to make suitable arrangements well ahead of time. You can find the policy and relevant notification form here: https://trinity.duke.edu/undergraduate/academic-policies/religious-holidays.\nNote: If you’ve read this far in the syllabus, email me a picture of your pet if you have one or your favorite meme!"
  },
  {
    "objectID": "course-syllabus.html#sec-important-dates",
    "href": "course-syllabus.html#sec-important-dates",
    "title": "Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nMonday, August 28: Classes begin\nMonday, September 4: Labor Day - No lecture\nFriday, September 8: Drop/add ends\nWednesday, October 4: Exam 1 - In class\nFriday, October 6: Exam 1 - Take home due\nFriday, October 13: Project 1 due + Mid-semester grades reported\nMonday, October 16: Fall Break - No lecture\nFriday, November 10: Last day to withdraw with W\nWednesday, November 15: Exam 2 - In class\nFriday, November 17: Exam 2 - Take home due\nWednesday, November 22: Thanksgiving Break - No lecture\nFriday, November 24: Thanksgiving Break - No lab\nFriday, December 8: Classes end\nSaturday, December 9 - Tuesday, December 12: Reading period\nThursday, December 14, 2-5pm: Project 2 presentations\n\nFor more important dates, see the full Duke Academic Calendar."
  },
  {
    "objectID": "course-syllabus.html#footnotes",
    "href": "course-syllabus.html#footnotes",
    "title": "Syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThese guiding principles are based on Course Policies related to ChatGPT and other AI Tools developed by Joel Gladd, Ph.D.↩︎"
  }
]